{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5tEHujePpQSt4Euj42RX3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57f363e20b9b4e4f9cda343a15972250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_902754345b5b4aa58594b82a423f56b4",
              "IPY_MODEL_367064c39b08435181bbf678b676abf1",
              "IPY_MODEL_1933b6fca35242229b9063192cd63fcb"
            ],
            "layout": "IPY_MODEL_f32dc1281a294609bf3878594e7b076f"
          }
        },
        "902754345b5b4aa58594b82a423f56b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d3feaa490fa4f54bd771f9f9eab6211",
            "placeholder": "​",
            "style": "IPY_MODEL_87525172f0ea479799dc8d2190efe744",
            "value": "modules.json: 100%"
          }
        },
        "367064c39b08435181bbf678b676abf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a182a9d5dc4443178f70345607f7d1e0",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81310f93c70d4946af7a53ae349fc37e",
            "value": 349
          }
        },
        "1933b6fca35242229b9063192cd63fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d937be38b2d4177a7196cb9fff04961",
            "placeholder": "​",
            "style": "IPY_MODEL_43210386bd2242cbab337bd7c4ea2cbb",
            "value": " 349/349 [00:00&lt;00:00, 4.84kB/s]"
          }
        },
        "f32dc1281a294609bf3878594e7b076f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3feaa490fa4f54bd771f9f9eab6211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87525172f0ea479799dc8d2190efe744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a182a9d5dc4443178f70345607f7d1e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81310f93c70d4946af7a53ae349fc37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d937be38b2d4177a7196cb9fff04961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43210386bd2242cbab337bd7c4ea2cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c28ea7f95f254ff9b885e7855502618e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6830c8057c74eaf8dd4da5f4e7f057f",
              "IPY_MODEL_99830715524940c6a6fb69f50394c098",
              "IPY_MODEL_e9cda53938fe4ababb27b4be9c772801"
            ],
            "layout": "IPY_MODEL_e268cff4af7b4ba0b182f754f722cc68"
          }
        },
        "a6830c8057c74eaf8dd4da5f4e7f057f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34caa10969be4254941f3a601c50625b",
            "placeholder": "​",
            "style": "IPY_MODEL_b5175011803445fbbab16fde06266b51",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "99830715524940c6a6fb69f50394c098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e3b8abfccd46e1828f8c105f97c09c",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_642e507bcb2e45849abb20d9a31d44bb",
            "value": 116
          }
        },
        "e9cda53938fe4ababb27b4be9c772801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ebb4f10ac7742449ddc590b10adf465",
            "placeholder": "​",
            "style": "IPY_MODEL_fd1aecbcda87485f9c17d3376c4c9a68",
            "value": " 116/116 [00:00&lt;00:00, 2.10kB/s]"
          }
        },
        "e268cff4af7b4ba0b182f754f722cc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34caa10969be4254941f3a601c50625b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5175011803445fbbab16fde06266b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e3b8abfccd46e1828f8c105f97c09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642e507bcb2e45849abb20d9a31d44bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ebb4f10ac7742449ddc590b10adf465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd1aecbcda87485f9c17d3376c4c9a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8de9e35cc9a4c62b50d3a45a9108762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2560832d9ee4584997d45def4a5f735",
              "IPY_MODEL_40c88f8f5d83439f817caba3c967b65f",
              "IPY_MODEL_02c03773c7b04c16a3d94d108505d715"
            ],
            "layout": "IPY_MODEL_5b24dfaae93549f89497aadc9618e204"
          }
        },
        "e2560832d9ee4584997d45def4a5f735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abe32017803248ec8a8e177630f9c522",
            "placeholder": "​",
            "style": "IPY_MODEL_2315baa66f514de9bc2f8e14e1dbb5dd",
            "value": "README.md: "
          }
        },
        "40c88f8f5d83439f817caba3c967b65f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13f5d43205a4f02ab22b3903a73dfad",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2eedbe8d66d416081804612f517b226",
            "value": 1
          }
        },
        "02c03773c7b04c16a3d94d108505d715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e086fcafba444e12a2068ad0daa397ce",
            "placeholder": "​",
            "style": "IPY_MODEL_dc81e945177147b9ab1b3fc15cc139a5",
            "value": " 10.5k/? [00:00&lt;00:00, 110kB/s]"
          }
        },
        "5b24dfaae93549f89497aadc9618e204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abe32017803248ec8a8e177630f9c522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2315baa66f514de9bc2f8e14e1dbb5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e13f5d43205a4f02ab22b3903a73dfad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e2eedbe8d66d416081804612f517b226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e086fcafba444e12a2068ad0daa397ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc81e945177147b9ab1b3fc15cc139a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6423198a9cc3439399597ab744d9204e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44fdf0a52ccf41359506a6c14a8f14d8",
              "IPY_MODEL_bc0dece8f1b34c7db3f44c66fa50f06a",
              "IPY_MODEL_be3d6a9af05e4742ab2f3424f865f3b1"
            ],
            "layout": "IPY_MODEL_e3fc20d6fb1943e88ac9f335fcc3145b"
          }
        },
        "44fdf0a52ccf41359506a6c14a8f14d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c83a26ceca984d9ea86a2d9b601ce747",
            "placeholder": "​",
            "style": "IPY_MODEL_6d842613a3964303bbd40ce892fbfada",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "bc0dece8f1b34c7db3f44c66fa50f06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91ca24ea8a7f4945a68f0e836d5a9c21",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c151a509f694c10a00b63250f0e6d33",
            "value": 53
          }
        },
        "be3d6a9af05e4742ab2f3424f865f3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8cb203201fa4649bfb4a9d744808a65",
            "placeholder": "​",
            "style": "IPY_MODEL_0ecc584ec91047c9a790e6718d48940c",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.08kB/s]"
          }
        },
        "e3fc20d6fb1943e88ac9f335fcc3145b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c83a26ceca984d9ea86a2d9b601ce747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d842613a3964303bbd40ce892fbfada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91ca24ea8a7f4945a68f0e836d5a9c21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c151a509f694c10a00b63250f0e6d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8cb203201fa4649bfb4a9d744808a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ecc584ec91047c9a790e6718d48940c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "975b3d8eb02b4c78b23179edadbaf9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8fb30335dfc48a4a96cd1474cc27c77",
              "IPY_MODEL_6d394109fb4e4057a6f00dc71cacb1e2",
              "IPY_MODEL_8aadce0a2378441982f625c879f1c819"
            ],
            "layout": "IPY_MODEL_b7275c16e30c456eaa4b44e4023f4aa6"
          }
        },
        "f8fb30335dfc48a4a96cd1474cc27c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e88ee826c504a47b9fa8ecb6ce10a5a",
            "placeholder": "​",
            "style": "IPY_MODEL_d08ab0b710274b9ebcfbe635cf7eb6a7",
            "value": "config.json: 100%"
          }
        },
        "6d394109fb4e4057a6f00dc71cacb1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f73b475c6644bdf9b9087c636b303d4",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f49049fd77b646bd8a2cf389012b65df",
            "value": 612
          }
        },
        "8aadce0a2378441982f625c879f1c819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b79e8a7a695439d897adf56f4ea97ee",
            "placeholder": "​",
            "style": "IPY_MODEL_dbc7d136a66e47daa649dc039ea9ea1c",
            "value": " 612/612 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "b7275c16e30c456eaa4b44e4023f4aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e88ee826c504a47b9fa8ecb6ce10a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d08ab0b710274b9ebcfbe635cf7eb6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f73b475c6644bdf9b9087c636b303d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49049fd77b646bd8a2cf389012b65df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b79e8a7a695439d897adf56f4ea97ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc7d136a66e47daa649dc039ea9ea1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37bad82439b24484b31d68fe44a9dfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8513a14baf6b40ad94250683681f9fa9",
              "IPY_MODEL_ebf9f90960f84b50bf7a6c005534b2de",
              "IPY_MODEL_d6e8b850e59a42bfb0dd44419b39644a"
            ],
            "layout": "IPY_MODEL_615bfec5977c41fcb8a319405b7fad40"
          }
        },
        "8513a14baf6b40ad94250683681f9fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20e0c55e71a4218bb6d144bf8ac128e",
            "placeholder": "​",
            "style": "IPY_MODEL_bee79f8202244796b2523f968721ad5f",
            "value": "model.safetensors: 100%"
          }
        },
        "ebf9f90960f84b50bf7a6c005534b2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87de8c993e554690bfba4e7fe8c6a858",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1aebf1e655954f5cb8419772ce2bf5df",
            "value": 90868376
          }
        },
        "d6e8b850e59a42bfb0dd44419b39644a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_090c2834faa84988ad0c5e370e065989",
            "placeholder": "​",
            "style": "IPY_MODEL_4f7e560839c84df9a17408aa445d27eb",
            "value": " 90.9M/90.9M [00:03&lt;00:00, 37.1MB/s]"
          }
        },
        "615bfec5977c41fcb8a319405b7fad40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20e0c55e71a4218bb6d144bf8ac128e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee79f8202244796b2523f968721ad5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87de8c993e554690bfba4e7fe8c6a858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aebf1e655954f5cb8419772ce2bf5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "090c2834faa84988ad0c5e370e065989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7e560839c84df9a17408aa445d27eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9df24d1407f24d41ba48aa731f97cc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_995ad44805af4be39c8221d95deaf15b",
              "IPY_MODEL_d8f4b7d49a19408f98e5dfee53cd99fa",
              "IPY_MODEL_b69add0700ca42e48c3897b8c1bec08d"
            ],
            "layout": "IPY_MODEL_9a889208730641f39dcbeb485d664044"
          }
        },
        "995ad44805af4be39c8221d95deaf15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91af01a361484ed2982e63a24e6d4b1e",
            "placeholder": "​",
            "style": "IPY_MODEL_cd76f88eae8543aaa25ce817ac7b96ab",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d8f4b7d49a19408f98e5dfee53cd99fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13cf1871967b47ceb9f7cd4fc8e93875",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb618f87c31f481ab5962d591c46b585",
            "value": 350
          }
        },
        "b69add0700ca42e48c3897b8c1bec08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c56756439994412a7bbeae7d51bae86",
            "placeholder": "​",
            "style": "IPY_MODEL_d2b56234f6db4714841b821a67ee02e1",
            "value": " 350/350 [00:00&lt;00:00, 4.77kB/s]"
          }
        },
        "9a889208730641f39dcbeb485d664044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91af01a361484ed2982e63a24e6d4b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd76f88eae8543aaa25ce817ac7b96ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13cf1871967b47ceb9f7cd4fc8e93875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb618f87c31f481ab5962d591c46b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c56756439994412a7bbeae7d51bae86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b56234f6db4714841b821a67ee02e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3842c759c7934185b3289ef5487ed196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59511b35ce0647f78b309e5f58f9a5ff",
              "IPY_MODEL_58eed49664ca4b0c8a586c8f798c1f38",
              "IPY_MODEL_a0deafa352864de68deea4aa6646e7e4"
            ],
            "layout": "IPY_MODEL_6b7f17a4729747718490e4e79edae415"
          }
        },
        "59511b35ce0647f78b309e5f58f9a5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2adb888db464c6cbbce752af8669536",
            "placeholder": "​",
            "style": "IPY_MODEL_ef6582d276194f6b98f9a3602d39b754",
            "value": "vocab.txt: "
          }
        },
        "58eed49664ca4b0c8a586c8f798c1f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26f7396e6cf341f3a2e5384cee99f61c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de78887f25554895a8b6da2fe0d57854",
            "value": 1
          }
        },
        "a0deafa352864de68deea4aa6646e7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ebb35bc683e4254b153d523cdec8838",
            "placeholder": "​",
            "style": "IPY_MODEL_bec834f1923d46b39101312cd7530500",
            "value": " 232k/? [00:00&lt;00:00, 4.09MB/s]"
          }
        },
        "6b7f17a4729747718490e4e79edae415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2adb888db464c6cbbce752af8669536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef6582d276194f6b98f9a3602d39b754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26f7396e6cf341f3a2e5384cee99f61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "de78887f25554895a8b6da2fe0d57854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ebb35bc683e4254b153d523cdec8838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec834f1923d46b39101312cd7530500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e7feed5c1724d42b86a2f4905b51d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4513c74f528a4465b4793616ab5e6ee0",
              "IPY_MODEL_ae22f966715240bfa810fdf40bca654f",
              "IPY_MODEL_67eefa2a3c3a4b318d11887887f2bffc"
            ],
            "layout": "IPY_MODEL_41c3464c4b7946b7aba8baad2c4b2194"
          }
        },
        "4513c74f528a4465b4793616ab5e6ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c9d5645ba6847e8a364769ff3e8d53a",
            "placeholder": "​",
            "style": "IPY_MODEL_1bb602b169fe47ccb2baca2fa2e284eb",
            "value": "tokenizer.json: "
          }
        },
        "ae22f966715240bfa810fdf40bca654f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3943955c20c4622adb33855a6b2b2e5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fa196780c1f478bb752cfec1c865427",
            "value": 1
          }
        },
        "67eefa2a3c3a4b318d11887887f2bffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_428467850e9d4e7fa8142c4689e4f370",
            "placeholder": "​",
            "style": "IPY_MODEL_fc00590c52dd488b8f667d51e3039891",
            "value": " 466k/? [00:00&lt;00:00, 6.86MB/s]"
          }
        },
        "41c3464c4b7946b7aba8baad2c4b2194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9d5645ba6847e8a364769ff3e8d53a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb602b169fe47ccb2baca2fa2e284eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3943955c20c4622adb33855a6b2b2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4fa196780c1f478bb752cfec1c865427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "428467850e9d4e7fa8142c4689e4f370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc00590c52dd488b8f667d51e3039891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "122e4d4c64914457a8ada87c234fe40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_448429f569af404bbf162ae3ccec32d4",
              "IPY_MODEL_5770e86c094d4d4f8e3473241495ad3f",
              "IPY_MODEL_7aaba2873c6140b4abefe864c34f0120"
            ],
            "layout": "IPY_MODEL_324dd3386d7d43e9bb63afcc048d42b0"
          }
        },
        "448429f569af404bbf162ae3ccec32d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919e56bd82874eb0963285dd7d520a1d",
            "placeholder": "​",
            "style": "IPY_MODEL_bc2e184e5cc943a6aa173c9579acfc4b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5770e86c094d4d4f8e3473241495ad3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3488471a0ae548d394dc40c93cf51a3a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6626a52314c8439a8a82c5994a4f4eac",
            "value": 112
          }
        },
        "7aaba2873c6140b4abefe864c34f0120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11565bb74a4d4902965b2cb386157f78",
            "placeholder": "​",
            "style": "IPY_MODEL_2e8df7f17f87442e90066644dc855a6d",
            "value": " 112/112 [00:00&lt;00:00, 4.23kB/s]"
          }
        },
        "324dd3386d7d43e9bb63afcc048d42b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "919e56bd82874eb0963285dd7d520a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2e184e5cc943a6aa173c9579acfc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3488471a0ae548d394dc40c93cf51a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6626a52314c8439a8a82c5994a4f4eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11565bb74a4d4902965b2cb386157f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e8df7f17f87442e90066644dc855a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1757ed981e834159bde05a810c8b1d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51d487adffa142e5b4b412c13216c4e3",
              "IPY_MODEL_cc13e815e637486d986f92dbf00ec74b",
              "IPY_MODEL_961cba277876429ca6392916a98a0c6e"
            ],
            "layout": "IPY_MODEL_195ad42c0e1941ccb35a2baf7ac6697e"
          }
        },
        "51d487adffa142e5b4b412c13216c4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25685bc5a39d40bfaccd38243c539841",
            "placeholder": "​",
            "style": "IPY_MODEL_e76ae1d6fcff4ea5a0ddfbc8af4b5a42",
            "value": "config.json: 100%"
          }
        },
        "cc13e815e637486d986f92dbf00ec74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9945d3f1be5a4ba78867888b5d8f5957",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b395229599354ce6bdc8eef3bd70f80d",
            "value": 190
          }
        },
        "961cba277876429ca6392916a98a0c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f30518c50454c9385dfa9867905cc61",
            "placeholder": "​",
            "style": "IPY_MODEL_f0345518a8c84c11993f9adc93a73c67",
            "value": " 190/190 [00:00&lt;00:00, 6.35kB/s]"
          }
        },
        "195ad42c0e1941ccb35a2baf7ac6697e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25685bc5a39d40bfaccd38243c539841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76ae1d6fcff4ea5a0ddfbc8af4b5a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9945d3f1be5a4ba78867888b5d8f5957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b395229599354ce6bdc8eef3bd70f80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f30518c50454c9385dfa9867905cc61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0345518a8c84c11993f9adc93a73c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekerintaiwoa/MediaApp/blob/master/ofline_aiagent2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A9L75fjXXEs"
      },
      "outputs": [],
      "source": [
        "# prompt: create an ai agents that allows users to upload a book, ask question about the book,Summarize Chapters or Sections,Study and Review\n",
        "\n",
        "# This code requires several libraries that might not be installed by default\n",
        "# on a standard Colab instance. We'll install them first.\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install PyMuPDF  # For handling PDF files\n",
        "!pip install nltk  # For natural language processing tasks like tokenization\n",
        "!pip install scikit-learn  # For text vectorization (TF-IDF)\n",
        "!pip install faiss-cpu  # For efficient similarity search (vector database)\n",
        "!pip install transformers  # For using powerful language models\n",
        "!pip install torch  # PyTorch is a dependency for transformers\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import nltk\n",
        "import re\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Download necessary NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None\n",
        "        self.tfidf_matrix = None\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            return\n",
        "\n",
        "        section_texts = list(self.chapter_sections.values())\n",
        "        print(f\"Vectorizing {len(section_texts)} sections...\")\n",
        "\n",
        "        # Using TF-IDF for simplicity; consider Sentence Transformers for better semantic search\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(section_texts)\n",
        "\n",
        "        # Create FAISS index\n",
        "        dimension = self.tfidf_matrix.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "        self.index.add(self.tfidf_matrix.astype('float32')) # FAISS requires float32\n",
        "        print(\"FAISS index created.\")\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        question_vec = self.vectorizer.transform([question]).toarray().astype('float32')\n",
        "        D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        relevant_section_title = section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title]\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context)\n",
        "            return f\"Answer: {answer['answer']} (Source: {relevant_section_title}, Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section:\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for study/review.\"\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# --- How to use the agent in Colab ---\n",
        "\n",
        "# 1. Mount Google Drive to access your files (optional, but common)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Create an instance of the BookQA agent\n",
        "agent = BookQA()\n",
        "\n",
        "# 3. Upload a book (replace '/content/drive/My Drive/your_book.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/My Drive/your_book.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)\n",
        "\n",
        "# --- Now you can interact with the agent ---\n",
        "\n",
        "# Example 1: Ask a question\n",
        "if agent.book_text:\n",
        "    question1 = \"What is the main topic of the introduction?\"\n",
        "    answer1 = agent.ask_question(question1)\n",
        "    print(f\"\\nQuestion: {question1}\")\n",
        "    print(answer1)\n",
        "\n",
        "    question2 = \"What is the author's perspective on [some topic mentioned in your book]?\"\n",
        "    answer2 = agent.ask_question(question2)\n",
        "    print(f\"\\nQuestion: {question2}\")\n",
        "    print(answer2)\n",
        "\n",
        "    # Example 2: List sections\n",
        "    print(\"\\nListing sections:\")\n",
        "    agent.list_sections()\n",
        "\n",
        "    # Example 3: Summarize a section (replace '1' with the actual section number or part of the title)\n",
        "    section_to_summarize = \"1\" # <--- **CHANGE THIS TO A SECTION NUMBER OR TITLE FROM `list_sections()`**\n",
        "    print(f\"\\nAttempting to summarize section: {section_to_summarize}\")\n",
        "    summary = agent.summarize_section(section_to_summarize)\n",
        "    print(summary)\n",
        "\n",
        "    # Example 4: Enter Study/Review mode\n",
        "    print(\"\\nEntering Study/Review mode:\")\n",
        "    # agent.study_review() # Uncomment this line to start the interactive study mode\n",
        "\n",
        "else:\n",
        "    print(\"\\nBook was not loaded successfully. Please check the file path and format.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install necessary libraries\n",
        "!pip install PyMuPDF  # For handling PDF files\n",
        "!pip install nltk  # For natural language processing tasks like tokenization\n",
        "!pip install scikit-learn  # For text vectorization (TF-IDF)\n",
        "!pip install faiss-cpu  # For efficient similarity search (vector database)\n",
        "!pip install transformers  # For using powerful language models\n",
        "!pip install torch  # PyTorch is a dependency for transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkxes4xOZFDi",
        "outputId": "9462bf35-8230-495d-d8d6-6acac34606eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.3\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xv2VTA73ZpZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import nltk\n",
        "import re\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "gFBM6QUBZsOv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import nltk\n",
        "import re\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None\n",
        "        self.tfidf_matrix = None\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Basic text cleaning.\"\"\"\n",
        "        text = text.lower() # Convert to lowercase\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove non-alphanumeric characters except spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        self.chapter_sections = {} # Clear existing sections\n",
        "\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            self.vectorizer = None\n",
        "            self.tfidf_matrix = None\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "        # Ensure all values in chapter_sections are strings, clean them, and filter empty ones\n",
        "        valid_section_texts = []\n",
        "        valid_section_titles = []\n",
        "        print(\"Cleaning and filtering sections for vectorization:\")\n",
        "        for title, text in self.chapter_sections.items():\n",
        "            if isinstance(text, str) and text.strip():\n",
        "                cleaned_text = self.clean_text(text) # Clean the text\n",
        "                if cleaned_text: # Only add if cleaned text is not empty\n",
        "                    valid_section_texts.append(cleaned_text)\n",
        "                    valid_section_titles.append(title) # Keep track of titles for valid sections\n",
        "                else:\n",
        "                    print(f\"Warning: Section '{title}' became empty after cleaning. Skipping for vectorization.\")\n",
        "            else:\n",
        "                print(f\"Warning: Section '{title}' is not a valid string or is empty. Skipping for vectorization.\")\n",
        "\n",
        "        print(f\"Found {len(valid_section_texts)} valid sections after cleaning and filtering.\")\n",
        "\n",
        "        if not valid_section_texts:\n",
        "            print(\"No valid sections to vectorize after filtering.\")\n",
        "            self.vectorizer = None\n",
        "            self.tfidf_matrix = None\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "        print(f\"Vectorizing {len(valid_section_texts)} valid sections...\")\n",
        "\n",
        "        # Using TF-IDF for simplicity; consider Sentence Transformers for better semantic search\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "        try:\n",
        "            self.tfidf_matrix = self.vectorizer.fit_transform(valid_section_texts)\n",
        "\n",
        "            # Create FAISS index\n",
        "            dimension = self.tfidf_matrix.shape[1]\n",
        "            if dimension > 0:\n",
        "                self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "                self.index.add(self.tfidf_matrix.astype('float32')) # FAISS requires float32\n",
        "                print(\"FAISS index created.\")\n",
        "                # Store the titles corresponding to the vectorized texts for later lookup\n",
        "                self._vectorized_section_titles = valid_section_titles\n",
        "            else:\n",
        "                print(\"TF-IDF matrix has no features after vectorization. Cannot create FAISS index.\")\n",
        "                self.index = None\n",
        "                self._vectorized_section_titles = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during TF-IDF vectorization: {e}\")\n",
        "            self.vectorizer = None\n",
        "            self.tfidf_matrix = None\n",
        "            self.index = None\n",
        "            self._vectorized_section_titles = []\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "        if not self.vectorizer or not self.index or not hasattr(self, '_vectorized_section_titles') or not self._vectorized_section_titles:\n",
        "             return \"Book content not vectorized or index not created. Cannot answer questions.\"\n",
        "\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        try:\n",
        "            # Clean the question before vectorizing for search\n",
        "            cleaned_question = self.clean_text(question)\n",
        "            if not cleaned_question:\n",
        "                 return \"Please provide a valid question after cleaning.\"\n",
        "\n",
        "            question_vec = self.vectorizer.transform([cleaned_question]).toarray().astype('float32')\n",
        "            D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "        except Exception as e:\n",
        "            print(f\"Error transforming question for search: {e}\")\n",
        "            return \"Could not process the question for searching.\"\n",
        "\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        # Use the stored vectorized section titles to get the correct title\n",
        "        relevant_section_title = self._vectorized_section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title] # Use original text for QA\n",
        "\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context) # Use original question for QA pipeline\n",
        "            return f\"Answer: {answer['answer']} (Source: '{relevant_section_title}', Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section from '{relevant_section_title}':\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for study/review.\"\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")"
      ],
      "metadata": {
        "id": "j6P1UkopZsX3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- How to use the agent in Colab ---\n",
        "\n",
        "# 1. Mount Google Drive to access your files (optional, but common)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4Vvz_0LZsfj",
        "outputId": "83e81f5a-192a-4561-eab4-c74564e6bdef"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VR7Q_usbZskc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create an instance of the BookQA agent\n",
        "agent = BookQA()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJSYhoGzZspi",
        "outputId": "028aeeca-d243-4ab4-beae-2d790ba9ef18"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization model loaded.\n",
            "Models initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXLRUpBGZsuj",
        "outputId": "9b68421f-4b1e-42f1-bcc4-9aaeee424d5d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Vectorizing 1 valid sections...\n",
            "Error during TF-IDF vectorization: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Now you can interact with the agent ---\n",
        "\n",
        "# Example 1: Ask a question\n",
        "if agent.book_text:\n",
        "    question1 = \"BRIAN TRACY IDEAS TO LIVE BY\"\n",
        "    answer1 = agent.ask_question(question1)\n",
        "    print(f\"\\nQuestion: {question1}\")\n",
        "    print(answer1)\n"
      ],
      "metadata": {
        "id": "R3S1fjB9ZtIh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c92528f",
        "outputId": "e9e12ba8-b085-4ae6-996c-2069364a63d8"
      },
      "source": [
        "# 2. Create an instance of the BookQA agent\n",
        "agent = BookQA()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization model loaded.\n",
            "Models initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ff7bf5",
        "outputId": "cadf6e6e-2c84-4566-ff4f-50e176232247"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Vectorizing 1 sections...\n",
            "Error reading file: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6825f1ca",
        "outputId": "7f693522-3d92-4ed9-f108-a0b3c67e4ca6"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/627260606-chatbotdoc (1).pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/627260606-chatbotdoc (1).pdf\n",
            "Reading 97 pages from /content/drive/MyDrive/627260606-chatbotdoc (1).pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 2 chapters/sections or chunks.\n",
            "Vectorizing 2 sections...\n",
            "Error reading file: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f0655f4",
        "outputId": "a933dda3-7b14-40d4-d85e-18604573785b"
      },
      "source": [
        "# --- Now you can interact with the agent ---\n",
        "\n",
        "# Example 1: Ask a question\n",
        "if agent.book_text:\n",
        "    question1 = \"What is the main topic of the introduction?\"\n",
        "    answer1 = agent.ask_question(question1)\n",
        "    print(f\"\\nQuestion: {question1}\")\n",
        "    print(answer1)\n",
        "\n",
        "    question2 = \"What are the key steps for setting goals?\" # Example question related to the book title\n",
        "    answer2 = agent.ask_question(question2)\n",
        "    print(f\"\\nQuestion: {question2}\")\n",
        "    print(answer2)\n",
        "\n",
        "    # Example 2: List sections\n",
        "    print(\"\\nListing sections:\")\n",
        "    agent.list_sections()\n",
        "\n",
        "    # Example 3: Summarize a section (replace '1' with the actual section number or part of the title)\n",
        "    # Check the output of list_sections() to find a section to summarize.\n",
        "    # For now, let's try summarizing the first identified section (assuming there's at least one)\n",
        "    if agent.chapter_sections:\n",
        "        first_section_key = list(agent.chapter_sections.keys())[0]\n",
        "        print(f\"\\nAttempting to summarize section: {first_section_key}\")\n",
        "        summary = agent.summarize_section(first_section_key)\n",
        "        print(summary)\n",
        "    else:\n",
        "        print(\"\\nNo sections available to summarize.\")\n",
        "\n",
        "\n",
        "    # Example 4: Enter Study/Review mode\n",
        "    print(\"\\nEntering Study/Review mode:\")\n",
        "    # agent.study_review() # Uncomment this line to start the interactive study mode\n",
        "\n",
        "else:\n",
        "    print(\"\\nBook was not loaded successfully. Please check the file path and format.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Book was not loaded successfully. Please check the file path and format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89c63f5c",
        "outputId": "a5c67147-23ee-4d6c-bbd9-dcc6dafc1236"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/627260606-chatbotdoc (1).pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/627260606-chatbotdoc (1).pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/627260606-chatbotdoc (1).pdf\n",
            "Reading 97 pages from /content/drive/MyDrive/627260606-chatbotdoc (1).pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 2 chapters/sections or chunks.\n",
            "Vectorizing 2 sections...\n",
            "Error reading file: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3710e6",
        "outputId": "d9b0ace2-6ac7-4655-a480-d2f34cbcce9c"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Vectorizing 1 valid sections...\n",
            "Error during TF-IDF vectorization: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09398f4e",
        "outputId": "54c09539-1ea6-48b9-9407-51843c5c9930"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Vectorizing 1 valid sections...\n",
            "Error during TF-IDF vectorization: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fd2f2e0"
      },
      "source": [
        "# Task\n",
        "Explain the error \"setting an array element with a sequence\" encountered during TF-IDF vectorization when processing PDF files \"/content/drive/MyDrive/627260606-chatbotdoc (1).pdf\" and \"/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\". If possible, fix the error in the provided code and incorporate the changes. Otherwise, diagnose the error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b59d8c9"
      },
      "source": [
        "## Install sentence transformers\n",
        "\n",
        "### Subtask:\n",
        "Add the necessary library for Sentence Transformers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeb69d2a"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to add the necessary library for Sentence Transformers. This requires installing the `sentence-transformers` package using pip. This needs to be in a separate code cell as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e96c3a96",
        "outputId": "cc5d35a4-7342-42c9-f527-517fa2bd725a"
      },
      "source": [
        "!pip install sentence-transformers"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae6cfad4"
      },
      "source": [
        "## Update `initialize models`\n",
        "\n",
        "### Subtask:\n",
        "Load a Sentence Transformer model instead of relying solely on TF-IDF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfd16b2"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary class for Sentence Transformers and initialize the Sentence Transformer model in the `initialize_models` method, replacing the TF-IDF vectorizer initialization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b28a24c"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None # This will be replaced by the embedding model\n",
        "        self.tfidf_matrix = None # This will be replaced by the embeddings\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "        self.embedding_model = None # New attribute for Sentence Transformer model\n",
        "\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "        # Initialize Sentence Transformer model for embeddings\n",
        "        try:\n",
        "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            print(\"Sentence Transformer model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Sentence Transformer model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.embedding_model = None\n",
        "\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Basic text cleaning.\"\"\"\n",
        "        text = text.lower() # Convert to lowercase\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove non-alphanumeric characters except spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        self.chapter_sections = {} # Clear existing sections\n",
        "\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index using Sentence Transformers.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "        if not self.embedding_model:\n",
        "            print(\"Sentence Transformer model not loaded. Cannot vectorize sections.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "\n",
        "        section_texts = list(self.chapter_sections.values())\n",
        "        print(f\"Creating embeddings for {len(section_texts)} sections...\")\n",
        "\n",
        "        try:\n",
        "            # Create embeddings using the Sentence Transformer model\n",
        "            embeddings = self.embedding_model.encode(section_texts, convert_to_numpy=True)\n",
        "            self.tfidf_matrix = embeddings # Store embeddings (renamed from tfidf_matrix)\n",
        "\n",
        "            # Create FAISS index\n",
        "            dimension = embeddings.shape[1]\n",
        "            if dimension > 0:\n",
        "                self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "                self.index.add(embeddings.astype('float32')) # FAISS requires float32\n",
        "                print(\"FAISS index created.\")\n",
        "                # Store the titles corresponding to the vectorized texts for later lookup\n",
        "                self._vectorized_section_titles = list(self.chapter_sections.keys()) # Store original titles\n",
        "            else:\n",
        "                print(\"Embeddings have no dimensions after vectorization. Cannot create FAISS index.\")\n",
        "                self.index = None\n",
        "                self._vectorized_section_titles = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during embedding creation or FAISS index creation: {e}\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            self._vectorized_section_titles = []\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "        if not self.embedding_model or not self.index or not hasattr(self, '_vectorized_section_titles') or not self._vectorized_section_titles:\n",
        "             return \"Book content not vectorized or index not created. Cannot answer questions.\"\n",
        "\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        try:\n",
        "            # Create embedding for the question\n",
        "            question_vec = self.embedding_model.encode([question], convert_to_numpy=True).astype('float32')\n",
        "            D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating question embedding or searching index: {e}\")\n",
        "            return \"Could not process the question for searching.\"\n",
        "\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        # Use the stored vectorized section titles to get the correct title\n",
        "        relevant_section_title = self._vectorized_section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title] # Use original text for QA\n",
        "\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context) # Use original question for QA pipeline\n",
        "            return f\"Answer: {answer['answer']} (Source: '{relevant_section_title}', Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section from '{relevant_section_title}':\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for study/review.\"\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57d9c5f1"
      },
      "source": [
        "## Review and refine\n",
        "\n",
        "### Subtask:\n",
        "Test the updated agent with the problematic PDF and potentially other documents. Adjust text splitting, model choice, or search parameters as needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86b2ecc"
      },
      "source": [
        "**Reasoning**:\n",
        "Re-instantiate the BookQA agent to load the updated code and then attempt to upload one of the problematic PDF files to test if the error is resolved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720,
          "referenced_widgets": [
            "57f363e20b9b4e4f9cda343a15972250",
            "902754345b5b4aa58594b82a423f56b4",
            "367064c39b08435181bbf678b676abf1",
            "1933b6fca35242229b9063192cd63fcb",
            "f32dc1281a294609bf3878594e7b076f",
            "2d3feaa490fa4f54bd771f9f9eab6211",
            "87525172f0ea479799dc8d2190efe744",
            "a182a9d5dc4443178f70345607f7d1e0",
            "81310f93c70d4946af7a53ae349fc37e",
            "1d937be38b2d4177a7196cb9fff04961",
            "43210386bd2242cbab337bd7c4ea2cbb",
            "c28ea7f95f254ff9b885e7855502618e",
            "a6830c8057c74eaf8dd4da5f4e7f057f",
            "99830715524940c6a6fb69f50394c098",
            "e9cda53938fe4ababb27b4be9c772801",
            "e268cff4af7b4ba0b182f754f722cc68",
            "34caa10969be4254941f3a601c50625b",
            "b5175011803445fbbab16fde06266b51",
            "18e3b8abfccd46e1828f8c105f97c09c",
            "642e507bcb2e45849abb20d9a31d44bb",
            "7ebb4f10ac7742449ddc590b10adf465",
            "fd1aecbcda87485f9c17d3376c4c9a68",
            "c8de9e35cc9a4c62b50d3a45a9108762",
            "e2560832d9ee4584997d45def4a5f735",
            "40c88f8f5d83439f817caba3c967b65f",
            "02c03773c7b04c16a3d94d108505d715",
            "5b24dfaae93549f89497aadc9618e204",
            "abe32017803248ec8a8e177630f9c522",
            "2315baa66f514de9bc2f8e14e1dbb5dd",
            "e13f5d43205a4f02ab22b3903a73dfad",
            "e2eedbe8d66d416081804612f517b226",
            "e086fcafba444e12a2068ad0daa397ce",
            "dc81e945177147b9ab1b3fc15cc139a5",
            "6423198a9cc3439399597ab744d9204e",
            "44fdf0a52ccf41359506a6c14a8f14d8",
            "bc0dece8f1b34c7db3f44c66fa50f06a",
            "be3d6a9af05e4742ab2f3424f865f3b1",
            "e3fc20d6fb1943e88ac9f335fcc3145b",
            "c83a26ceca984d9ea86a2d9b601ce747",
            "6d842613a3964303bbd40ce892fbfada",
            "91ca24ea8a7f4945a68f0e836d5a9c21",
            "4c151a509f694c10a00b63250f0e6d33",
            "e8cb203201fa4649bfb4a9d744808a65",
            "0ecc584ec91047c9a790e6718d48940c",
            "975b3d8eb02b4c78b23179edadbaf9c7",
            "f8fb30335dfc48a4a96cd1474cc27c77",
            "6d394109fb4e4057a6f00dc71cacb1e2",
            "8aadce0a2378441982f625c879f1c819",
            "b7275c16e30c456eaa4b44e4023f4aa6",
            "6e88ee826c504a47b9fa8ecb6ce10a5a",
            "d08ab0b710274b9ebcfbe635cf7eb6a7",
            "6f73b475c6644bdf9b9087c636b303d4",
            "f49049fd77b646bd8a2cf389012b65df",
            "5b79e8a7a695439d897adf56f4ea97ee",
            "dbc7d136a66e47daa649dc039ea9ea1c",
            "37bad82439b24484b31d68fe44a9dfff",
            "8513a14baf6b40ad94250683681f9fa9",
            "ebf9f90960f84b50bf7a6c005534b2de",
            "d6e8b850e59a42bfb0dd44419b39644a",
            "615bfec5977c41fcb8a319405b7fad40",
            "d20e0c55e71a4218bb6d144bf8ac128e",
            "bee79f8202244796b2523f968721ad5f",
            "87de8c993e554690bfba4e7fe8c6a858",
            "1aebf1e655954f5cb8419772ce2bf5df",
            "090c2834faa84988ad0c5e370e065989",
            "4f7e560839c84df9a17408aa445d27eb",
            "9df24d1407f24d41ba48aa731f97cc03",
            "995ad44805af4be39c8221d95deaf15b",
            "d8f4b7d49a19408f98e5dfee53cd99fa",
            "b69add0700ca42e48c3897b8c1bec08d",
            "9a889208730641f39dcbeb485d664044",
            "91af01a361484ed2982e63a24e6d4b1e",
            "cd76f88eae8543aaa25ce817ac7b96ab",
            "13cf1871967b47ceb9f7cd4fc8e93875",
            "fb618f87c31f481ab5962d591c46b585",
            "0c56756439994412a7bbeae7d51bae86",
            "d2b56234f6db4714841b821a67ee02e1",
            "3842c759c7934185b3289ef5487ed196",
            "59511b35ce0647f78b309e5f58f9a5ff",
            "58eed49664ca4b0c8a586c8f798c1f38",
            "a0deafa352864de68deea4aa6646e7e4",
            "6b7f17a4729747718490e4e79edae415",
            "c2adb888db464c6cbbce752af8669536",
            "ef6582d276194f6b98f9a3602d39b754",
            "26f7396e6cf341f3a2e5384cee99f61c",
            "de78887f25554895a8b6da2fe0d57854",
            "7ebb35bc683e4254b153d523cdec8838",
            "bec834f1923d46b39101312cd7530500",
            "6e7feed5c1724d42b86a2f4905b51d79",
            "4513c74f528a4465b4793616ab5e6ee0",
            "ae22f966715240bfa810fdf40bca654f",
            "67eefa2a3c3a4b318d11887887f2bffc",
            "41c3464c4b7946b7aba8baad2c4b2194",
            "2c9d5645ba6847e8a364769ff3e8d53a",
            "1bb602b169fe47ccb2baca2fa2e284eb",
            "f3943955c20c4622adb33855a6b2b2e5",
            "4fa196780c1f478bb752cfec1c865427",
            "428467850e9d4e7fa8142c4689e4f370",
            "fc00590c52dd488b8f667d51e3039891",
            "122e4d4c64914457a8ada87c234fe40c",
            "448429f569af404bbf162ae3ccec32d4",
            "5770e86c094d4d4f8e3473241495ad3f",
            "7aaba2873c6140b4abefe864c34f0120",
            "324dd3386d7d43e9bb63afcc048d42b0",
            "919e56bd82874eb0963285dd7d520a1d",
            "bc2e184e5cc943a6aa173c9579acfc4b",
            "3488471a0ae548d394dc40c93cf51a3a",
            "6626a52314c8439a8a82c5994a4f4eac",
            "11565bb74a4d4902965b2cb386157f78",
            "2e8df7f17f87442e90066644dc855a6d",
            "1757ed981e834159bde05a810c8b1d00",
            "51d487adffa142e5b4b412c13216c4e3",
            "cc13e815e637486d986f92dbf00ec74b",
            "961cba277876429ca6392916a98a0c6e",
            "195ad42c0e1941ccb35a2baf7ac6697e",
            "25685bc5a39d40bfaccd38243c539841",
            "e76ae1d6fcff4ea5a0ddfbc8af4b5a42",
            "9945d3f1be5a4ba78867888b5d8f5957",
            "b395229599354ce6bdc8eef3bd70f80d",
            "6f30518c50454c9385dfa9867905cc61",
            "f0345518a8c84c11993f9adc93a73c67"
          ]
        },
        "id": "924e90c1",
        "outputId": "341d4c21-34e5-4b91-c1e1-9d1ee1a8c18d"
      },
      "source": [
        "# 2. Create an instance of the BookQA agent to load the updated code\n",
        "agent = BookQA()\n",
        "\n",
        "# 3. Upload a book (replace the path with one of the problematic PDF files)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # Using one of the problematic files\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)\n",
        "\n",
        "# If upload is successful, list sections to confirm processing\n",
        "if agent.chapter_sections:\n",
        "    print(\"\\nBook processed successfully. Listing sections:\")\n",
        "    agent.list_sections()\n",
        "else:\n",
        "    print(\"\\nBook processing failed.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization model loaded.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57f363e20b9b4e4f9cda343a15972250"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c28ea7f95f254ff9b885e7855502618e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8de9e35cc9a4c62b50d3a45a9108762"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6423198a9cc3439399597ab744d9204e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "975b3d8eb02b4c78b23179edadbaf9c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37bad82439b24484b31d68fe44a9dfff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9df24d1407f24d41ba48aa731f97cc03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3842c759c7934185b3289ef5487ed196"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e7feed5c1724d42b86a2f4905b51d79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "122e4d4c64914457a8ada87c234fe40c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1757ed981e834159bde05a810c8b1d00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Transformer model loaded.\n",
            "Models initialized.\n",
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Creating embeddings for 1 sections...\n",
            "FAISS index created.\n",
            "\n",
            "Book processed successfully. Listing sections:\n",
            "Chapters/Sections:\n",
            "1. Introduction/Beginning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99b18539"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully loaded the book and created embeddings. Now, test the `ask_question`, `list_sections`, and `summarize_section` methods to ensure the agent is functional with the loaded book.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeTb4Q58gMU9",
        "outputId": "625e55db-82b9-4267-e751-bfddfb68f33e"
      },
      "source": [
        "# Test the ask_question method\n",
        "question1 = \"What are the main ideas presented in the book?\"\n",
        "answer1 = agent.ask_question(question1)\n",
        "print(f\"\\nQuestion: {question1}\")\n",
        "print(answer1)\n",
        "\n",
        "question2 = \"How to set goals?\"\n",
        "answer2 = agent.ask_question(question2)\n",
        "print(f\"\\nQuestion: {question2}\")\n",
        "print(answer2)\n",
        "\n",
        "# Test the list_sections method (already done in the previous step, but can be repeated)\n",
        "print(\"\\nListing sections again:\")\n",
        "agent.list_sections()\n",
        "\n",
        "# Test the summarize_section method\n",
        "# Assuming there's at least one section, summarize the first one.\n",
        "if agent.chapter_sections:\n",
        "    first_section_key = list(agent.chapter_sections.keys())[0]\n",
        "    print(f\"\\nAttempting to summarize section: {first_section_key}\")\n",
        "    summary = agent.summarize_section(first_section_key)\n",
        "    print(summary)\n",
        "else:\n",
        "    print(\"\\nNo sections available to summarize.\")\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for answer to: 'What are the main ideas presented in the book?'\n",
            "Most relevant section: 'Introduction/Beginning'\n",
            "\n",
            "Question: What are the main ideas presented in the book?\n",
            "Answer: The more reasons you have for \n",
            "achieving your goal (Source: 'Introduction/Beginning', Score: 0.03)\n",
            "Searching for answer to: 'How to set goals?'\n",
            "Most relevant section: 'Introduction/Beginning'\n",
            "\n",
            "Question: How to set goals?\n",
            "Answer: act as if it were impossible to fail (Source: 'Introduction/Beginning', Score: 0.01)\n",
            "\n",
            "Listing sections again:\n",
            "Chapters/Sections:\n",
            "1. Introduction/Beginning\n",
            "\n",
            "Attempting to summarize section: Introduction/Beginning\n",
            "Summarizing section: 'Introduction/Beginning'\n",
            "Splitting section into 68 chunks for summarization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 1/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 2/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 3/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 4/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 5/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 6/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 7/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 8/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 9/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 10/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 11/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 12/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 13/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 14/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 15/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 16/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 17/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 18/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 19/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 20/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 21/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 22/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 23/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 24/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 25/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 26/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 27/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 28/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 29/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 30/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 31/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 32/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 33/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 34/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 35/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 36/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 37/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 38/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 39/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 40/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 41/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 42/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 43/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 44/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 45/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 46/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 47/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 48/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 49/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 50/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 51/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 52/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 53/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 54/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 55/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 56/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 57/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 58/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 59/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 60/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 61/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 62/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 63/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 64/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 65/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 66/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 150, but your input_length is only 131. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 67/68\n",
            "Summarized chunk 68/68\n",
            "Summary of 'Introduction/Beginning':\n",
            "BRIAN TRACY GOAL PLANNER M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R . the great secret of success is that there are no secrets of success .\n",
            "there are no limits on what you can achieve with your life, except the limits you accept in your own mind . you are a potential genius; there is no problem you cannot solve, and no answer you cannot fi nd some- where .\n",
            "Brian Tracy has consulted for more than 1,000 companies and addressed more than 3,000,000 people in 4,000 talks and seminars . he has studied, researched, written and spoken for 30 years in the fi elds of eco- nomics, history, business, philosophy and psychology .\n",
            "nguages speaks to corporate and public audiences on the subjects of Person- al and Professional Development . talks and seminars on Leadership, Selling, Self-Esteem, Goals, Strategy, Creativity and Success Psychology bring about immediate changes .\n",
            "Brian is the president of three companies headquartered in solana beach, California . he is also the President of a private on-line college for business and entre-preneurship .\n",
            "the contents, or parts thereof, may not be reproduced for any purpose without the written permission of Brian Tracy . this goal planner has been designed after more than 25 years of research and practice .\n",
            "you can learn the habits you need to reach Maximum Achievement by practicing continuous goal-setting and daily action planning . bycompleting this planner over the next 31 days, you will develop in yourself habits that will lead you irresistibly onward to a life of success and achievement .\n",
            "NER The purpose of this goal planner is to enable you to decide exactly what you want in every area of your life . you are asked to set priorities on your goals and organize them in order of importance to you .\n",
            "you are asked to think about your major goals based on ten goal-achieving criteria . you will become a more skilled thinker with every word you write, with every idea you generate . self-discipline is required. Continuous action to-ward your goals must take place every day .\n",
            "you learn how to harness the awesome pow- ers of your subconscious and superconscious minds to bring you anything you really want in life . when you have clear, specifi c goals that you are writing and rewriting every day, you trigger these laws into action on your behalf .\n",
            "your outer world of reality will be like your inner world of belief . as you set challenging goals and move toward them, your belief in yourself becomes unshakable . every day, you confi dently expect that every event, positive or negative, has been sent to help move you toward your goals .\n",
            "you can substitute a positive goal for any negative thought that may be holding you back . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "nation will make you an irresistible force of nature . you can be and do and have all kinds of wonderful things . there lies within you a great, untapped potential .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . write out your three most important goals in life right now: 1. 2. 3. 2. How would you spend your time, where would you go, what would you do, if you found out today that you only had six months to live? 2. 3. 4. 5. 5. 3. 3. What have you always wanted to do but been afraid to attempt?\n",
            "ney would you like to be earning? in one year?.................................................$ In two years? ..........................................$ In three years? $ __________ 8. Who else is earning the kind of money you want to earn?\n",
            "written permission of Brian Tracy . 7 10. Career and professional goals: What do you want to be good at? A. B. C. 11. Sport and fi tness goals .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . M A X I M U M A C H I E V E M E N T G O A L P L A N N E R  Brian Tracy.\n",
            "ts, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . what do you think should be your most important goal? Write it out in detail .\n",
            "the people whose help and cooperation I will require are: 1. ________________________________ ______________ . __________ ___________________ ____________ 3. _ _____________.______________ 4. _ _______ ______ . 5. _.________,______________, ____________ _ (______________)______________. .\n",
            "in the right-hand column, organize your goals from #1 = most important to #7 = least important . this will give you a completion of your goals .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . GOAL NUMBER ONE: ACTION STEPS ORDER 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. Organize your action steps in order of importance to achieve your goal, from #1 to #10 .\n",
            "rganize your action steps in the right-hand column in order of importance to achieving your goal, from #1 to #10 . ACTION PLAN – What I will do immediately is: 1. 2. 3. 4. 5. 6. M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy .\n",
            "______________________ 1. Belief: Is it believable and achievable? 3. Write it down: How will you measure success? 4. Analyze: Where are you starting from now? 7. Ask: What major obstacles must you overcome? 9. Key People: Whose assistance or cooperation do you need? 16 10. FINALLY — Write out a detailed plan of accomplishment .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 17 COMMITMENT \"all sorts of things occur to help that would never otherwise have occurred,\" he said .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . GETTING STARTED 1. You are responsible. Develop the habit of goal setting by finishing two pages each day for 31 days .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the number of times I succeed is in direct proportion to the number I can fail and keep on trying.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . M A X I M U M A C H I E V E M E N T G O A L P L A N N E R  Brian Tracy. All rights reserved.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .   2. Daily Goal Setting Exercise — my major defi nite purpose is: 3. Daily Goal Planning Exercise .\n",
            "M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved. the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the successful person always has a number of projects planned, to which he looks forward .\n",
            "ns in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "es as the enemy of success, but it isn’t at all... You can be discouraged by failure — or you can learn from it . so go ahead and make mistakes. make all you can . remember that’s where you’ll fi nd success. on the far side of failure .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the contedence is a powerful factor in prosperity consciousness: self-esteem: believing you can do it, believing you deserve it .\n",
            "nts, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "Joyce Brothers M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved. The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "daily goal setting exercise — my major defi nite purpose is: 3. Daily Goal Setting Exercise — write out plans in longhand using the present tense . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . a questio is a challenge for a man if he is willing to study them and make capital from them .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . it is important to know how to concentrate it, how to husband it and how to focus it on important things .\n",
            "Michael Korda M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved. The contents, or parts thereof, may not be reproduce in any form for any purpose without the written permission of Brian Tracy .\n",
            "ercise — my major defi nite purpose is: 3. Daily Goal Planning Exercise — write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. The fi rst law of success... is concentration — to blend all the energies to one point, and to go directly to that point, looking neither to the right nor to the left .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the giants of the race have been men of concentration, who have struck sledge-hammer blows in one place until they have accomplished their purpose .\n",
            "the contents, or parts thereof, may not be reproduced in any form without the written permission of Brian Tracy . the majority of men meet with failure because of their lack of persistence in creating new plans to take the place of those which fail .\n",
            "M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "rpose is: 3. Daily Goal Planning Exercise . write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. Only you must, then, really wish these things, and wish them exclusively, and not wish a hundred other incompatible things just as strongly .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the contents of the daily goal planning exercise Quick List — my major defi nite purpose is: 3. Daily Goal Setting Exercise — write out plans in longhand using the present tense .\n",
            "48 4. Write your major problem or goal in the form of a question . 5. Write out 20 answers to question number four: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20 .\n",
            "Tom Hopkins M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved. The contents, or parts thereof, may not be reproduce in any form for any purpose without the written permission of Brian Tracy .\n",
            "IDEA FOR TODAY 1. Daily Goal Planning Exercise Quick List . write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. Always try to do something for the other fellow and you will be agreeably surprised how things come your way .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . a y 18 / / DATE BACKGROUND IDEA FOR TODAY 1. Daily Goal Planning Exercise Quick List — your three most important goals:   2. Daily Goal Setting Exercise — write out plans in longhand using the present tense .\n",
            "your major problem or goal in the form of a question is 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 6. Select at least one action from the above exercise to begin immediately: M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R .\n",
            "Bruce Barton M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy. 57 D A Y 20 / / DATE BACKGROUND IDEA FOR TODAY 1.\n",
            "ily Goal Planning Exercise — write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. Expect trouble as an inevitable part of life . when it comes, hold your head high, look it squarely in the eye and say \"I will be bigger than you. You cannot defeat me\"\n",
            "E M E N T G O A L P L A N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 61 D A Y 22 / / DATE BACKGROUND IDEA FOR TODAY 1. Daily Goal Planning Exercise Quick List — your three most important goals .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 62 4. Write your major problem or goal in the form of a question: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20.\n",
            "lf to profi t by your chance, the opportunity will only make you ridiculous . a great occasion is valuable to you just in proportion as you have educated yourself to make use of it .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy. 65 Nothing in the world can take the place of persistence alone is omnipotent .\n",
            "67 There is one thing stronger than all the armies in the world and that is an idea whose time has come . the contents, or parts thereof, may not be reproduced in any form without the written permission of Brian Tracy .\n",
            "A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "al Setting exercise — my major defi nite purpose is: 3. Daily Goal Planning Exercise — write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. M A X I M U M A C H I E V E M E N T G O A L P L A N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy. 72 4. Write your major problem or goal in the form of a question: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 73 The empires of the future are the empire of the mind .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 75 In order to succeed, we must fi rst believe we can .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy. 77 I do not think there is any other quality so essential to success of any kind as the quality of perseverance. it overcome almost everything, even nature.\n",
            "al Planning Exercise — write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy . 79 Progress always involves risk, you can’t steal second base and keep your foot on fi rst .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .   2. Daily Goal Setting Exercise — my major defi nite purpose is: 3. Daily Goal Planning Exercise .\n",
            "81 The establishment of a clear, central purpose or goal in life is the starting point of all success . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "you are an action person, so take action today! it is not what you say, or wish, or hope, or intend... It is only what you do that counts .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the ask_question method\n",
        "question1 = \"What are the main ideas presented in the book?\"\n",
        "answer1 = agent.ask_question(question1)\n",
        "print(f\"\\nQuestion: {question1}\")\n",
        "print(answer1)\n",
        "\n",
        "question2 = \"How to set goals?\"\n",
        "answer2 = agent.ask_question(question2)\n",
        "print(f\"\\nQuestion: {question2}\")\n",
        "print(answer2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7rUHDt9g-ln",
        "outputId": "2f370c5f-1b92-4180-d412-650f75a12bfd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for answer to: 'What are the main ideas presented in the book?'\n",
            "Most relevant section: 'Introduction/Beginning'\n",
            "\n",
            "Question: What are the main ideas presented in the book?\n",
            "Answer: The more reasons you have for \n",
            "achieving your goal (Source: 'Introduction/Beginning', Score: 0.03)\n",
            "Searching for answer to: 'How to set goals?'\n",
            "Most relevant section: 'Introduction/Beginning'\n",
            "\n",
            "Question: How to set goals?\n",
            "Answer: act as if it were impossible to fail (Source: 'Introduction/Beginning', Score: 0.01)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88ccc655"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial error \"setting an array element with a sequence\" occurred during TF-IDF vectorization when processing the provided PDF files.\n",
        "*   This error was resolved by replacing the TF-IDF vectorization approach with Sentence Transformer embeddings for creating text representations.\n",
        "*   The updated `BookQA` class successfully initialized a Sentence Transformer model (`all-MiniLM-L6-v2`) and used it to generate embeddings for the book sections.\n",
        "*   A FAISS index was created using the generated embeddings, enabling efficient semantic search.\n",
        "*   The agent successfully processed the previously problematic PDF file using the new embedding approach.\n",
        "*   Core functionalities, including listing sections, asking questions, and summarizing sections, worked after the update.\n",
        "*   The summarization pipeline produced warnings regarding `max_new_tokens` and `max_length` parameters but completed the task.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The switch from TF-IDF to Sentence Transformer embeddings effectively addressed the array dimension error, suggesting that the issue was related to how TF-IDF handled sequences within the text data extracted from the PDFs.\n",
        "*   Future work could involve addressing the summarization warnings for potentially better control over summary length and exploring more sophisticated text splitting techniques or larger language models for improved QA and summarization quality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29873aec"
      },
      "source": [
        "# Task\n",
        "Explain and fix the \"setting an array element with a sequence\" error occurring during TF-IDF vectorization when processing PDF files \"/content/drive/MyDrive/627260606-chatbotdoc (1).pdf\" and \"/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\". Additionally, modify the provided Python code to include functionality for creating flashcards from the processed book content to aid readers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd5aa316"
      },
      "source": [
        "## Update `bookqa` class with flashcard functionality\n",
        "\n",
        "### Subtask:\n",
        "Add new methods to the `BookQA` class to support flashcard creation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38e4ee4c"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the new methods `create_flashcards`, `_extract_flashcard_content`, and `_format_flashcard` within the `BookQA` class to support flashcard creation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5298723c"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import fitz  # PyMuPDF\n",
        "import nltk\n",
        "import re\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Download necessary NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None # This will be replaced by the embedding model\n",
        "        self.tfidf_matrix = None # This will be replaced by the embeddings\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "        self.embedding_model = None # New attribute for Sentence Transformer model\n",
        "\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "        # Initialize Sentence Transformer model for embeddings\n",
        "        try:\n",
        "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            print(\"Sentence Transformer model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Sentence Transformer model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.embedding_model = None\n",
        "\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Basic text cleaning.\"\"\"\n",
        "        text = text.lower() # Convert to lowercase\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove non-alphanumeric characters except spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        self.chapter_sections = {} # Clear existing sections\n",
        "\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index using Sentence Transformers.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "        if not self.embedding_model:\n",
        "            print(\"Sentence Transformer model not loaded. Cannot vectorize sections.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "\n",
        "        section_texts = list(self.chapter_sections.values())\n",
        "        print(f\"Creating embeddings for {len(section_texts)} sections...\")\n",
        "\n",
        "        try:\n",
        "            # Create embeddings using the Sentence Transformer model\n",
        "            embeddings = self.embedding_model.encode(section_texts, convert_to_numpy=True)\n",
        "            self.tfidf_matrix = embeddings # Store embeddings (renamed from tfidf_matrix)\n",
        "\n",
        "            # Create FAISS index\n",
        "            dimension = embeddings.shape[1]\n",
        "            if dimension > 0:\n",
        "                self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "                self.index.add(embeddings.astype('float32')) # FAISS requires float32\n",
        "                print(\"FAISS index created.\")\n",
        "                # Store the titles corresponding to the vectorized texts for later lookup\n",
        "                self._vectorized_section_titles = list(self.chapter_sections.keys()) # Store original titles\n",
        "            else:\n",
        "                print(\"Embeddings have no dimensions after vectorization. Cannot create FAISS index.\")\n",
        "                self.index = None\n",
        "                self._vectorized_section_titles = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during embedding creation or FAISS index creation: {e}\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            self._vectorized_section_titles = []\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "        if not self.embedding_model or not self.index or not hasattr(self, '_vectorized_section_titles') or not self._vectorized_section_titles:\n",
        "             return \"Book content not vectorized or index not created. Cannot answer questions.\"\n",
        "\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        try:\n",
        "            # Create embedding for the question\n",
        "            question_vec = self.embedding_model.encode([question], convert_to_numpy=True).astype('float32')\n",
        "            D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating question embedding or searching index: {e}\")\n",
        "            return \"Could not process the question for searching.\"\n",
        "\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        # Use the stored vectorized section titles to get the correct title\n",
        "        relevant_section_title = self._vectorized_section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title] # Use original text for QA\n",
        "\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context) # Use original question for QA pipeline\n",
        "            return f\"Answer: {answer['answer']} (Source: '{relevant_section_title}', Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section from '{relevant_section_title}':\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "    def create_flashcards(self, section_identifier=None):\n",
        "        \"\"\"Generates flashcards from the book content, optionally from a specific section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for flashcard creation.\"\n",
        "\n",
        "        sections_to_process = {}\n",
        "        if section_identifier:\n",
        "            section_titles = list(self.chapter_sections.keys())\n",
        "            section_text = None\n",
        "            section_title = None\n",
        "\n",
        "            try:\n",
        "                # Try to find by number (1-based index)\n",
        "                section_index = int(section_identifier) - 1\n",
        "                if 0 <= section_index < len(section_titles):\n",
        "                    section_title = section_titles[section_index]\n",
        "                    section_text = self.chapter_sections[section_title]\n",
        "            except ValueError:\n",
        "                # If not a number, try to find by partial title match\n",
        "                for title in section_titles:\n",
        "                    if section_identifier.lower() in title.lower():\n",
        "                        section_title = title\n",
        "                        section_text = self.chapter_sections[title]\n",
        "                        break\n",
        "\n",
        "            if section_text is None:\n",
        "                return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "            sections_to_process[section_title] = section_text\n",
        "            print(f\"Generating flashcards for section: '{section_title}'\")\n",
        "        else:\n",
        "            sections_to_process = self.chapter_sections\n",
        "            print(\"Generating flashcards for the entire book.\")\n",
        "\n",
        "        all_flashcards = []\n",
        "        for title, text in sections_to_process.items():\n",
        "            flashcards = self._extract_flashcard_content(text)\n",
        "            formatted_flashcards = [self._format_flashcard(fc) for fc in flashcards]\n",
        "            all_flashcards.extend(formatted_flashcards)\n",
        "\n",
        "        if all_flashcards:\n",
        "            print(f\"Generated {len(all_flashcards)} potential flashcards.\")\n",
        "            return all_flashcards\n",
        "        else:\n",
        "            return \"Could not generate any flashcards from the selected content.\"\n",
        "\n",
        "\n",
        "    def _extract_flashcard_content(self, text):\n",
        "        \"\"\"Identifies and extracts potential flashcard material from text.\n",
        "           (Basic implementation: looks for sentences ending with question marks or definitions)\n",
        "        \"\"\"\n",
        "        # This is a very basic approach. More advanced techniques (like using NLP models\n",
        "        # to identify key terms/definitions or question-answer pairs) would be better.\n",
        "        # For demonstration, let's split by sentence and look for simple patterns.\n",
        "\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "        flashcard_candidates = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Simple pattern: sentence ending with a question mark\n",
        "            if sentence.strip().endswith('?'):\n",
        "                # Use the sentence as the front, and try to find a potential answer in the next sentence(s)\n",
        "                front = sentence.strip()\n",
        "                back = \"Answer not found nearby (requires more advanced logic)\" # Placeholder\n",
        "                flashcard_candidates.append({'front': front, 'back': back})\n",
        "\n",
        "            # Simple pattern: looking for \"is a\", \"is the\", \"are\" as potential definitions\n",
        "            # This is highly heuristic and will likely produce many false positives/negatives\n",
        "            definition_match = re.search(r'(.+)\\s+(is a|is the|are)\\s+(.+)\\.', sentence, re.IGNORECASE)\n",
        "            if definition_match:\n",
        "                front = definition_match.group(1).strip() # Term\n",
        "                back = definition_match.group(3).strip() # Definition\n",
        "                flashcard_candidates.append({'front': front, 'back': back})\n",
        "\n",
        "        return flashcard_candidates\n",
        "\n",
        "\n",
        "    def _format_flashcard(self, flashcard_data):\n",
        "        \"\"\"Formats the extracted content into a flashcard structure.\"\"\"\n",
        "        # In this basic implementation, the data is already in the desired format.\n",
        "        # This method serves as a placeholder for more complex formatting if needed.\n",
        "        return flashcard_data\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for study/review.\"\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Create Flashcards (Entire Book)\")\n",
        "        print(\"5. Create Flashcards (Specific Section)\")\n",
        "        print(\"6. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                flashcards = self.create_flashcards()\n",
        "                if isinstance(flashcards, list):\n",
        "                    print(\"\\nGenerated Flashcards:\")\n",
        "                    for i, fc in enumerate(flashcards):\n",
        "                        print(f\"Flashcard {i+1}:\")\n",
        "                        print(f\"  Front: {fc['front']}\")\n",
        "                        print(f\"  Back: {fc['back']}\")\n",
        "                        print(\"-\" * 20)\n",
        "                else:\n",
        "                    print(flashcards) # Print error message\n",
        "            elif choice == '5':\n",
        "                section_input = input(\"Enter the chapter/section number or name to create flashcards from: \")\n",
        "                flashcards = self.create_flashcards(section_input)\n",
        "                if isinstance(flashcards, list):\n",
        "                    print(f\"\\nGenerated Flashcards for '{section_input}':\")\n",
        "                    for i, fc in enumerate(flashcards):\n",
        "                        print(f\"Flashcard {i+1}:\")\n",
        "                        print(f\"  Front: {fc['front']}\")\n",
        "                        print(f\"  Back: {fc['back']}\")\n",
        "                        print(\"-\" * 20)\n",
        "                else:\n",
        "                    print(flashcards) # Print error message\n",
        "            elif choice == '6':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47d8576c"
      },
      "source": [
        "## Implement flashcard content extraction\n",
        "\n",
        "### Subtask:\n",
        "Develop logic within the new methods to extract key terms, concepts, or question-answer pairs from the book text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a42691a8"
      },
      "source": [
        "**Reasoning**:\n",
        "Refine the `_extract_flashcard_content` method to use more advanced NLP techniques and improve the extraction of flashcard front and back content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e531e1e",
        "outputId": "05048ef6-0305-4d9d-edc5-8a1eb6658400"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import fitz\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Download necessary NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
        "except LookupError:\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "try:\n",
        "    nltk.data.find('chunkers/maxent_ne_chunker')\n",
        "except LookupError:\n",
        "    nltk.download('maxent_ne_chunker')\n",
        "try:\n",
        "    nltk.data.find('corpora/words')\n",
        "except LookupError:\n",
        "    nltk.download('words')\n",
        "\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None # This will be replaced by the embedding model\n",
        "        self.tfidf_matrix = None # This will be replaced by the embeddings\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "        self.embedding_model = None # New attribute for Sentence Transformer model\n",
        "\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "        # Initialize Sentence Transformer model for embeddings\n",
        "        try:\n",
        "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            print(\"Sentence Transformer model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Sentence Transformer model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.embedding_model = None\n",
        "\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Basic text cleaning.\"\"\"\n",
        "        text = text.lower() # Convert to lowercase\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove non-alphanumeric characters except spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        self.chapter_sections = {} # Clear existing sections\n",
        "\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index using Sentence Transformers.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "        if not self.embedding_model:\n",
        "            print(\"Sentence Transformer model not loaded. Cannot vectorize sections.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "\n",
        "        section_texts = list(self.chapter_sections.values())\n",
        "        print(f\"Creating embeddings for {len(section_texts)} sections...\")\n",
        "\n",
        "        try:\n",
        "            # Create embeddings using the Sentence Transformer model\n",
        "            embeddings = self.embedding_model.encode(section_texts, convert_to_numpy=True)\n",
        "            self.tfidf_matrix = embeddings # Store embeddings (renamed from tfidf_matrix)\n",
        "\n",
        "            # Create FAISS index\n",
        "            dimension = embeddings.shape[1]\n",
        "            if dimension > 0:\n",
        "                self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "                self.index.add(embeddings.astype('float32')) # FAISS requires float32\n",
        "                print(\"FAISS index created.\")\n",
        "                # Store the titles corresponding to the vectorized texts for later lookup\n",
        "                self._vectorized_section_titles = list(self.chapter_sections.keys()) # Store original titles\n",
        "            else:\n",
        "                print(\"Embeddings have no dimensions after vectorization. Cannot create FAISS index.\")\n",
        "                self.index = None\n",
        "                self._vectorized_section_titles = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during embedding creation or FAISS index creation: {e}\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            self._vectorized_section_titles = []\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "        if not self.embedding_model or not self.index or not hasattr(self, '_vectorized_section_titles') or not self._vectorized_section_titles:\n",
        "             return \"Book content not vectorized or index not created. Cannot answer questions.\"\n",
        "\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        try:\n",
        "            # Create embedding for the question\n",
        "            question_vec = self.embedding_model.encode([question], convert_to_numpy=True).astype('float32')\n",
        "            D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating question embedding or searching index: {e}\")\n",
        "            return \"Could not process the question for searching.\"\n",
        "\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        # Use the stored vectorized section titles to get the correct title\n",
        "        relevant_section_title = self._vectorized_section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title] # Use original text for QA\n",
        "\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context) # Use original question for QA pipeline\n",
        "            return f\"Answer: {answer['answer']} (Source: '{relevant_section_title}', Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section from '{relevant_section_title}':\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "    def create_flashcards(self, section_identifier=None):\n",
        "        \"\"\"Generates flashcards from the book content, optionally from a specific section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for flashcard creation.\"\n",
        "\n",
        "        sections_to_process = {}\n",
        "        if section_identifier:\n",
        "            section_titles = list(self.chapter_sections.keys())\n",
        "            section_text = None\n",
        "            section_title = None\n",
        "\n",
        "            try:\n",
        "                # Try to find by number (1-based index)\n",
        "                section_index = int(section_identifier) - 1\n",
        "                if 0 <= section_index < len(section_titles):\n",
        "                    section_title = section_titles[section_index]\n",
        "                    section_text = self.chapter_sections[section_title]\n",
        "            except ValueError:\n",
        "                # If not a number, try to find by partial title match\n",
        "                for title in section_titles:\n",
        "                    if section_identifier.lower() in title.lower():\n",
        "                        section_title = title\n",
        "                        section_text = self.chapter_sections[title]\n",
        "                        break\n",
        "\n",
        "            if section_text is None:\n",
        "                return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "            sections_to_process[section_title] = section_text\n",
        "            print(f\"Generating flashcards for section: '{section_title}'\")\n",
        "        else:\n",
        "            sections_to_process = self.chapter_sections\n",
        "            print(\"Generating flashcards for the entire book.\")\n",
        "\n",
        "        all_flashcards = []\n",
        "        for title, text in sections_to_process.items():\n",
        "            flashcards = self._extract_flashcard_content(text)\n",
        "            formatted_flashcards = [self._format_flashcard(fc) for fc in flashcards]\n",
        "            all_flashcards.extend(formatted_flashcards)\n",
        "\n",
        "        if all_flashcards:\n",
        "            print(f\"Generated {len(all_flashcards)} potential flashcards.\")\n",
        "            return all_flashcards\n",
        "        else:\n",
        "            return \"Could not generate any flashcards from the selected content.\"\n",
        "\n",
        "\n",
        "    def _extract_flashcard_content(self, text):\n",
        "        \"\"\"Identifies and extracts potential flashcard material from text using NLP.\"\"\"\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "        flashcard_candidates = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Skip very short sentences\n",
        "            if len(sentence.split()) < 5:\n",
        "                continue\n",
        "\n",
        "            # Attempt to extract Question-Answer pairs using the QA pipeline\n",
        "            if self.qa_pipeline:\n",
        "                try:\n",
        "                    # Use the sentence as the context and try to generate a question\n",
        "                    # This is a simplified approach; a dedicated question generation model would be better.\n",
        "                    # For now, let's try to find potential answers and formulate simple questions.\n",
        "                    # A better approach would be to iterate through potential answer spans.\n",
        "                    # Let's use a simple heuristic for now: look for noun phrases as potential answers.\n",
        "                    tokens = nltk.word_tokenize(sentence)\n",
        "                    pos_tags = nltk.pos_tag(tokens)\n",
        "                    # Simple noun phrase chunking\n",
        "                    grammar = \"NP: {<DT>?<JJ>*<NN.*>+}\"\n",
        "                    cp = nltk.RegexpParser(grammar)\n",
        "                    tree = cp.parse(pos_tags)\n",
        "\n",
        "                    potential_answers = []\n",
        "                    for subtree in tree.subtrees():\n",
        "                        if subtree.label() == 'NP':\n",
        "                            potential_answers.append(\" \".join([word for (word, tag) in subtree.leaves()]))\n",
        "\n",
        "                    # For each potential answer, try to formulate a question.\n",
        "                    # This is a placeholder and needs a proper question generation approach.\n",
        "                    for answer in potential_answers:\n",
        "                        # Simple question generation heuristic (very basic)\n",
        "                        # If the sentence contains \"is a\", try \"What is a [term]?\"\n",
        "                        if \" is a \" in sentence.lower() and answer.lower() in sentence.lower():\n",
        "                            term = sentence.lower().split(\" is a \")[0].strip()\n",
        "                            if len(term.split()) < 10: # Avoid very long terms\n",
        "                                flashcard_candidates.append({'front': f\"What is {term}?\", 'back': answer})\n",
        "                                continue # Move to the next potential answer\n",
        "\n",
        "                        # If the sentence contains \"are\", try \"What are [terms]?\"\n",
        "                        if \" are \" in sentence.lower() and answer.lower() in sentence.lower():\n",
        "                             term = sentence.lower().split(\" are \")[0].strip()\n",
        "                             if len(term.split()) < 10: # Avoid very long terms\n",
        "                                flashcard_candidates.append({'front': f\"What are {term}?\", 'back': answer})\n",
        "                                continue # Move to the next potential answer\n",
        "\n",
        "                        # Try a general question using the answer\n",
        "                        # This is highly dependent on the sentence structure\n",
        "                        # A more robust method would involve dependency parsing or a QG model\n",
        "                        if len(answer.split()) > 1 and len(answer.split()) < 10: # Avoid very short/long answers\n",
        "                             # Simple: \"What about [answer]?\" or \"Tell me about [answer]?\"\n",
        "                             flashcard_candidates.append({'front': f\"Explain: {answer}\", 'back': sentence.strip()})\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error during flashcard extraction (NLP): {e}\")\n",
        "\n",
        "\n",
        "            # Basic pattern: sentence ending with a question mark (still include as a fallback)\n",
        "            if sentence.strip().endswith('?'):\n",
        "                 front = sentence.strip()\n",
        "                 # Try to find a short answer in the following sentence(s)\n",
        "                 answer_found = False\n",
        "                 for i, next_sentence in enumerate(sentences[sentences.index(sentence)+1:]):\n",
        "                     if len(next_sentence.split()) < 20: # Consider relatively short sentences as potential answers\n",
        "                         back = next_sentence.strip()\n",
        "                         flashcard_candidates.append({'front': front, 'back': back})\n",
        "                         answer_found = True\n",
        "                         break\n",
        "                     if i > 2: # Don't look too far ahead\n",
        "                         break\n",
        "                 if not answer_found:\n",
        "                      flashcard_candidates.append({'front': front, 'back': \"Answer not found nearby (requires more advanced logic)\"}) # Placeholder\n",
        "\n",
        "\n",
        "        return flashcard_candidates\n",
        "\n",
        "\n",
        "    def _format_flashcard(self, flashcard_data):\n",
        "        \"\"\"Formats the extracted content into a flashcard structure.\"\"\"\n",
        "        # In this basic implementation, the data is already in the desired format.\n",
        "        # This method serves as a placeholder for more complex formatting if needed.\n",
        "        return flashcard_data\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for study/review.\"\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Create Flashcards (Entire Book)\")\n",
        "        print(\"5. Create Flashcards (Specific Section)\")\n",
        "        print(\"6. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                flashcards = self.create_flashcards()\n",
        "                if isinstance(flashcards, list):\n",
        "                    print(\"\\nGenerated Flashcards:\")\n",
        "                    for i, fc in enumerate(flashcards):\n",
        "                        print(f\"Flashcard {i+1}:\")\n",
        "                        print(f\"  Front: {fc['front']}\")\n",
        "                        print(f\"  Back: {fc['back']}\")\n",
        "                        print(\"-\" * 20)\n",
        "                else:\n",
        "                    print(flashcards) # Print error message\n",
        "            elif choice == '5':\n",
        "                section_input = input(\"Enter the chapter/section number or name to create flashcards from: \")\n",
        "                flashcards = self.create_flashcards(section_input)\n",
        "                if isinstance(flashcards, list):\n",
        "                    print(f\"\\nGenerated Flashcards for '{section_input}':\")\n",
        "                    for i, fc in enumerate(flashcards):\n",
        "                        print(f\"Flashcard {i+1}:\")\n",
        "                        print(f\"  Front: {fc['front']}\")\n",
        "                        print(f\"  Back: {fc['back']}\")\n",
        "                        print(\"-\" * 20)\n",
        "                else:\n",
        "                    print(flashcards) # Print error message\n",
        "            elif choice == '6':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c214509"
      },
      "source": [
        "**Reasoning**:\n",
        "The `_extract_flashcard_content` method is updated to use more sophisticated NLP techniques for extracting flashcard content. The next step is to test this updated method by creating flashcards from a loaded book to verify if the extraction logic works as expected.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r8lw863_px6w",
        "outputId": "c54e1745-9d95-49d3-8cad-e5db2991465c"
      },
      "source": [
        "# Create an instance of the BookQA agent to load the updated code\n",
        "agent = BookQA()\n",
        "\n",
        "# Upload a book to test flashcard creation\n",
        "# Use the same book path as before, assuming it loaded successfully in previous steps\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf'\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)\n",
        "\n",
        "# If upload is successful, create flashcards from the first section\n",
        "if agent.chapter_sections:\n",
        "    first_section_key = list(agent.chapter_sections.keys())[0]\n",
        "    print(f\"\\nAttempting to create flashcards from section: {first_section_key}\")\n",
        "    flashcards = agent.create_flashcards(first_section_key)\n",
        "\n",
        "    if isinstance(flashcards, list):\n",
        "        print(\"\\nGenerated Flashcards:\")\n",
        "        for i, fc in enumerate(flashcards):\n",
        "            print(f\"Flashcard {i+1}:\")\n",
        "            print(f\"  Front: {fc['front']}\")\n",
        "            print(f\"  Back: {fc['back']}\")\n",
        "            print(\"-\" * 20)\n",
        "    else:\n",
        "        print(flashcards) # Print error message\n",
        "else:\n",
        "    print(\"\\nBook processing failed. Cannot create flashcards.\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization model loaded.\n",
            "Sentence Transformer model loaded.\n",
            "Models initialized.\n",
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Creating embeddings for 1 sections...\n",
            "FAISS index created.\n",
            "\n",
            "Attempting to create flashcards from section: Introduction/Beginning\n",
            "Generating flashcards for section: 'Introduction/Beginning'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-45-1021560231.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfirst_section_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchapter_sections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nAttempting to create flashcards from section: {first_section_key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mflashcards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_flashcards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_section_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflashcards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-44-2228653498.py\u001b[0m in \u001b[0;36mcreate_flashcards\u001b[0;34m(self, section_identifier)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mall_flashcards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msections_to_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mflashcards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_flashcard_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0mformatted_flashcards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_flashcard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflashcards\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mall_flashcards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_flashcards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-44-2228653498.py\u001b[0m in \u001b[0;36m_extract_flashcard_content\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_flashcard_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;34m\"\"\"Identifies and extracts potential flashcard material from text using NLP.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mflashcard_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_punkt_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPunktTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mPunktSentenceTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mload_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mlang_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt_tab/{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_punkt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba6fa400"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback indicates a `LookupError` because the `punkt_tab` resource is not found. Although `punkt` was downloaded previously, `punkt_tab` seems to be a separate requirement for sentence tokenization in this context. The next step is to download the `punkt_tab` resource using `nltk.download()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0HcZKXVp2Ii",
        "outputId": "21745de4-6ddf-4eba-b9c3-3d5f0ff2ab58"
      },
      "source": [
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6de8a47c"
      },
      "source": [
        "**Reasoning**:\n",
        "The `punkt_tab` resource has been downloaded. Now, re-initialize the BookQA agent and attempt to create flashcards again to see if the `LookupError` is resolved and the flashcard extraction proceeds.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH6Hevrpp4-A",
        "outputId": "365d22f6-f083-478e-ec93-0552650b26e5"
      },
      "source": [
        "# Create an instance of the BookQA agent to load the updated code\n",
        "agent = BookQA()\n",
        "\n",
        "# Upload a book to test flashcard creation\n",
        "# Use the same book path as before, assuming it loaded successfully in previous steps\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf'\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)\n",
        "\n",
        "# If upload is successful, create flashcards from the first section\n",
        "if agent.chapter_sections:\n",
        "    first_section_key = list(agent.chapter_sections.keys())[0]\n",
        "    print(f\"\\nAttempting to create flashcards from section: {first_section_key}\")\n",
        "    flashcards = agent.create_flashcards(first_section_key)\n",
        "\n",
        "    if isinstance(flashcards, list):\n",
        "        print(\"\\nGenerated Flashcards:\")\n",
        "        for i, fc in enumerate(flashcards):\n",
        "            print(f\"Flashcard {i+1}:\")\n",
        "            print(f\"  Front: {fc['front']}\")\n",
        "            print(f\"  Back: {fc['back']}\")\n",
        "            print(\"-\" * 20)\n",
        "    else:\n",
        "        print(flashcards) # Print error message\n",
        "else:\n",
        "    print(\"\\nBook processing failed. Cannot create flashcards.\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Error during flashcard extraction (NLP): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Generated 37 potential flashcards.\n",
            "\n",
            "Generated Flashcards:\n",
            "Flashcard 1:\n",
            "  Front: In each case the question you ask yourself is: “What do I really want?\n",
            "  Back: You \n",
            "are asked to rewrite your goals every day, and make plans for their accomplishment.\n",
            "--------------------\n",
            "Flashcard 2:\n",
            "  Front: How would you spend your time, where would you go, what would you do, if \n",
            "you found out today that you only had six months to live?\n",
            "  Back: 1.\n",
            "--------------------\n",
            "Flashcard 3:\n",
            "  Front: What would you do differently if you won one million dollars cash, tax free, \n",
            "tomorrow?\n",
            "  Back: 1.\n",
            "--------------------\n",
            "Flashcard 4:\n",
            "  Front: What have you always wanted to do but been afraid to attempt?\n",
            "  Back: 1.\n",
            "--------------------\n",
            "Flashcard 5:\n",
            "  Front: What do you enjoy doing most in life?\n",
            "  Back: If you could engage in any full-time \n",
            "activity, without pay, what would it be?\n",
            "--------------------\n",
            "Flashcard 6:\n",
            "  Front: If you could engage in any full-time \n",
            "activity, without pay, what would it be?\n",
            "  Back: 1.\n",
            "--------------------\n",
            "Flashcard 7:\n",
            "  Front: How much money would you like to be earning?\n",
            "  Back: In one year?\n",
            "--------------------\n",
            "Flashcard 8:\n",
            "  Front: ................................................................................$\n",
            " \n",
            "In ﬁ ve years?\n",
            "  Back: .................................................................................$\n",
            "7.\n",
            "--------------------\n",
            "Flashcard 9:\n",
            "  Front: How much do you want to be worth when you retire?\n",
            "  Back: ............... $ __________\n",
            "8. \n",
            "Who else is earning the kind of money you want to earn?\n",
            "--------------------\n",
            "Flashcard 10:\n",
            "  Front: ............... $ __________\n",
            "8. \n",
            "Who else is earning the kind of money you want to earn?\n",
            "  Back: 1.\n",
            "--------------------\n",
            "Flashcard 11:\n",
            "  Front: What is he/she doing differently from you that enables him/her to earn this \n",
            "kind of money?\n",
            "  Back: 1.\n",
            "--------------------\n",
            "Flashcard 12:\n",
            "  Front: Career and professional goals: What do you want to be good at?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 13:\n",
            "  Front: Sport and ﬁ tness goals: What do you want to achieve physically?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 14:\n",
            "  Front: Personal development goals: In what areas do you want to improve?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 15:\n",
            "  Front: Family and relationship goals: What do you want to do for your family?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 16:\n",
            "  Front: Travel goals — places to visit/vacations: Where do you want to go?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 17:\n",
            "  Front: Material and tangible goals (things): What do you want to acquire?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 18:\n",
            "  Front: Community and service goals: How do you want to contribute?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 19:\n",
            "  Front: Creative goals: What do you want to bring into reality?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 20:\n",
            "  Front: Spiritual and inner development goals: What kind of a person do you want to \n",
            "become?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 21:\n",
            "  Front: Intellectual and educational goals: What do you want to learn?\n",
            "  Back: A.\n",
            "--------------------\n",
            "Flashcard 22:\n",
            "  Front: What one great thing would you dare to dream if you knew you could not \n",
            "fail?\n",
            "  Back: If you were guaranteed of success?\n",
            "--------------------\n",
            "Flashcard 23:\n",
            "  Front: If you were guaranteed of success?\n",
            "  Back: All rights reserved.\n",
            "--------------------\n",
            "Flashcard 24:\n",
            "  Front: If you could have any one goal on this list within 24 hours, which one goal \n",
            "would you choose?\n",
            "  Back: All rights reserved.\n",
            "--------------------\n",
            "Flashcard 25:\n",
            "  Front: Based on these exercises, what do you think should be your most important \n",
            "goal?\n",
            "  Back: Your major deﬁ nite purpose?\n",
            "--------------------\n",
            "Flashcard 26:\n",
            "  Front: Your major deﬁ nite purpose?\n",
            "  Back: Write it out in detail.\n",
            "--------------------\n",
            "Flashcard 27:\n",
            "  Front: Desire: How much do you really want it on a scale of 1 - 10?\n",
            "  Back: _______________\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 28:\n",
            "  Front: Belief: Is it believable and achievable?\n",
            "  Back: 3.\n",
            "--------------------\n",
            "Flashcard 29:\n",
            "  Front: Write it down: How will you measure success?\n",
            "  Back: __________________________\n",
            "4.\n",
            "--------------------\n",
            "Flashcard 30:\n",
            "  Front: Analyze: Where are you starting from now?\n",
            "  Back: 5.\n",
            "--------------------\n",
            "Flashcard 31:\n",
            "  Front: Determine Why : How will you personally beneﬁ t from achieving it?\n",
            "  Back: ________\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 32:\n",
            "  Front: Ask: What major obstacles must you overcome?\n",
            "  Back: _____________________________\n",
            "8.\n",
            "--------------------\n",
            "Flashcard 33:\n",
            "  Front: Research: What additional information, knowledge and skills will you require?\n",
            "  Back: 9.\n",
            "--------------------\n",
            "Flashcard 34:\n",
            "  Front: Key People: Whose assistance or cooperation do you need?\n",
            "  Back: All rights reserved.\n",
            "--------------------\n",
            "Flashcard 35:\n",
            "  Front: Write it out clearly; what are you going to do, starting today, \n",
            "and every day?\n",
            "  Back: The more detailed your description, the more likely it is that you \n",
            "will achieve it!\n",
            "--------------------\n",
            "Flashcard 36:\n",
            "  Front: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "  Back: Seek this very minute, whatever you can do, \n",
            "or dream you can; begin it.\n",
            "--------------------\n",
            "Flashcard 37:\n",
            "  Front: 27\n",
            "Would you like me to give you a formula for… success?\n",
            "  Back: It’s quite simple, really.\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2daa0f3"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback shows repeated `LookupError` for the resource `averaged_perceptron_tagger_eng`. Although `averaged_perceptron_tagger` was downloaded, the error specifically requests `averaged_perceptron_tagger_eng`. It seems this specific English version is needed. The next step is to download this resource.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iN3mLOUp--C",
        "outputId": "1b75877a-216d-4fff-ecce-594ac14655ef"
      },
      "source": [
        "try:\n",
        "    nltk.data.find('taggers/averaged_perceptron_tagger_eng')\n",
        "except LookupError:\n",
        "    nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8b88242"
      },
      "source": [
        "**Reasoning**:\n",
        "The required NLTK resources (`punkt`, `averaged_perceptron_tagger`, `maxent_ne_chunker`, `words`, `punkt_tab`, and `averaged_perceptron_tagger_eng`) have been downloaded. Now, re-initialize the BookQA agent with the updated flashcard extraction logic and attempt to create flashcards again to see if the NLP processes run without errors and generate flashcards.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsQQYLQiqBjv",
        "outputId": "156e7358-1c3b-4720-da71-ff750ef3fc2a"
      },
      "source": [
        "# Create an instance of the BookQA agent to load the updated code\n",
        "agent = BookQA()\n",
        "\n",
        "# Upload a book to test flashcard creation\n",
        "# Use the same book path as before, assuming it loaded successfully in previous steps\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf'\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)\n",
        "\n",
        "# If upload is successful, create flashcards from the first section\n",
        "if agent.chapter_sections:\n",
        "    first_section_key = list(agent.chapter_sections.keys())[0]\n",
        "    print(f\"\\nAttempting to create flashcards from section: {first_section_key}\")\n",
        "    flashcards = agent.create_flashcards(first_section_key)\n",
        "\n",
        "    if isinstance(flashcards, list):\n",
        "        print(\"\\nGenerated Flashcards:\")\n",
        "        for i, fc in enumerate(flashcards):\n",
        "            print(f\"Flashcard {i+1}:\")\n",
        "            print(f\"  Front: {fc['front']}\")\n",
        "            print(f\"  Back: {fc['back']}\")\n",
        "            print(\"-\" * 20)\n",
        "    else:\n",
        "        print(flashcards) # Print error message\n",
        "else:\n",
        "    print(\"\\nBook processing failed. Cannot create flashcards.\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1092:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1093:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1094:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1095:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1096:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1097:\n",
            "  Front: Explain: D A Y\n",
            "  Back: 53\n",
            "D A Y\n",
            "18\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1098:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: 53\n",
            "D A Y\n",
            "18\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1099:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1100:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1101:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1102:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1103:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1104:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1105:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1106:\n",
            "  Front: Explain: No man\n",
            "  Back: No man has come to true greatness who has not felt that his life belongs to his race, \n",
            "that which God gives to him, he gives to mankind.\n",
            "--------------------\n",
            "Flashcard 1107:\n",
            "  Front: Explain: true greatness\n",
            "  Back: No man has come to true greatness who has not felt that his life belongs to his race, \n",
            "that which God gives to him, he gives to mankind.\n",
            "--------------------\n",
            "Flashcard 1108:\n",
            "  Front: Explain: life belongs\n",
            "  Back: No man has come to true greatness who has not felt that his life belongs to his race, \n",
            "that which God gives to him, he gives to mankind.\n",
            "--------------------\n",
            "Flashcard 1109:\n",
            "  Front: Explain: — Phillips Brooks M A X\n",
            "  Back: — Phillips Brooks\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1110:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: — Phillips Brooks\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1111:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1112:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1113:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1114:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1115:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1116:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1117:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1118:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1119:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1120:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1121:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1122:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1123:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1124:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1125:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1126:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1127:\n",
            "  Front: Explain: D A Y\n",
            "  Back: 55\n",
            "D A Y\n",
            "19\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1128:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: 55\n",
            "D A Y\n",
            "19\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1129:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1130:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1131:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1132:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1133:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1134:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1135:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1136:\n",
            "  Front: Explain: Nothing splendid\n",
            "  Back: Nothing splendid has ever been achieved except by those who dared believe that \n",
            "something inside of them was superior to circumstance.\n",
            "--------------------\n",
            "Flashcard 1137:\n",
            "  Front: Explain: — Bruce Barton M A X\n",
            "  Back: — Bruce Barton\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1138:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: — Bruce Barton\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1139:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1140:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1141:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1142:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1143:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1144:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1145:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1146:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1147:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1148:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1149:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1150:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1151:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1152:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1153:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1154:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1155:\n",
            "  Front: Explain: D A Y\n",
            "  Back: 57\n",
            "D A Y\n",
            "20\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1156:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: 57\n",
            "D A Y\n",
            "20\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1157:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1158:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1159:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1160:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1161:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1162:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1163:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1164:\n",
            "  Front: Explain: the single-most\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 1165:\n",
            "  Front: Explain: useful bit\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 1166:\n",
            "  Front: Explain: all humanity\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 1167:\n",
            "  Front: Explain: an inevitable part\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 1168:\n",
            "  Front: Explain: the eye\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 1169:\n",
            "  Front: Explain: me. ” — Ann Landers M A X\n",
            "  Back: You cannot defeat me.” — Ann Landers\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1170:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: You cannot defeat me.” — Ann Landers\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1171:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1172:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1173:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1174:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1175:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1176:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1177:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1178:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1179:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1180:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1181:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1182:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1183:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1184:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1185:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1186:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1187:\n",
            "  Front: Explain: D A Y\n",
            "  Back: 59\n",
            "D A Y\n",
            "21\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1188:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: 59\n",
            "D A Y\n",
            "21\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1189:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1190:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1191:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1192:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1193:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1194:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1195:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1196:\n",
            "  Front: Explain: The person\n",
            "  Back: The person determined to achieve maximum success learns the principle that progress \n",
            "is made one step at a time.\n",
            "--------------------\n",
            "Flashcard 1197:\n",
            "  Front: Explain: maximum success\n",
            "  Back: The person determined to achieve maximum success learns the principle that progress \n",
            "is made one step at a time.\n",
            "--------------------\n",
            "Flashcard 1198:\n",
            "  Front: Explain: the principle\n",
            "  Back: The person determined to achieve maximum success learns the principle that progress \n",
            "is made one step at a time.\n",
            "--------------------\n",
            "Flashcard 1199:\n",
            "  Front: Explain: a time\n",
            "  Back: The person determined to achieve maximum success learns the principle that progress \n",
            "is made one step at a time.\n",
            "--------------------\n",
            "Flashcard 1200:\n",
            "  Front: Explain: A house\n",
            "  Back: A house is built a brick at a time.\n",
            "--------------------\n",
            "Flashcard 1201:\n",
            "  Front: Explain: a brick\n",
            "  Back: A house is built a brick at a time.\n",
            "--------------------\n",
            "Flashcard 1202:\n",
            "  Front: Explain: a time\n",
            "  Back: A house is built a brick at a time.\n",
            "--------------------\n",
            "Flashcard 1203:\n",
            "  Front: What are football games?\n",
            "  Back: Football games\n",
            "--------------------\n",
            "Flashcard 1204:\n",
            "  Front: What are football games?\n",
            "  Back: a play\n",
            "--------------------\n",
            "Flashcard 1205:\n",
            "  Front: What are football games?\n",
            "  Back: a time\n",
            "--------------------\n",
            "Flashcard 1206:\n",
            "  Front: Explain: A department store grows\n",
            "  Back: A department store grows bigger one customer at a time.\n",
            "--------------------\n",
            "Flashcard 1207:\n",
            "  Front: Explain: a time\n",
            "  Back: A department store grows bigger one customer at a time.\n",
            "--------------------\n",
            "Flashcard 1208:\n",
            "  Front: Explain: Every big accomplishment\n",
            "  Back: Every big \n",
            "accomplishment is a series of little accomplishments.\n",
            "--------------------\n",
            "Flashcard 1209:\n",
            "  Front: What is every big \n",
            "accomplishment?\n",
            "  Back: a series\n",
            "--------------------\n",
            "Flashcard 1210:\n",
            "  Front: What is every big \n",
            "accomplishment?\n",
            "  Back: little accomplishments\n",
            "--------------------\n",
            "Flashcard 1211:\n",
            "  Front: Explain: — David Joseph Schwartz M A X\n",
            "  Back: — David Joseph Schwartz\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1212:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: — David Joseph Schwartz\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1213:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1214:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1215:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1216:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1217:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1218:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1219:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1220:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1221:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1222:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1223:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1224:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1225:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1226:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1227:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1228:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1229:\n",
            "  Front: Explain: D A Y\n",
            "  Back: 61\n",
            "D A Y\n",
            "22\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1230:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: 61\n",
            "D A Y\n",
            "22\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1231:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1232:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1233:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1234:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1235:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1236:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1237:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1238:\n",
            "  Front: Explain: no road\n",
            "  Back: There is no road too long to the man who advances deliberately and without \n",
            "undue haste;  there are no honors too distant to the man who prepares himself \n",
            "for them with patience.\n",
            "--------------------\n",
            "Flashcard 1239:\n",
            "  Front: Explain: the man\n",
            "  Back: There is no road too long to the man who advances deliberately and without \n",
            "undue haste;  there are no honors too distant to the man who prepares himself \n",
            "for them with patience.\n",
            "--------------------\n",
            "Flashcard 1240:\n",
            "  Front: Explain: undue haste\n",
            "  Back: There is no road too long to the man who advances deliberately and without \n",
            "undue haste;  there are no honors too distant to the man who prepares himself \n",
            "for them with patience.\n",
            "--------------------\n",
            "Flashcard 1241:\n",
            "  Front: Explain: no honors\n",
            "  Back: There is no road too long to the man who advances deliberately and without \n",
            "undue haste;  there are no honors too distant to the man who prepares himself \n",
            "for them with patience.\n",
            "--------------------\n",
            "Flashcard 1242:\n",
            "  Front: Explain: the man\n",
            "  Back: There is no road too long to the man who advances deliberately and without \n",
            "undue haste;  there are no honors too distant to the man who prepares himself \n",
            "for them with patience.\n",
            "--------------------\n",
            "Flashcard 1243:\n",
            "  Front: Explain: — Jean De La Bruy M A X\n",
            "  Back: — Jean De La Bruy\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1244:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: — Jean De La Bruy\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1245:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1246:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1247:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1248:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1249:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1250:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1251:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1252:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1253:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1254:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1255:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1256:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1257:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1258:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1259:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1260:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1261:\n",
            "  Front: Explain: the opportunity\n",
            "  Back: 63\n",
            "Unless you have prepared yourself to proﬁ t by your chance, the opportunity will only \n",
            "make you ridiculous.\n",
            "--------------------\n",
            "Flashcard 1262:\n",
            "  Front: Explain: A great occasion\n",
            "  Back: A great occasion is valuable to you just in proportion as you \n",
            "have educated yourself to make use of it.\n",
            "--------------------\n",
            "Flashcard 1263:\n",
            "  Front: Explain: — Orison Swett Marden D A Y\n",
            "  Back: — Orison Swett Marden\n",
            "D A Y\n",
            "23\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1264:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: — Orison Swett Marden\n",
            "D A Y\n",
            "23\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1265:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1266:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1267:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1268:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1269:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1270:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1271:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1272:\n",
            "  Front: Explain: M A X\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1273:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1274:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1275:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1276:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1277:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1278:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1279:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1280:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1281:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1282:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1283:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1284:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1285:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1286:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1287:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1288:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1289:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1290:\n",
            "  Front: Explain: the world\n",
            "  Back: 65\n",
            "Nothing in the world can take the place of persistence.\n",
            "--------------------\n",
            "Flashcard 1291:\n",
            "  Front: Explain: the place\n",
            "  Back: 65\n",
            "Nothing in the world can take the place of persistence.\n",
            "--------------------\n",
            "Flashcard 1292:\n",
            "  Front: Explain: — Calvin Coolidge D A Y\n",
            "  Back: — Calvin Coolidge\n",
            "D A Y\n",
            "24\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1293:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: — Calvin Coolidge\n",
            "D A Y\n",
            "24\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1294:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1295:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1296:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1297:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1298:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1299:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1300:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1301:\n",
            "  Front: Explain: M A X\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1302:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1303:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1304:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1305:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1306:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1307:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1308:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1309:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1310:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1311:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1312:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1313:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1314:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1315:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1316:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1317:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1318:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1319:\n",
            "  Front: Explain: the armies\n",
            "  Back: 67\n",
            "There is one thing stronger than all the armies in the world and that is an idea \n",
            "whose time has come.\n",
            "--------------------\n",
            "Flashcard 1320:\n",
            "  Front: Explain: the world\n",
            "  Back: 67\n",
            "There is one thing stronger than all the armies in the world and that is an idea \n",
            "whose time has come.\n",
            "--------------------\n",
            "Flashcard 1321:\n",
            "  Front: Explain: an idea\n",
            "  Back: 67\n",
            "There is one thing stronger than all the armies in the world and that is an idea \n",
            "whose time has come.\n",
            "--------------------\n",
            "Flashcard 1322:\n",
            "  Front: Explain: — Victor Hugo D A Y\n",
            "  Back: — Victor Hugo\n",
            "D A Y\n",
            "25\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1323:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: — Victor Hugo\n",
            "D A Y\n",
            "25\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1324:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1325:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1326:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1327:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1328:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1329:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1330:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1331:\n",
            "  Front: Explain: M A X\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1332:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1333:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1334:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1335:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1336:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1337:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1338:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1339:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1340:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1341:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1342:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1343:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1344:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1345:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1346:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1347:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1348:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1349:\n",
            "  Front: Explain: true —\n",
            "  Back: 69\n",
            "All our dreams come true — if we have the courage\n",
            "to pursue them.\n",
            "--------------------\n",
            "Flashcard 1350:\n",
            "  Front: Explain: the courage\n",
            "  Back: 69\n",
            "All our dreams come true — if we have the courage\n",
            "to pursue them.\n",
            "--------------------\n",
            "Flashcard 1351:\n",
            "  Front: Explain: — Walt Disney D A Y\n",
            "  Back: — Walt Disney\n",
            "D A Y\n",
            "26\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1352:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: — Walt Disney\n",
            "D A Y\n",
            "26\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1353:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1354:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1355:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1356:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1357:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1358:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1359:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1360:\n",
            "  Front: Explain: M A X\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1361:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1362:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1363:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1364:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1365:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1366:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1367:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1368:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1369:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1370:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1371:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1372:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1373:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1374:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1375:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1376:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1377:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1378:\n",
            "  Front: Explain: The quality\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 1379:\n",
            "  Front: Explain: a person ’ s life\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 1380:\n",
            "  Front: Explain: direct proportion\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 1381:\n",
            "  Front: Explain: chosen ﬁ eld\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 1382:\n",
            "  Front: Explain: — Vincent T. Lombardi D A Y\n",
            "  Back: — Vincent T. Lombardi\n",
            "D A Y\n",
            "27\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1383:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: — Vincent T. Lombardi\n",
            "D A Y\n",
            "27\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1384:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1385:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1386:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1387:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1388:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1389:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1390:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1391:\n",
            "  Front: Explain: M A X\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1392:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1393:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1394:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1395:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1396:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1397:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1398:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1399:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1400:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1401:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1402:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1403:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1404:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1405:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1406:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1407:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1408:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1409:\n",
            "  Front: What are 73\n",
            "the empires of the future?\n",
            "  Back: The empires\n",
            "--------------------\n",
            "Flashcard 1410:\n",
            "  Front: What are 73\n",
            "the empires of the future?\n",
            "  Back: the future\n",
            "--------------------\n",
            "Flashcard 1411:\n",
            "  Front: What are 73\n",
            "the empires of the future?\n",
            "  Back: the empires\n",
            "--------------------\n",
            "Flashcard 1412:\n",
            "  Front: What are 73\n",
            "the empires of the future?\n",
            "  Back: the mind\n",
            "--------------------\n",
            "Flashcard 1413:\n",
            "  Front: Explain: — Winston Churchill D A Y\n",
            "  Back: — Winston Churchill\n",
            "D A Y\n",
            "28\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1414:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: — Winston Churchill\n",
            "D A Y\n",
            "28\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1415:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1416:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1417:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1418:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1419:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1420:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1421:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1422:\n",
            "  Front: Explain: M A X\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1423:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1424:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1425:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1426:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1427:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1428:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1429:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1430:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1431:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1432:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1433:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1434:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1435:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1436:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1437:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1438:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1439:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1440:\n",
            "  Front: Explain: — Michael Korda D A Y\n",
            "  Back: — Michael Korda\n",
            "D A Y\n",
            "29\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1441:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: — Michael Korda\n",
            "D A Y\n",
            "29\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1442:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1443:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1444:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1445:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1446:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1447:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1448:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1449:\n",
            "  Front: Explain: M A X\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1450:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1451:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1452:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1453:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1454:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1455:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1456:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1457:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1458:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1459:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1460:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1461:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1462:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1463:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1464:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1465:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1466:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1467:\n",
            "  Front: Explain: any other quality\n",
            "  Back: 77\n",
            "I do not think there is any other quality so essential to success of any kind as \n",
            "the quality of perseverance.\n",
            "--------------------\n",
            "Flashcard 1468:\n",
            "  Front: Explain: any kind\n",
            "  Back: 77\n",
            "I do not think there is any other quality so essential to success of any kind as \n",
            "the quality of perseverance.\n",
            "--------------------\n",
            "Flashcard 1469:\n",
            "  Front: Explain: the quality\n",
            "  Back: 77\n",
            "I do not think there is any other quality so essential to success of any kind as \n",
            "the quality of perseverance.\n",
            "--------------------\n",
            "Flashcard 1470:\n",
            "  Front: Explain: — John D. Rockefeller D A Y\n",
            "  Back: — John D. Rockefeller\n",
            "D A Y\n",
            "30\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1471:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: — John D. Rockefeller\n",
            "D A Y\n",
            "30\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1472:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1473:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1474:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1475:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1476:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1477:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1478:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1479:\n",
            "  Front: Explain: M A X\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1480:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1481:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1482:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1483:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1484:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1485:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1486:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1487:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1488:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1489:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1490:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1491:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1492:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1493:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1494:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1495:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1496:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1497:\n",
            "  Front: Explain: t steal second base\n",
            "  Back: 79\n",
            "Progress always involves risk, you can’t steal second base and\n",
            "keep your foot on ﬁ rst.\n",
            "--------------------\n",
            "Flashcard 1498:\n",
            "  Front: Explain: ﬁ rst\n",
            "  Back: 79\n",
            "Progress always involves risk, you can’t steal second base and\n",
            "keep your foot on ﬁ rst.\n",
            "--------------------\n",
            "Flashcard 1499:\n",
            "  Front: Explain: — Frederick Wilcox D A Y\n",
            "  Back: — Frederick Wilcox\n",
            "D A Y\n",
            "31\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1500:\n",
            "  Front: Explain: / / DATE BACKGROUND IDEA FOR TODAY\n",
            "  Back: — Frederick Wilcox\n",
            "D A Y\n",
            "31\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1501:\n",
            "  Front: Explain: Daily Goal Planning Exercise Quick List —\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1502:\n",
            "  Front: Explain: important goals\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1503:\n",
            "  Front: Explain: ■ ■\n",
            "  Back: Daily Goal Planning Exercise Quick List — your three most important goals:\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            " \n",
            "■\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 1504:\n",
            "  Front: Explain: Daily Goal Setting Exercise —\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1505:\n",
            "  Front: Explain: major deﬁ\n",
            "  Back: Daily Goal Setting Exercise — my major deﬁ nite purpose is:\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 1506:\n",
            "  Front: Explain: Daily Goal Planning Exercise —\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1507:\n",
            "  Front: Explain: the present tense\n",
            "  Back: Daily Goal Planning Exercise — write out plans in longhand using the \n",
            "present tense:\n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 1508:\n",
            "  Front: Explain: M A X\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1509:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1510:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1511:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1512:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1513:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1514:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1515:\n",
            "  Front: Explain: major problem\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1516:\n",
            "  Front: Explain: the form\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1517:\n",
            "  Front: Explain: a question\n",
            "  Back: Write your major problem or goal in the form of a question:\n",
            "5.\n",
            "--------------------\n",
            "Flashcard 1518:\n",
            "  Front: Explain: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1519:\n",
            "  Front: Explain: A X\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1520:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1521:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1522:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1523:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1524:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1525:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1526:\n",
            "  Front: Explain: The establishment\n",
            "  Back: 81\n",
            "The establishment of a clear, central purpose or goal in life\n",
            "is the starting point of all success.\n",
            "--------------------\n",
            "Flashcard 1527:\n",
            "  Front: Explain: central purpose\n",
            "  Back: 81\n",
            "The establishment of a clear, central purpose or goal in life\n",
            "is the starting point of all success.\n",
            "--------------------\n",
            "Flashcard 1528:\n",
            "  Front: Explain: all success\n",
            "  Back: 81\n",
            "The establishment of a clear, central purpose or goal in life\n",
            "is the starting point of all success.\n",
            "--------------------\n",
            "Flashcard 1529:\n",
            "  Front: Explain: — Brian Tracy NOTES M A X\n",
            "  Back: — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1530:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1531:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1532:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1533:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1534:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1535:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1536:\n",
            "  Front: Explain: The potential\n",
            "  Back: 82\n",
            "The potential of the average person is like a huge ocean unsailed,\n",
            "a new continent unexplored, a world of possibilities waiting to be released \n",
            "and channeled toward some great good.” — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1537:\n",
            "  Front: Explain: the average person\n",
            "  Back: 82\n",
            "The potential of the average person is like a huge ocean unsailed,\n",
            "a new continent unexplored, a world of possibilities waiting to be released \n",
            "and channeled toward some great good.” — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1538:\n",
            "  Front: Explain: a huge ocean\n",
            "  Back: 82\n",
            "The potential of the average person is like a huge ocean unsailed,\n",
            "a new continent unexplored, a world of possibilities waiting to be released \n",
            "and channeled toward some great good.” — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1539:\n",
            "  Front: Explain: a new continent\n",
            "  Back: 82\n",
            "The potential of the average person is like a huge ocean unsailed,\n",
            "a new continent unexplored, a world of possibilities waiting to be released \n",
            "and channeled toward some great good.” — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1540:\n",
            "  Front: Explain: a world\n",
            "  Back: 82\n",
            "The potential of the average person is like a huge ocean unsailed,\n",
            "a new continent unexplored, a world of possibilities waiting to be released \n",
            "and channeled toward some great good.” — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1541:\n",
            "  Front: Explain: M U M A C H\n",
            "  Back: 82\n",
            "The potential of the average person is like a huge ocean unsailed,\n",
            "a new continent unexplored, a world of possibilities waiting to be released \n",
            "and channeled toward some great good.” — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1542:\n",
            "  Front: Explain: The contents\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1543:\n",
            "  Front: Explain: parts thereof\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1544:\n",
            "  Front: Explain: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1545:\n",
            "  Front: Explain: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1546:\n",
            "  Front: Explain: Brian Tracy\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 1547:\n",
            "  Front: Explain: this Goal Planner\n",
            "  Back: By completing this Goal Planner, you have begun \n",
            "to establish the habit of success.\n",
            "--------------------\n",
            "Flashcard 1548:\n",
            "  Front: Explain: the habit\n",
            "  Back: By completing this Goal Planner, you have begun \n",
            "to establish the habit of success.\n",
            "--------------------\n",
            "Flashcard 1549:\n",
            "  Front: Explain: a new Goal Planner today\n",
            "  Back: Order a new Goal Planner today so you can keep \n",
            "moving ahead.\n",
            "--------------------\n",
            "Flashcard 1550:\n",
            "  Front: Explain: im- portant things\n",
            "  Back: This could be one of the most im-\n",
            "portant things you ever do!\n",
            "--------------------\n",
            "Flashcard 1551:\n",
            "  Front: What are you?\n",
            "  Back: an action person\n",
            "--------------------\n",
            "Flashcard 1552:\n",
            "  Front: What are you?\n",
            "  Back: take action today\n",
            "--------------------\n",
            "Flashcard 1553:\n",
            "  Front: Explain: Stevens Avenue\n",
            "  Back: 462 Stevens Avenue, Suite 202\n",
            "Solana Beach, CA 92075\n",
            "858-436-7300 • 800-542-4252 • Fax 858-436-7301\n",
            "www.briantracy.com\n",
            "--------------------\n",
            "Flashcard 1554:\n",
            "  Front: Explain: Solana Beach\n",
            "  Back: 462 Stevens Avenue, Suite 202\n",
            "Solana Beach, CA 92075\n",
            "858-436-7300 • 800-542-4252 • Fax 858-436-7301\n",
            "www.briantracy.com\n",
            "--------------------\n",
            "Flashcard 1555:\n",
            "  Front: Explain: 858-436-7300 • 800-542-4252 • Fax\n",
            "  Back: 462 Stevens Avenue, Suite 202\n",
            "Solana Beach, CA 92075\n",
            "858-436-7300 • 800-542-4252 • Fax 858-436-7301\n",
            "www.briantracy.com\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "427a1a09"
      },
      "source": [
        "**Reasoning**:\n",
        "The flashcard extraction is now working, but the generated flashcards are not ideal. The \"front\" is often just a phrase, and the \"back\" is the entire section or a large chunk of text, which is not useful for flashcards. The current subtask is to refine the extraction logic to get better key terms/questions and corresponding definitions/answers. The next step is to modify the `_extract_flashcard_content` method further to attempt to extract more meaningful pairs. This will involve trying different NLP approaches or heuristics within the existing structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h441pKMMqL2Y"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import fitz\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Ensure all necessary NLTK data is downloaded\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
        "except LookupError:\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "try:\n",
        "    nltk.data.find('chunkers/maxent_ne_chunker')\n",
        "except LookupError:\n",
        "    nltk.download('maxent_ne_chunker')\n",
        "try:\n",
        "    nltk.data.find('corpora/words')\n",
        "except LookupError:\n",
        "    nltk.download('words')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "try:\n",
        "    nltk.data.find('taggers/averaged_perceptron_tagger_eng')\n",
        "except LookupError:\n",
        "    nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None # This will be replaced by the embedding model\n",
        "        self.tfidf_matrix = None # This will be replaced by the embeddings\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "        self.embedding_model = None # New attribute for Sentence Transformer model\n",
        "\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "        # Initialize Sentence Transformer model for embeddings\n",
        "        try:\n",
        "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            print(\"Sentence Transformer model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Sentence Transformer model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.embedding_model = None\n",
        "\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Basic text cleaning.\"\"\"\n",
        "        text = text.lower() # Convert to lowercase\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove non-alphanumeric characters except spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        self.chapter_sections = {} # Clear existing sections\n",
        "\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index using Sentence Transformers.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "        if not self.embedding_model:\n",
        "            print(\"Sentence Transformer model not loaded. Cannot vectorize sections.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "\n",
        "        section_texts = list(self.chapter_sections.values())\n",
        "        print(f\"Creating embeddings for {len(section_texts)} sections...\")\n",
        "\n",
        "        try:\n",
        "            # Create embeddings using the Sentence Transformer model\n",
        "            embeddings = self.embedding_model.encode(section_texts, convert_to_numpy=True)\n",
        "            self.tfidf_matrix = embeddings # Store embeddings (renamed from tfidf_matrix)\n",
        "\n",
        "            # Create FAISS index\n",
        "            dimension = embeddings.shape[1]\n",
        "            if dimension > 0:\n",
        "                self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "                self.index.add(embeddings.astype('float32')) # FAISS requires float32\n",
        "                print(\"FAISS index created.\")\n",
        "                # Store the titles corresponding to the vectorized texts for later lookup\n",
        "                self._vectorized_section_titles = list(self.chapter_sections.keys()) # Store original titles\n",
        "            else:\n",
        "                print(\"Embeddings have no dimensions after vectorization. Cannot create FAISS index.\")\n",
        "                self.index = None\n",
        "                self._vectorized_section_titles = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during embedding creation or FAISS index creation: {e}\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            self._vectorized_section_titles = []\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "        if not self.embedding_model or not self.index or not hasattr(self, '_vectorized_section_titles') or not self._vectorized_section_titles:\n",
        "             return \"Book content not vectorized or index not created. Cannot answer questions.\"\n",
        "\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        try:\n",
        "            # Create embedding for the question\n",
        "            question_vec = self.embedding_model.encode([question], convert_to_numpy=True).astype('float32')\n",
        "            D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating question embedding or searching index: {e}\")\n",
        "            return \"Could not process the question for searching.\"\n",
        "\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        # Use the stored vectorized section titles to get the correct title\n",
        "        relevant_section_title = self._vectorized_section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title] # Use original text for QA\n",
        "\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context) # Use original question for QA pipeline\n",
        "            return f\"Answer: {answer['answer']} (Source: '{relevant_section_title}', Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section from '{relevant_section_title}':\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "    def create_flashcards(self, section_identifier=None):\n",
        "        \"\"\"Generates flashcards from the book content, optionally from a specific section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for flashcard creation.\"\n",
        "\n",
        "        sections_to_process = {}\n",
        "        if section_identifier:\n",
        "            section_titles = list(self.chapter_sections.keys())\n",
        "            section_text = None\n",
        "            section_title = None\n",
        "\n",
        "            try:\n",
        "                # Try to find by number (1-based index)\n",
        "                section_index = int(section_identifier) - 1\n",
        "                if 0 <= section_index < len(section_titles):\n",
        "                    section_title = section_titles[section_index]\n",
        "                    section_text = self.chapter_sections[section_title]\n",
        "            except ValueError:\n",
        "                # If not a number, try to find by partial title match\n",
        "                for title in section_titles:\n",
        "                    if section_identifier.lower() in title.lower():\n",
        "                        section_title = title\n",
        "                        section_text = self.chapter_sections[title]\n",
        "                        break\n",
        "\n",
        "            if section_text is None:\n",
        "                return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "            sections_to_process[section_title] = section_text\n",
        "            print(f\"Generating flashcards for section: '{section_title}'\")\n",
        "        else:\n",
        "            sections_to_process = self.chapter_sections\n",
        "            print(\"Generating flashcards for the entire book.\")\n",
        "\n",
        "        all_flashcards = []\n",
        "        for title, text in sections_to_process.items():\n",
        "            flashcards = self._extract_flashcard_content(text)\n",
        "            formatted_flashcards = [self._format_flashcard(fc) for fc in flashcards]\n",
        "            all_flashcards.extend(formatted_flashcards)\n",
        "\n",
        "        if all_flashcards:\n",
        "            print(f\"Generated {len(all_flashcards)} potential flashcards.\")\n",
        "            return all_flashcards\n",
        "        else:\n",
        "            return \"Could not generate any flashcards from the selected content.\"\n",
        "\n",
        "\n",
        "    def _extract_flashcard_content(self, text):\n",
        "        \"\"\"Identifies and extracts potential flashcard material from text using NLP.\"\"\"\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "        flashcard_candidates = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Skip very short sentences\n",
        "            if len(sentence.split()) < 8: # Increased minimum length\n",
        "                continue\n",
        "\n",
        "            # Try to extract Term-Definition pairs using POS tagging and dependency parsing heuristics\n",
        "            tokens = nltk.word_tokenize(sentence)\n",
        "            pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "            # Look for patterns like \"Term is a Definition\" or \"Term refers to Definition\"\n",
        "            # This is still heuristic but more targeted\n",
        "            definition_patterns = [\n",
        "                (r'(.+)\\s+(is a|is the|refers to)\\s+(.+)\\.', 'What is {term}?'),\n",
        "                (r'(.+)\\s+(are|include)\\s+(.+)\\.', 'What are {term}?'),\n",
        "            ]\n",
        "\n",
        "            for pattern, question_template in definition_patterns:\n",
        "                match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "                if match:\n",
        "                    term = match.group(1).strip()\n",
        "                    definition = match.group(3).strip()\n",
        "                    # Basic filtering for reasonable term/definition length\n",
        "                    if 3 <= len(term.split()) <= 10 and len(definition.split()) >= 5:\n",
        "                         flashcard_candidates.append({'front': question_template.format(term=term), 'back': definition})\n",
        "                         # Once a definition is found, move to the next sentence\n",
        "                         break # Break out of pattern loop, continue to next sentence\n",
        "\n",
        "            # As a fallback, consider sentences with question marks\n",
        "            if sentence.strip().endswith('?'):\n",
        "                front = sentence.strip()\n",
        "                # Try to find a concise answer in the following sentence(s)\n",
        "                answer_found = False\n",
        "                for i, next_sentence in enumerate(sentences[sentences.index(sentence)+1:]):\n",
        "                    # Consider sentences that are not too long as potential answers\n",
        "                    if 5 <= len(next_sentence.split()) <= 30:\n",
        "                        back = next_sentence.strip()\n",
        "                        flashcard_candidates.append({'front': front, 'back': back})\n",
        "                        answer_found = True\n",
        "                        break\n",
        "                    if i > 3: # Don't look too far ahead\n",
        "                        break\n",
        "                if not answer_found:\n",
        "                     # If no good answer found, use a placeholder or the original sentence (truncated)\n",
        "                     back = sentence.strip()[:100] + \"...\" if len(sentence) > 100 else sentence.strip()\n",
        "                     flashcard_candidates.append({'front': front, 'back': f\"Answer not found nearby. Relevant context: {back}\"})\n",
        "\n",
        "\n",
        "        # Additional heuristic: Extracting key terms and their surrounding sentence as definition\n",
        "        # Identify potential key terms (e.g., prominent noun phrases)\n",
        "        terms_to_consider = set()\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "        grammar = \"NP: {<DT>?<JJ>*<NNP>+|<DT>?<JJ>*<NN>+<NNS>?}\" # More specific NP pattern\n",
        "        cp = nltk.RegexpParser(grammar)\n",
        "        tree = cp.parse(pos_tags)\n",
        "\n",
        "        for subtree in tree.subtrees():\n",
        "            if subtree.label() == 'NP':\n",
        "                term = \" \".join([word for (word, tag) in subtree.leaves()])\n",
        "                # Filter terms based on length and common words\n",
        "                if 2 <= len(term.split()) <= 5 and term.lower() not in ['the', 'a', 'is', 'are', 'this', 'that', 'it']:\n",
        "                     terms_to_consider.add(term)\n",
        "\n",
        "        # Create flashcards for key terms by finding sentences where they appear\n",
        "        for term in terms_to_consider:\n",
        "             for sentence in sentences:\n",
        "                  if re.search(r'\\b' + re.escape(term) + r'\\b', sentence, re.IGNORECASE):\n",
        "                       # Use the term as the front, and the sentence (or a part of it) as the back\n",
        "                       front = term.strip()\n",
        "                       back = sentence.strip()\n",
        "                       # Avoid creating duplicate flashcards if already captured by other patterns\n",
        "                       if {'front': front, 'back': back} not in flashcard_candidates:\n",
        "                           flashcard_candidates.append({'front': front, 'back': back})\n",
        "                           break # Move to the next term after finding one sentence\n",
        "\n",
        "\n",
        "        return flashcard_candidates\n",
        "\n",
        "\n",
        "    def _format_flashcard(self, flashcard_data):\n",
        "        \"\"\"Formats the extracted content into a flashcard structure.\"\"\"\n",
        "        # In this basic implementation, the data is already in the desired format.\n",
        "        # This method serves as a placeholder for more complex formatting if needed.\n",
        "        return flashcard_data\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for study/review.\"\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Create Flashcards (Entire Book)\")\n",
        "        print(\"5. Create Flashcards (Specific Section)\")\n",
        "        print(\"6. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                flashcards = self.create_flashcards()\n",
        "                if isinstance(flashcards, list):\n",
        "                    print(\"\\nGenerated Flashcards:\")\n",
        "                    for i, fc in enumerate(flashcards):\n",
        "                        print(f\"Flashcard {i+1}:\")\n",
        "                        print(f\"  Front: {fc['front']}\")\n",
        "                        print(f\"  Back: {fc['back']}\")\n",
        "                        print(\"-\" * 20)\n",
        "                else:\n",
        "                    print(flashcards) # Print error message\n",
        "            elif choice == '5':\n",
        "                section_input = input(\"Enter the chapter/section number or name to create flashcards from: \")\n",
        "                flashcards = self.create_flashcards(section_input)\n",
        "                if isinstance(flashcards, list):\n",
        "                    print(f\"\\nGenerated Flashcards for '{section_input}':\")\n",
        "                    for i, fc in enumerate(flashcards):\n",
        "                        print(f\"Flashcard {i+1}:\")\n",
        "                        print(f\"  Front: {fc['front']}\")\n",
        "                        print(f\"  Back: {fc['back']}\")\n",
        "                        print(\"-\" * 20)\n",
        "                else:\n",
        "                    print(flashcards) # Print error message\n",
        "            elif choice == '6':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72df6918"
      },
      "source": [
        "**Reasoning**:\n",
        "The `_extract_flashcard_content` method has been further refined with more targeted heuristics for extracting flashcard content. The next logical step in completing the subtask is to test this updated method by generating flashcards from the loaded book again. This will help evaluate the effectiveness of the new extraction logic and identify if further adjustments are needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb3addd",
        "outputId": "92944766-a631-42e2-e793-bcc1f3ec0d5c"
      },
      "source": [
        "# Create an instance of the BookQA agent to load the updated code\n",
        "agent = BookQA()\n",
        "\n",
        "# Upload a book to test flashcard creation\n",
        "# Use the same book path as before, assuming it loaded successfully in previous steps\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf'\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)\n",
        "\n",
        "# If upload is successful, create flashcards from the first section\n",
        "if agent.chapter_sections:\n",
        "    first_section_key = list(agent.chapter_sections.keys())[0]\n",
        "    print(f\"\\nAttempting to create flashcards from section: {first_section_key}\")\n",
        "    flashcards = agent.create_flashcards(first_section_key)\n",
        "\n",
        "    if isinstance(flashcards, list):\n",
        "        print(\"\\nGenerated Flashcards:\")\n",
        "        for i, fc in enumerate(flashcards):\n",
        "            print(f\"Flashcard {i+1}:\")\n",
        "            print(f\"  Front: {fc['front']}\")\n",
        "            print(f\"  Back: {fc['back']}\")\n",
        "            print(\"-\" * 20)\n",
        "    else:\n",
        "        print(flashcards) # Print error message\n",
        "else:\n",
        "    print(\"\\nBook processing failed. Cannot create flashcards.\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization model loaded.\n",
            "Sentence Transformer model loaded.\n",
            "Models initialized.\n",
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Creating embeddings for 1 sections...\n",
            "FAISS index created.\n",
            "\n",
            "Attempting to create flashcards from section: Introduction/Beginning\n",
            "Generating flashcards for section: 'Introduction/Beginning'\n",
            "Generated 280 potential flashcards.\n",
            "\n",
            "Generated Flashcards:\n",
            "Flashcard 1:\n",
            "  Front: In each case the question you ask yourself is: “What do I really want?\n",
            "  Back: What are my \n",
            "real goals in life?”\n",
            "You are asked to think about your major goals based on ten goal-achieving criteria.\n",
            "--------------------\n",
            "Flashcard 2:\n",
            "  Front: How would you spend your time, where would you go, what would you do, if \n",
            "you found out today that you only had six months to live?\n",
            "  Back: Answer not found nearby. Relevant context: How would you spend your time, where would you go, what would you do, if \n",
            "you found out today that y...\n",
            "--------------------\n",
            "Flashcard 3:\n",
            "  Front: What would you do differently if you won one million dollars cash, tax free, \n",
            "tomorrow?\n",
            "  Back: What have you always wanted to do but been afraid to attempt?\n",
            "--------------------\n",
            "Flashcard 4:\n",
            "  Front: What have you always wanted to do but been afraid to attempt?\n",
            "  Back: Answer not found nearby. Relevant context: What have you always wanted to do but been afraid to attempt?\n",
            "--------------------\n",
            "Flashcard 5:\n",
            "  Front: What do you enjoy doing most in life?\n",
            "  Back: If you could engage in any full-time \n",
            "activity, without pay, what would it be?\n",
            "--------------------\n",
            "Flashcard 6:\n",
            "  Front: If you could engage in any full-time \n",
            "activity, without pay, what would it be?\n",
            "  Back: How much money would you like to be earning?\n",
            "--------------------\n",
            "Flashcard 7:\n",
            "  Front: How much money would you like to be earning?\n",
            "  Back: ................................................................................$\n",
            " \n",
            "In ﬁ ve years?\n",
            "--------------------\n",
            "Flashcard 8:\n",
            "  Front: How much do you want to be worth when you retire?\n",
            "  Back: ............... $ __________\n",
            "8. \n",
            "Who else is earning the kind of money you want to earn?\n",
            "--------------------\n",
            "Flashcard 9:\n",
            "  Front: ............... $ __________\n",
            "8. \n",
            "Who else is earning the kind of money you want to earn?\n",
            "  Back: What is he/she doing differently from you that enables him/her to earn this \n",
            "kind of money?\n",
            "--------------------\n",
            "Flashcard 10:\n",
            "  Front: What is he/she doing differently from you that enables him/her to earn this \n",
            "kind of money?\n",
            "  Back: Answer not found nearby. Relevant context: What is he/she doing differently from you that enables him/her to earn this \n",
            "kind of money?\n",
            "--------------------\n",
            "Flashcard 11:\n",
            "  Front: Career and professional goals: What do you want to be good at?\n",
            "  Back: Sport and ﬁ tness goals: What do you want to achieve physically?\n",
            "--------------------\n",
            "Flashcard 12:\n",
            "  Front: Sport and ﬁ tness goals: What do you want to achieve physically?\n",
            "  Back: Personal development goals: In what areas do you want to improve?\n",
            "--------------------\n",
            "Flashcard 13:\n",
            "  Front: Personal development goals: In what areas do you want to improve?\n",
            "  Back: Family and relationship goals: What do you want to do for your family?\n",
            "--------------------\n",
            "Flashcard 14:\n",
            "  Front: Family and relationship goals: What do you want to do for your family?\n",
            "  Back: Travel goals — places to visit/vacations: Where do you want to go?\n",
            "--------------------\n",
            "Flashcard 15:\n",
            "  Front: Travel goals — places to visit/vacations: Where do you want to go?\n",
            "  Back: Material and tangible goals (things): What do you want to acquire?\n",
            "--------------------\n",
            "Flashcard 16:\n",
            "  Front: Material and tangible goals (things): What do you want to acquire?\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 17:\n",
            "  Front: Community and service goals: How do you want to contribute?\n",
            "  Back: Creative goals: What do you want to bring into reality?\n",
            "--------------------\n",
            "Flashcard 18:\n",
            "  Front: Creative goals: What do you want to bring into reality?\n",
            "  Back: Spiritual and inner development goals: What kind of a person do you want to \n",
            "become?\n",
            "--------------------\n",
            "Flashcard 19:\n",
            "  Front: Spiritual and inner development goals: What kind of a person do you want to \n",
            "become?\n",
            "  Back: Intellectual and educational goals: What do you want to learn?\n",
            "--------------------\n",
            "Flashcard 20:\n",
            "  Front: Intellectual and educational goals: What do you want to learn?\n",
            "  Back: What one great thing would you dare to dream if you knew you could not \n",
            "fail?\n",
            "--------------------\n",
            "Flashcard 21:\n",
            "  Front: What one great thing would you dare to dream if you knew you could not \n",
            "fail?\n",
            "  Back: If you were guaranteed of success?\n",
            "--------------------\n",
            "Flashcard 22:\n",
            "  Front: If you could have any one goal on this list within 24 hours, which one goal \n",
            "would you choose?\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 23:\n",
            "  Front: Based on these exercises, what do you think should be your most important \n",
            "goal?\n",
            "  Back: Your major deﬁ nite purpose?\n",
            "--------------------\n",
            "Flashcard 24:\n",
            "  Front: Desire: How much do you really want it on a scale of 1 - 10?\n",
            "  Back: Belief: Is it believable and achievable?\n",
            "--------------------\n",
            "Flashcard 25:\n",
            "  Front: Write it down: How will you measure success?\n",
            "  Back: Analyze: Where are you starting from now?\n",
            "--------------------\n",
            "Flashcard 26:\n",
            "  Front: Determine Why : How will you personally beneﬁ t from achieving it?\n",
            "  Back: Timing: Set a deadline on your goal!\n",
            "--------------------\n",
            "Flashcard 27:\n",
            "  Front: Research: What additional information, knowledge and skills will you require?\n",
            "  Back: Key People: Whose assistance or cooperation do you need?\n",
            "--------------------\n",
            "Flashcard 28:\n",
            "  Front: Key People: Whose assistance or cooperation do you need?\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 29:\n",
            "  Front: Write it out clearly; what are you going to do, starting today, \n",
            "and every day?\n",
            "  Back: The more detailed your description, the more likely it is that you \n",
            "will achieve it!\n",
            "--------------------\n",
            "Flashcard 30:\n",
            "  Front: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "  Back: Seek this very minute, whatever you can do, \n",
            "or dream you can; begin it.\n",
            "--------------------\n",
            "Flashcard 31:\n",
            "  Front: 27\n",
            "Would you like me to give you a formula for… success?\n",
            "  Back: Double your rate of \n",
            "failure… You’re thinking of failures as the enemy of success.\n",
            "--------------------\n",
            "Flashcard 32:\n",
            "  Front: What are The empires of the future?\n",
            "  Back: the empires of the mind\n",
            "--------------------\n",
            "Flashcard 33:\n",
            "  Front: a habit\n",
            "  Back: Repeat the process every single day for 30 days until it becomes a habit.\n",
            "--------------------\n",
            "Flashcard 34:\n",
            "  Front: a potential genius\n",
            "  Back: You are a potential genius; there is \n",
            "no problem you cannot solve, and \n",
            "no answer you cannot ﬁ nd some-\n",
            "where.\n",
            "--------------------\n",
            "Flashcard 35:\n",
            "  Front: intense purpose\n",
            "  Back: The suc-\n",
            "cessful men of today are men of one overmastering idea, one unwavering aim, \n",
            "men of single and intense purpose.\n",
            "--------------------\n",
            "Flashcard 36:\n",
            "  Front: the great desire\n",
            "  Back: Concentrate all your thoughts on the great desire in your life.\n",
            "--------------------\n",
            "Flashcard 37:\n",
            "  Front: Goal Planner\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 38:\n",
            "  Front: the box\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 39:\n",
            "  Front: an inevitable part\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 40:\n",
            "  Front: every single day\n",
            "  Back: Repeat the process every single day for 30 days until it becomes a habit.\n",
            "--------------------\n",
            "Flashcard 41:\n",
            "  Front: action steps\n",
            "  Back: Start with number one:\n",
            "GOAL NUMBER ONE:\n",
            " \n",
            "ACTION STEPS \n",
            "ORDER\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 42:\n",
            "  Front: Mental Storehouse\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 43:\n",
            "  Front: the ﬁ\n",
            "  Back: ■   He has studied, researched, written and \n",
            "spoken for 30 years in the ﬁ elds of eco-\n",
            "nomics, history, business, philosophy \n",
            "and psychology.\n",
            "--------------------\n",
            "Flashcard 44:\n",
            "  Front: the form\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 45:\n",
            "  Front: a new Goal Planner\n",
            "  Back: Order a new Goal Planner today so you can keep \n",
            "moving ahead.\n",
            "--------------------\n",
            "Flashcard 46:\n",
            "  Front: ll ﬁ\n",
            "  Back: Because, \n",
            "remember that’s where you’ll ﬁ nd success.\n",
            "--------------------\n",
            "Flashcard 47:\n",
            "  Front: the quality\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 48:\n",
            "  Front: Goal Planning — Day One\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 49:\n",
            "  Front: life overnight\n",
            "  Back: Any one of them could change the course of his life overnight.\n",
            "--------------------\n",
            "Flashcard 50:\n",
            "  Front: The person\n",
            "  Back: Everything you have in your life \n",
            "you have attracted to yourself     \n",
            "because of the person you are.\n",
            "--------------------\n",
            "Flashcard 51:\n",
            "  Front: GOAL SETTING EXERCISES\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 52:\n",
            "  Front: this goal\n",
            "  Back: This goal planner has been designed after more than 25 years of research and practice.\n",
            "--------------------\n",
            "Flashcard 53:\n",
            "  Front: Brian Tracy Univesity .........................................................................\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 54:\n",
            "  Front: a detailed plan\n",
            "  Back: FINALLY — Write out a detailed plan of accomplishment, a list of activities, \n",
            "for your major goal.\n",
            "--------------------\n",
            "Flashcard 55:\n",
            "  Front: no answer\n",
            "  Back: You are a potential genius; there is \n",
            "no problem you cannot solve, and \n",
            "no answer you cannot ﬁ nd some-\n",
            "where.\n",
            "--------------------\n",
            "Flashcard 56:\n",
            "  Front: a success\n",
            "  Back: Then your life will take on a success \n",
            "momentum of its own.\n",
            "--------------------\n",
            "Flashcard 57:\n",
            "  Front: the courage\n",
            "  Back: 69\n",
            "All our dreams come true — if we have the courage\n",
            "to pursue them.\n",
            "--------------------\n",
            "Flashcard 58:\n",
            "  Front: every word\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 59:\n",
            "  Front: The Law\n",
            "  Back: The Law of Control — Your goals allow you to control the direction of change \n",
            "in your life, thereby freeing you from aimlessness, drifting and random occurrences.\n",
            "--------------------\n",
            "Flashcard 60:\n",
            "  Front: this list\n",
            "  Back: If you could have any one goal on this list within 24 hours, which one goal \n",
            "would you choose?\n",
            "--------------------\n",
            "Flashcard 61:\n",
            "  Front: a manner\n",
            "  Back: The Law of Subconscious Activity — You will begin to walk, talk, act and per-\n",
            "ceive in a manner that will make your goals a reality.\n",
            "--------------------\n",
            "Flashcard 62:\n",
            "  Front: every area\n",
            "  Back: 2\n",
            "HOW TO USE YOUR GOAL PLANNER\n",
            "The purpose of this goal planner is to enable you to decide exactly what you want in \n",
            "every area of your life, and then to help you achieve it.\n",
            "--------------------\n",
            "Flashcard 63:\n",
            "  Front: t steal second base\n",
            "  Back: 79\n",
            "Progress always involves risk, you can’t steal second base and\n",
            "keep your foot on ﬁ rst.\n",
            "--------------------\n",
            "Flashcard 64:\n",
            "  Front: management consulting\n",
            "  Back: He has had successful careers in sales \n",
            "and marketing, investments, real estate develop-\n",
            "ment and syndication, importation, distribution \n",
            "and management consulting.\n",
            "--------------------\n",
            "Flashcard 65:\n",
            "  Front: the Ages\n",
            "  Back: The Law of Superconscious Activity — Called the “Secret of the Ages,” this is \n",
            "the most powerful of all laws.\n",
            "--------------------\n",
            "Flashcard 66:\n",
            "  Front: the word\n",
            "  Back: Write your goals in the present, positive tense, starting with the word “I.”\n",
            " \n",
            "(I am, I sell, I achieve, etc.)\n",
            "--------------------\n",
            "Flashcard 67:\n",
            "  Front: no road\n",
            "  Back: There is no road too long to the man who advances deliberately and without \n",
            "undue haste;  there are no honors too distant to the man who prepares himself \n",
            "for them with patience.\n",
            "--------------------\n",
            "Flashcard 68:\n",
            "  Front: the high road\n",
            "  Back: When you complete this planner, you will be on the high road to success and \n",
            "achievement in every area of your life.\n",
            "--------------------\n",
            "Flashcard 69:\n",
            "  Front: The majority\n",
            "  Back: 43\n",
            "D A Y\n",
            "13\n",
            " /   /\n",
            "The majority of men meet with failure because of their lack of persistence \n",
            "in creating new plans to take the place of those which fail.\n",
            "--------------------\n",
            "Flashcard 70:\n",
            "  Front: s date\n",
            "  Back: Begin with today’s date then, write down your three most important goals right \n",
            "now; (#1)\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 71:\n",
            "  Front: the enemy\n",
            "  Back: Double your rate of \n",
            "failure… You’re thinking of failures as the enemy of success.\n",
            "--------------------\n",
            "Flashcard 72:\n",
            "  Front: a matter\n",
            "  Back: All of life is a matter of habit.\n",
            "--------------------\n",
            "Flashcard 73:\n",
            "  Front: a reality\n",
            "  Back: The Law of Subconscious Activity — You will begin to walk, talk, act and per-\n",
            "ceive in a manner that will make your goals a reality.\n",
            "--------------------\n",
            "Flashcard 74:\n",
            "  Front: GOAL NUMBER TWO\n",
            "  Back: 13\n",
            "GOAL NUMBER TWO:\n",
            " \n",
            "ACTION STEPS \n",
            "ORDER\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 75:\n",
            "  Front: major problem\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 76:\n",
            "  Front: BRIAN TRACY\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 77:\n",
            "  Front: every event\n",
            "  Back: The Law of Expectations — Each day, you conﬁ dently expect that every event, \n",
            "positive or negative, has been sent to help move you toward your goals.\n",
            "--------------------\n",
            "Flashcard 78:\n",
            "  Front: a Lifetime\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 79:\n",
            "  Front: the top\n",
            "  Back: He is the top selling \n",
            "author of 48 books that have been trans-\n",
            "lated into dozens of languages.\n",
            "--------------------\n",
            "Flashcard 80:\n",
            "  Front: unstoppable force\n",
            "  Back: It simply says that, “any thought, plan, goal or idea, \n",
            "held continuously in your conscious mind, must be brought into reality by the super-\n",
            "conscious mind.”\n",
            "All these laws in combination will make you an irresistible and unstoppable force of \n",
            "nature.\n",
            "--------------------\n",
            "Flashcard 81:\n",
            "  Front: an action person\n",
            "  Back: You are an action person, so take action today!\n",
            "--------------------\n",
            "Flashcard 82:\n",
            "  Front: every week\n",
            "  Back: This concentration \n",
            "must be continuous, unceasing — every minute; every hour; every day; every week.\n",
            "--------------------\n",
            "Flashcard 83:\n",
            "  Front: A department store grows\n",
            "  Back: A department store grows bigger one customer at a time.\n",
            "--------------------\n",
            "Flashcard 84:\n",
            "  Front: an idea\n",
            "  Back: 67\n",
            "There is one thing stronger than all the armies in the world and that is an idea \n",
            "whose time has come.\n",
            "--------------------\n",
            "Flashcard 85:\n",
            "  Front: Good luck\n",
            "  Back: Good luck!\n",
            "--------------------\n",
            "Flashcard 86:\n",
            "  Front: Travel goals\n",
            "  Back: Travel goals — places to visit/vacations: Where do you want to go?\n",
            "--------------------\n",
            "Flashcard 87:\n",
            "  Front: the President\n",
            "  Back: He is active \n",
            "in community and national af-\n",
            "fairs, and is the President \n",
            "of three companies \n",
            "headquartered in \n",
            "Solana Beach, \n",
            "California.\n",
            "--------------------\n",
            "Flashcard 88:\n",
            "  Front: prosperity consciousness\n",
            "  Back: 29\n",
            "The strongest single factor in prosperity consciousness is self-esteem: \n",
            "believing you can do it, believing you deserve it, believing you will get it.\n",
            "--------------------\n",
            "Flashcard 89:\n",
            "  Front: a question\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 90:\n",
            "  Front: a brick\n",
            "  Back: A house is built a brick at a time.\n",
            "--------------------\n",
            "Flashcard 91:\n",
            "  Front: Nothing splendid\n",
            "  Back: Nothing splendid has ever been achieved except by those who dared believe that \n",
            "something inside of them was superior to circumstance.\n",
            "--------------------\n",
            "Flashcard 92:\n",
            "  Front: own mind\n",
            "  Back: There are no limits on what you can \n",
            "achieve with your life, except the \n",
            "limits you accept in your own mind.\n",
            "--------------------\n",
            "Flashcard 93:\n",
            "  Front: the ignorance\n",
            "  Back: Concerning all acts of initiative \n",
            "(and creation), there is an elementary truth, the ignorance of \n",
            "which kills countless ideas and splendid plans; that the moment \n",
            "one deﬁ nitely commits oneself, then Providence moves, too.\n",
            "--------------------\n",
            "Flashcard 94:\n",
            "  Front: a list\n",
            "  Back: Ten Goal Exercise:\n",
            " \n",
            "Make a list of at least ten goals you would like to accomplish in the next year.\n",
            "--------------------\n",
            "Flashcard 95:\n",
            "  Front: life belongs\n",
            "  Back: No man has come to true greatness who has not felt that his life belongs to his race, \n",
            "that which God gives to him, he gives to mankind.\n",
            "--------------------\n",
            "Flashcard 96:\n",
            "  Front: a number\n",
            "  Back: 25\n",
            "The successful person always has a number of projects planned, to which he \n",
            "looks forward.\n",
            "--------------------\n",
            "Flashcard 97:\n",
            "  Front: take action today\n",
            "  Back: You are an action person, so take action today!\n",
            "--------------------\n",
            "Flashcard 98:\n",
            "  Front: speciﬁ c goals\n",
            "  Back: When you have clear, speciﬁ c goals that you are writing and rewriting every day, you \n",
            "trigger these laws into action on your behalf.\n",
            "--------------------\n",
            "Flashcard 99:\n",
            "  Front: the opportunity\n",
            "  Back: 63\n",
            "Unless you have prepared yourself to proﬁ t by your chance, the opportunity will only \n",
            "make you ridiculous.\n",
            "--------------------\n",
            "Flashcard 100:\n",
            "  Front: Effect — Clear\n",
            "  Back: The Law of Cause and Effect — Clear, repeated goals become the primary \n",
            "cause of the effects in your life.\n",
            "--------------------\n",
            "Flashcard 101:\n",
            "  Front: Attraction — Every\n",
            "  Back: The Law of Attraction — Every time you rewrite or think about your goals, you \n",
            "intensify the speed of vibration that causes you to attract people and circumstances \n",
            "into your life that will help you achieve your goals.\n",
            "--------------------\n",
            "Flashcard 102:\n",
            "  Front: the worldwide\n",
            "  Back: ■   He has written and produced more \n",
            "than 350 audio and video learning \n",
            "programs, including the worldwide, best-\n",
            "selling Psychology of Achieve-\n",
            "ment, which has been trans-\n",
            "lated into more than 20 \n",
            "languages.\n",
            "--------------------\n",
            "Flashcard 103:\n",
            "  Front: The purpose\n",
            "  Back: 2\n",
            "HOW TO USE YOUR GOAL PLANNER\n",
            "The purpose of this goal planner is to enable you to decide exactly what you want in \n",
            "every area of your life, and then to help you achieve it.\n",
            "--------------------\n",
            "Flashcard 104:\n",
            "  Front: single factor\n",
            "  Back: 29\n",
            "The strongest single factor in prosperity consciousness is self-esteem: \n",
            "believing you can do it, believing you deserve it, believing you will get it.\n",
            "--------------------\n",
            "Flashcard 105:\n",
            "  Front: The quality\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 106:\n",
            "  Front: Brian Tracy International\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY – Author  •  Trainer  •  Consultant\n",
            "B\n",
            "rian Tracy is Chairman and CEO of \n",
            "Brian Tracy International, a company \n",
            "specializing in the training and devel-\n",
            "opment of individuals and organizations.\n",
            "--------------------\n",
            "Flashcard 107:\n",
            "  Front: the man\n",
            "  Back: Concentrate… for the greatest achievements are reserved for the man of single aim, \n",
            "in who no rival powers divide the empire of the soul.\n",
            "--------------------\n",
            "Flashcard 108:\n",
            "  Front: Brian Tracy\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 109:\n",
            "  Front: FINALLY — Write\n",
            "  Back: FINALLY — Write out a detailed plan of accomplishment, a list of activities, \n",
            "for your major goal.\n",
            "--------------------\n",
            "Flashcard 110:\n",
            "  Front: a mighty river\n",
            "  Back: You will become more focused, directed and channeled, like a mighty river, \n",
            "moving forward over all obstacles to create the kind of life you desire.\n",
            "--------------------\n",
            "Flashcard 111:\n",
            "  Front: much money\n",
            "  Back: How much money would you like to be earning?\n",
            "--------------------\n",
            "Flashcard 112:\n",
            "  Front: D A Y\n",
            "  Back: — Tom Hopkins\n",
            "D A Y\n",
            "1\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 113:\n",
            "  Front: the moment\n",
            "  Back: Concerning all acts of initiative \n",
            "(and creation), there is an elementary truth, the ignorance of \n",
            "which kills countless ideas and splendid plans; that the moment \n",
            "one deﬁ nitely commits oneself, then Providence moves, too.\n",
            "--------------------\n",
            "Flashcard 114:\n",
            "  Front: the principle\n",
            "  Back: The person determined to achieve maximum success learns the principle that progress \n",
            "is made one step at a time.\n",
            "--------------------\n",
            "Flashcard 115:\n",
            "  Front: continuous goal-setting\n",
            "  Back: You can learn the habits you need to reach Maximum Achievement by practicing \n",
            "continuous goal-setting and daily action planning until these behaviors become auto-\n",
            "matic.\n",
            "--------------------\n",
            "Flashcard 116:\n",
            "  Front: a time\n",
            "  Back: Your success will be largely deter-\n",
            "mined by your ability to concen-\n",
            "trate single-mindedly on one thing \n",
            "at a time.\n",
            "--------------------\n",
            "Flashcard 117:\n",
            "  Front: that point\n",
            "  Back: The ﬁ rst law of success… is concentration — to blend all the energies to one \n",
            "point, and to go directly to that point, looking neither to the right nor to the \n",
            "left.\n",
            "--------------------\n",
            "Flashcard 118:\n",
            "  Front: a Keynote\n",
            "  Back: As a Keynote speaker and \n",
            "seminar leader, he addresses more than 250,000 \n",
            "people each year.\n",
            "--------------------\n",
            "Flashcard 119:\n",
            "  Front: useful bit\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 120:\n",
            "  Front: unwavering aim\n",
            "  Back: The suc-\n",
            "cessful men of today are men of one overmastering idea, one unwavering aim, \n",
            "men of single and intense purpose.\n",
            "--------------------\n",
            "Flashcard 121:\n",
            "  Front: each case\n",
            "  Back: In each case the question you ask yourself is: “What do I really want?\n",
            "--------------------\n",
            "Flashcard 122:\n",
            "  Front: goal-achieving personality\n",
            "  Back: You will take complete charge of your life and turn yourself into an unstop-\n",
            "pable, goal-achieving personality.\n",
            "--------------------\n",
            "Flashcard 123:\n",
            "  Front: important goal\n",
            "  Back: With your goals clearly before you, you are asked to select your most important goal, \n",
            "the one goal that, when you achieve it, will enable you to achieve many of your other \n",
            "goals as well.\n",
            "--------------------\n",
            "Flashcard 124:\n",
            "  Front: the start\n",
            "  Back: At the start of this planner, you are asked to think about your goals in several areas of \n",
            "your life.\n",
            "--------------------\n",
            "Flashcard 125:\n",
            "  Front: single aim\n",
            "  Back: Concentrate… for the greatest achievements are reserved for the man of single aim, \n",
            "in who no rival powers divide the empire of the soul.\n",
            "--------------------\n",
            "Flashcard 126:\n",
            "  Front: any kind\n",
            "  Back: 77\n",
            "I do not think there is any other quality so essential to success of any kind as \n",
            "the quality of perseverance.\n",
            "--------------------\n",
            "Flashcard 127:\n",
            "  Front: rst step\n",
            "  Back: You can \n",
            "break that big plan into small steps and take the ﬁ rst step right away.\n",
            "--------------------\n",
            "Flashcard 128:\n",
            "  Front: the number\n",
            "  Back: 19\n",
            "I am not judged by the number of times I fail, but by the number of times \n",
            "I succeed; and the number of times I succeed is in direct proportion to the \n",
            "number of times I can fail and keep on trying.\n",
            "--------------------\n",
            "Flashcard 129:\n",
            "  Front: a result\n",
            "  Back: If you only care enough for a result, you will almost certainly attain it… Only you \n",
            "must, then, really wish these things, and wish them exclusively, and not wish at the \n",
            "same time a hundred other incompatible things just as strongly.\n",
            "--------------------\n",
            "Flashcard 130:\n",
            "  Front: true greatness\n",
            "  Back: No man has come to true greatness who has not felt that his life belongs to his race, \n",
            "that which God gives to him, he gives to mankind.\n",
            "--------------------\n",
            "Flashcard 131:\n",
            "  Front: the soul\n",
            "  Back: Concentrate… for the greatest achievements are reserved for the man of single aim, \n",
            "in who no rival powers divide the empire of the soul.\n",
            "--------------------\n",
            "Flashcard 132:\n",
            "  Front: the habit\n",
            "  Back: Develop the habit of goal setting by completing two \n",
            "pages each day for 31 days;\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 133:\n",
            "  Front: the time\n",
            "  Back: The Law of Substitution — Whatever your conscious mind is thinking about, most \n",
            "of the time, is being accepted by your subconscious mind and it is being attracted \n",
            "into your life.\n",
            "--------------------\n",
            "Flashcard 134:\n",
            "  Front: high level\n",
            "  Back: He has conducted \n",
            "high level consulting assignments with several \n",
            "billion-dollar plus corporations in strategic \n",
            "planning and organizational develop-\n",
            "ment.\n",
            "--------------------\n",
            "Flashcard 135:\n",
            "  Front: this “\n",
            "  Back: Write out twenty answers to this “mindstorming” question; (#5)\n",
            "7.\n",
            "--------------------\n",
            "Flashcard 136:\n",
            "  Front: action planning\n",
            "  Back: You can learn the habits you need to reach Maximum Achievement by practicing \n",
            "continuous goal-setting and daily action planning until these behaviors become auto-\n",
            "matic.\n",
            "--------------------\n",
            "Flashcard 137:\n",
            "  Front: The potential\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 138:\n",
            "  Front: The great secret\n",
            "  Back: The great secret of success is that \n",
            "there are no secrets of success; \n",
            "there are only timeless principles \n",
            "that have proven effective through-\n",
            "out the centuries.\n",
            "--------------------\n",
            "Flashcard 139:\n",
            "  Front: The pay-off\n",
            "  Back: The pay-off?\n",
            "--------------------\n",
            "Flashcard 140:\n",
            "  Front: Solana Beach\n",
            "  Back: He is active \n",
            "in community and national af-\n",
            "fairs, and is the President \n",
            "of three companies \n",
            "headquartered in \n",
            "Solana Beach, \n",
            "California.\n",
            "--------------------\n",
            "Flashcard 141:\n",
            "  Front: the speed\n",
            "  Back: The Law of Attraction — Every time you rewrite or think about your goals, you \n",
            "intensify the speed of vibration that causes you to attract people and circumstances \n",
            "into your life that will help you achieve your goals.\n",
            "--------------------\n",
            "Flashcard 142:\n",
            "  Front: rst law\n",
            "  Back: The ﬁ rst law of success… is concentration — to blend all the energies to one \n",
            "point, and to go directly to that point, looking neither to the right nor to the \n",
            "left.\n",
            "--------------------\n",
            "Flashcard 143:\n",
            "  Front: Whose assistance\n",
            "  Back: Key People: Whose assistance or cooperation do you need?\n",
            "--------------------\n",
            "Flashcard 144:\n",
            "  Front: GOAL NUMBER THREE\n",
            "  Back: 14\n",
            "GOAL NUMBER THREE:\n",
            " \n",
            "ACTION STEPS \n",
            "ORDER\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 145:\n",
            "  Front: a company\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY – Author  •  Trainer  •  Consultant\n",
            "B\n",
            "rian Tracy is Chairman and CEO of \n",
            "Brian Tracy International, a company \n",
            "specializing in the training and devel-\n",
            "opment of individuals and organizations.\n",
            "--------------------\n",
            "Flashcard 146:\n",
            "  Front: re thinking\n",
            "  Back: Double your rate of \n",
            "failure… You’re thinking of failures as the enemy of success.\n",
            "--------------------\n",
            "Flashcard 147:\n",
            "  Front: great thing\n",
            "  Back: What one great thing would you dare to dream if you knew you could not \n",
            "fail?\n",
            "--------------------\n",
            "Flashcard 148:\n",
            "  Front: the next year\n",
            "  Back: You are about to embark on a journey of adventure and discovery that \n",
            "will enable you to accomplish more in the next year or two than many people accom-\n",
            "plish in ten years, or even twenty.\n",
            "--------------------\n",
            "Flashcard 149:\n",
            "  Front: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 150:\n",
            "  Front: the US\n",
            "  Back: ■   Brian Tracy has consulted for more than \n",
            "1,000 companies and addressed more than \n",
            "3,000,000 people in 4,000 talks and seminars \n",
            "throughout the US, Canada and 40 other coun-\n",
            "tries worldwide.\n",
            "--------------------\n",
            "Flashcard 151:\n",
            "  Front: any other quality\n",
            "  Back: 77\n",
            "I do not think there is any other quality so essential to success of any kind as \n",
            "the quality of perseverance.\n",
            "--------------------\n",
            "Flashcard 152:\n",
            "  Front: the eye\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 153:\n",
            "  Front: each year\n",
            "  Back: As a Keynote speaker and \n",
            "seminar leader, he addresses more than 250,000 \n",
            "people each year.\n",
            "--------------------\n",
            "Flashcard 154:\n",
            "  Front: the face\n",
            "  Back: Your ability to persist in the face of adversity will \n",
            "go up.\n",
            "--------------------\n",
            "Flashcard 155:\n",
            "  Front: major goal\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 156:\n",
            "  Front: twenty answers\n",
            "  Back: Write out twenty answers to this “mindstorming” question; (#5)\n",
            "7.\n",
            "--------------------\n",
            "Flashcard 157:\n",
            "  Front: the average person\n",
            "  Back: 82\n",
            "The potential of the average person is like a huge ocean unsailed,\n",
            "a new continent unexplored, a world of possibilities waiting to be released \n",
            "and channeled toward some great good.” — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 158:\n",
            "  Front: the page\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 159:\n",
            "  Front: this goal planner\n",
            "  Back: This goal planner has been designed after more than 25 years of research and practice.\n",
            "--------------------\n",
            "Flashcard 160:\n",
            "  Front: every idea\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 161:\n",
            "  Front: positive tense\n",
            "  Back: Write your goals in the present, positive tense, starting with the word “I.”\n",
            " \n",
            "(I am, I sell, I achieve, etc.)\n",
            "--------------------\n",
            "Flashcard 162:\n",
            "  Front: a bias\n",
            "  Back: 23\n",
            "Have a bias toward action — let’s see something happen now.\n",
            "--------------------\n",
            "Flashcard 163:\n",
            "  Front: that big plan\n",
            "  Back: You can \n",
            "break that big plan into small steps and take the ﬁ rst step right away.\n",
            "--------------------\n",
            "Flashcard 164:\n",
            "  Front: the one\n",
            "  Back: With your goals clearly before you, you are asked to select your most important goal, \n",
            "the one goal that, when you achieve it, will enable you to achieve many of your other \n",
            "goals as well.\n",
            "--------------------\n",
            "Flashcard 165:\n",
            "  Front: the world\n",
            "  Back: 65\n",
            "Nothing in the world can take the place of persistence.\n",
            "--------------------\n",
            "Flashcard 166:\n",
            "  Front: wonderful future\n",
            "  Back: After that, your wonderful future of health, wealth and happiness is assured.\n",
            "--------------------\n",
            "Flashcard 167:\n",
            "  Front: the support\n",
            "  Back: The rule is: Success depends on the support of other people.\n",
            "--------------------\n",
            "Flashcard 168:\n",
            "  Front: Continuous action\n",
            "  Back: Continuous action to-\n",
            "ward your goals must take place every day.\n",
            "--------------------\n",
            "Flashcard 169:\n",
            "  Front: conscious mind\n",
            "  Back: The Law of Substitution — Whatever your conscious mind is thinking about, most \n",
            "of the time, is being accepted by your subconscious mind and it is being attracted \n",
            "into your life.\n",
            "--------------------\n",
            "Flashcard 170:\n",
            "  Front: every day\n",
            "  Back: You \n",
            "are asked to rewrite your goals every day, and make plans for their accomplishment.\n",
            "--------------------\n",
            "Flashcard 171:\n",
            "  Front: any thought\n",
            "  Back: It simply says that, “any thought, plan, goal or idea, \n",
            "held continuously in your conscious mind, must be brought into reality by the super-\n",
            "conscious mind.”\n",
            "All these laws in combination will make you an irresistible and unstoppable force of \n",
            "nature.\n",
            "--------------------\n",
            "Flashcard 172:\n",
            "  Front: the day\n",
            "  Back: Work steadily toward the achieve-\n",
            "ment of your goal(s) throughout the day;\n",
            "9.\n",
            "--------------------\n",
            "Flashcard 173:\n",
            "  Front: YOUR MENTAL STOREHOUSE\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 174:\n",
            "  Front: systematic work\n",
            "  Back: Hard, systematic work is necessary.\n",
            "--------------------\n",
            "Flashcard 175:\n",
            "  Front: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 176:\n",
            "  Front: a deadline\n",
            "  Back: Timing: Set a deadline on your goal!\n",
            "--------------------\n",
            "Flashcard 177:\n",
            "  Front: Maximum Achievement\n",
            "  Back: You can learn the habits you need to reach Maximum Achievement by practicing \n",
            "continuous goal-setting and daily action planning until these behaviors become auto-\n",
            "matic.\n",
            "--------------------\n",
            "Flashcard 178:\n",
            "  Front: The only hurdle\n",
            "  Back: The only hurdle \n",
            "between you and what you want to be is the support of others.\n",
            "--------------------\n",
            "Flashcard 179:\n",
            "  Front: A whole stream\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 180:\n",
            "  Front: subconscious mind\n",
            "  Back: Your subconscious mind goes \n",
            "to work to bring your goals into your life — when you are ready.\n",
            "--------------------\n",
            "Flashcard 181:\n",
            "  Front: all manner\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 182:\n",
            "  Front: service goals\n",
            "  Back: Community and service goals: How do you want to contribute?\n",
            "--------------------\n",
            "Flashcard 183:\n",
            "  Front: outer world\n",
            "  Back: The Law of Belief — Your outer world of reality will be like your inner world of \n",
            "belief.\n",
            "--------------------\n",
            "Flashcard 184:\n",
            "  Front: every hour\n",
            "  Back: This concentration \n",
            "must be continuous, unceasing — every minute; every hour; every day; every week.\n",
            "--------------------\n",
            "Flashcard 185:\n",
            "  Front: material assistance\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 186:\n",
            "  Front: direct proportion\n",
            "  Back: 19\n",
            "I am not judged by the number of times I fail, but by the number of times \n",
            "I succeed; and the number of times I succeed is in direct proportion to the \n",
            "number of times I can fail and keep on trying.\n",
            "--------------------\n",
            "Flashcard 187:\n",
            "  Front: real estate\n",
            "  Back: He has had successful careers in sales \n",
            "and marketing, investments, real estate develop-\n",
            "ment and syndication, importation, distribution \n",
            "and management consulting.\n",
            "--------------------\n",
            "Flashcard 188:\n",
            "  Front: Major Goal .............................................................\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 189:\n",
            "  Front: daily action planning\n",
            "  Back: You can learn the habits you need to reach Maximum Achievement by practicing \n",
            "continuous goal-setting and daily action planning until these behaviors become auto-\n",
            "matic.\n",
            "--------------------\n",
            "Flashcard 190:\n",
            "  Front: thoughtful effort\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 191:\n",
            "  Front: The additional knowledge\n",
            "  Back: The additional knowledge and skills I will require are:\n",
            " \n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 192:\n",
            "  Front: seminar leader\n",
            "  Back: As a Keynote speaker and \n",
            "seminar leader, he addresses more than 250,000 \n",
            "people each year.\n",
            "--------------------\n",
            "Flashcard 193:\n",
            "  Front: a world\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 194:\n",
            "  Front: a positive goal\n",
            "  Back: You can substitute a positive goal or thought for any negative thought \n",
            "that may be holding you back.\n",
            "--------------------\n",
            "Flashcard 195:\n",
            "  Front: each day\n",
            "  Back: The Law of Expectations — Each day, you conﬁ dently expect that every event, \n",
            "positive or negative, has been sent to help move you toward your goals.\n",
            "--------------------\n",
            "Flashcard 196:\n",
            "  Front: the direction\n",
            "  Back: The Law of Control — Your goals allow you to control the direction of change \n",
            "in your life, thereby freeing you from aimlessness, drifting and random occurrences.\n",
            "--------------------\n",
            "Flashcard 197:\n",
            "  Front: this planner\n",
            "  Back: When you follow this planner, you \n",
            "will be able to accomplish anything you really want.\n",
            "--------------------\n",
            "Flashcard 198:\n",
            "  Front: the mind\n",
            "  Back: Only engage and the mind grows heated; begin \n",
            "and then the task will be completed.”\n",
            "Goethe\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 199:\n",
            "  Front: this Goal Planner\n",
            "  Back: This goal planner has been designed after more than 25 years of research and practice.\n",
            "--------------------\n",
            "Flashcard 200:\n",
            "  Front: The ﬁ\n",
            "  Back: ■   He has studied, researched, written and \n",
            "spoken for 30 years in the ﬁ elds of eco-\n",
            "nomics, history, business, philosophy \n",
            "and psychology.\n",
            "--------------------\n",
            "Flashcard 201:\n",
            "  Front: a complete goal list\n",
            "  Back: This will give you a complete goal list, organized by priority.\n",
            "--------------------\n",
            "Flashcard 202:\n",
            "  Front: a person\n",
            "  Back: Spiritual and inner development goals: What kind of a person do you want to \n",
            "become?\n",
            "--------------------\n",
            "Flashcard 203:\n",
            "  Front: the single-most\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 204:\n",
            "  Front: ve years\n",
            "  Back: ................................................................................$\n",
            " \n",
            "In ﬁ ve years?\n",
            "--------------------\n",
            "Flashcard 205:\n",
            "  Front: s life\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 206:\n",
            "  Front: untapped potential\n",
            "  Back: There lies within you a great, untapped potential that no \n",
            "one is yet aware of.\n",
            "--------------------\n",
            "Flashcard 207:\n",
            "  Front: rst rule\n",
            "  Back: The ﬁ rst rule of success, and the one that supersedes all others, is to have energy.\n",
            "--------------------\n",
            "Flashcard 208:\n",
            "  Front: every minute\n",
            "  Back: This concentration \n",
            "must be continuous, unceasing — every minute; every hour; every day; every week.\n",
            "--------------------\n",
            "Flashcard 209:\n",
            "  Front: every bit\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 210:\n",
            "  Front: the empire\n",
            "  Back: Concentrate… for the greatest achievements are reserved for the man of single aim, \n",
            "in who no rival powers divide the empire of the soul.\n",
            "--------------------\n",
            "Flashcard 211:\n",
            "  Front: self-conﬁ dence\n",
            "  Back: Your self-conﬁ dence and self-esteem will increase \n",
            "daily.\n",
            "--------------------\n",
            "Flashcard 212:\n",
            "  Front: the process\n",
            "  Back: Repeat the process every single day for 30 days until it becomes a habit.\n",
            "--------------------\n",
            "Flashcard 213:\n",
            "  Front: nd success\n",
            "  Back: Because, \n",
            "remember that’s where you’ll ﬁ nd success.\n",
            "--------------------\n",
            "Flashcard 214:\n",
            "  Front: No other element\n",
            "  Back: No other element can do so much for a man if he is \n",
            "willing to study them and make capital out of them.\n",
            "--------------------\n",
            "Flashcard 215:\n",
            "  Front: Each day\n",
            "  Back: The Law of Expectations — Each day, you conﬁ dently expect that every event, \n",
            "positive or negative, has been sent to help move you toward your goals.\n",
            "--------------------\n",
            "Flashcard 216:\n",
            "  Front: relationship goals\n",
            "  Back: Family and relationship goals: What do you want to do for your family?\n",
            "--------------------\n",
            "Flashcard 217:\n",
            "  Front: tness goals\n",
            "  Back: Sport and ﬁ tness goals: What do you want to achieve physically?\n",
            "--------------------\n",
            "Flashcard 218:\n",
            "  Front: the race\n",
            "  Back: The giants of the race have been men of concentration, who have struck sledge-\n",
            "hammer blows in one place until they have accomplished their purpose.\n",
            "--------------------\n",
            "Flashcard 219:\n",
            "  Front: all success\n",
            "  Back: 81\n",
            "The establishment of a clear, central purpose or goal in life\n",
            "is the starting point of all success.\n",
            "--------------------\n",
            "Flashcard 220:\n",
            "  Front: a formula for… success\n",
            "  Back: 27\n",
            "Would you like me to give you a formula for… success?\n",
            "--------------------\n",
            "Flashcard 221:\n",
            "  Front: the person\n",
            "  Back: Everything you have in your life \n",
            "you have attracted to yourself     \n",
            "because of the person you are.\n",
            "--------------------\n",
            "Flashcard 222:\n",
            "  Front: a life\n",
            "  Back: By completing this planner over the next 31 days, you will develop in yourself habits \n",
            "that will lead you irresistibly onward to a life of success and achievement.\n",
            "--------------------\n",
            "Flashcard 223:\n",
            "  Front: a basic rule\n",
            "  Back: Here is a basic rule for winning success — Let’s mark it in the mind and remember \n",
            "it.\n",
            "--------------------\n",
            "Flashcard 224:\n",
            "  Front: Napoleon Hill\n",
            "  Back: — Napoleon Hill\n",
            "D A Y\n",
            "2\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 225:\n",
            "  Front: major deﬁ\n",
            "  Back: Your major deﬁ nite purpose?\n",
            "--------------------\n",
            "Flashcard 226:\n",
            "  Front: an elementary truth\n",
            "  Back: Concerning all acts of initiative \n",
            "(and creation), there is an elementary truth, the ignorance of \n",
            "which kills countless ideas and splendid plans; that the moment \n",
            "one deﬁ nitely commits oneself, then Providence moves, too.\n",
            "--------------------\n",
            "Flashcard 227:\n",
            "  Front: This concentration\n",
            "  Back: This concentration \n",
            "must be continuous, unceasing — every minute; every hour; every day; every week.\n",
            "--------------------\n",
            "Flashcard 228:\n",
            "  Front: A central theme\n",
            "  Back: A central theme of Maximum Achievement is that you can have anything you want, as \n",
            "long as you know what it is.\n",
            "--------------------\n",
            "Flashcard 229:\n",
            "  Front: ” question\n",
            "  Back: Write out twenty answers to this “mindstorming” question; (#5)\n",
            "7.\n",
            "--------------------\n",
            "Flashcard 230:\n",
            "  Front: a series\n",
            "  Back: Every big \n",
            "accomplishment is a series of little accomplishments.\n",
            "--------------------\n",
            "Flashcard 231:\n",
            "  Front: no problem\n",
            "  Back: You are a potential genius; there is \n",
            "no problem you cannot solve, and \n",
            "no answer you cannot ﬁ nd some-\n",
            "where.\n",
            "--------------------\n",
            "Flashcard 232:\n",
            "  Front: the other fellow\n",
            "  Back: Always try to do something for the other fellow and you will be agreeably \n",
            "surprised how things come your way — how many pleasant things are done \n",
            "for you.\n",
            "--------------------\n",
            "Flashcard 233:\n",
            "  Front: a man\n",
            "  Back: No other element can do so much for a man if he is \n",
            "willing to study them and make capital out of them.\n",
            "--------------------\n",
            "Flashcard 234:\n",
            "  Front: inner world\n",
            "  Back: The Law of Belief — Your outer world of reality will be like your inner world of \n",
            "belief.\n",
            "--------------------\n",
            "Flashcard 235:\n",
            "  Front: A great occasion\n",
            "  Back: A great occasion is valuable to you just in proportion as you \n",
            "have educated yourself to make use of it.\n",
            "--------------------\n",
            "Flashcard 236:\n",
            "  Front: undue haste\n",
            "  Back: There is no road too long to the man who advances deliberately and without \n",
            "undue haste;  there are no honors too distant to the man who prepares himself \n",
            "for them with patience.\n",
            "--------------------\n",
            "Flashcard 237:\n",
            "  Front: the bottom\n",
            "  Back: Select an action commitment for today and write it in the box at the bottom of \n",
            "the page; (#6)\n",
            "8.\n",
            "--------------------\n",
            "Flashcard 238:\n",
            "  Front: A house\n",
            "  Back: A house is built a brick at a time.\n",
            "--------------------\n",
            "Flashcard 239:\n",
            "  Front: the kind\n",
            "  Back: You will become more focused, directed and channeled, like a mighty river, \n",
            "moving forward over all obstacles to create the kind of life you desire.\n",
            "--------------------\n",
            "Flashcard 240:\n",
            "  Front: a scale\n",
            "  Back: Desire: How much do you really want it on a scale of 1 - 10?\n",
            "--------------------\n",
            "Flashcard 241:\n",
            "  Front: a journey\n",
            "  Back: You are about to embark on a journey of adventure and discovery that \n",
            "will enable you to accomplish more in the next year or two than many people accom-\n",
            "plish in ten years, or even twenty.\n",
            "--------------------\n",
            "Flashcard 242:\n",
            "  Front: inner development goals\n",
            "  Back: Spiritual and inner development goals: What kind of a person do you want to \n",
            "become?\n",
            "--------------------\n",
            "Flashcard 243:\n",
            "  Front: complete charge\n",
            "  Back: You will take complete charge of your life and turn yourself into an unstop-\n",
            "pable, goal-achieving personality.\n",
            "--------------------\n",
            "Flashcard 244:\n",
            "  Front: the right-hand column\n",
            "  Back: In the right-hand column, organize your goals from #1 = most important to #7 = \n",
            "least important.\n",
            "--------------------\n",
            "Flashcard 245:\n",
            "  Front: the task\n",
            "  Back: Only engage and the mind grows heated; begin \n",
            "and then the task will be completed.”\n",
            "Goethe\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 246:\n",
            "  Front: skilled thinker\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 247:\n",
            "  Front: temporary defeat\n",
            "  Back: 21\n",
            "Opportunity… often it comes disguised in the form of misfortune,\n",
            "or temporary defeat.\n",
            "--------------------\n",
            "Flashcard 248:\n",
            "  Front: goal setting\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 249:\n",
            "  Front: the course\n",
            "  Back: Any one of them could change the course of his life overnight.\n",
            "--------------------\n",
            "Flashcard 250:\n",
            "  Front: a play\n",
            "  Back: Football games are won \n",
            "a play at a time.\n",
            "--------------------\n",
            "Flashcard 251:\n",
            "  Front: an action commitment\n",
            "  Back: Select an action commitment for today and write it in the box at the bottom of \n",
            "the page; (#6)\n",
            "8.\n",
            "--------------------\n",
            "Flashcard 252:\n",
            "  Front: countless ideas\n",
            "  Back: Concerning all acts of initiative \n",
            "(and creation), there is an elementary truth, the ignorance of \n",
            "which kills countless ideas and splendid plans; that the moment \n",
            "one deﬁ nitely commits oneself, then Providence moves, too.\n",
            "--------------------\n",
            "Flashcard 253:\n",
            "  Front: The establishment\n",
            "  Back: 81\n",
            "The establishment of a clear, central purpose or goal in life\n",
            "is the starting point of all success.\n",
            "--------------------\n",
            "Flashcard 254:\n",
            "  Front: the chance\n",
            "  Back: 17\n",
            "COMMITMENT\n",
            "“Until one is committed, there is hesitancy, the chance to draw \n",
            "back, always ineffectiveness.\n",
            "--------------------\n",
            "Flashcard 255:\n",
            "  Front: central purpose\n",
            "  Back: 81\n",
            "The establishment of a clear, central purpose or goal in life\n",
            "is the starting point of all success.\n",
            "--------------------\n",
            "Flashcard 256:\n",
            "  Front: development goals\n",
            "  Back: Personal development goals: In what areas do you want to improve?\n",
            "--------------------\n",
            "Flashcard 257:\n",
            "  Front: ACTION PLAN\n",
            "  Back: ACTION PLAN – What I will do immediately is:\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 258:\n",
            "  Front: rian Tracy\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY – Author  •  Trainer  •  Consultant\n",
            "B\n",
            "rian Tracy is Chairman and CEO of \n",
            "Brian Tracy International, a company \n",
            "specializing in the training and devel-\n",
            "opment of individuals and organizations.\n",
            "--------------------\n",
            "Flashcard 259:\n",
            "  Front: GOAL NUMBER ONE\n",
            "  Back: Start with number one:\n",
            "GOAL NUMBER ONE:\n",
            " \n",
            "ACTION STEPS \n",
            "ORDER\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 260:\n",
            "  Front: Success Psychology\n",
            "  Back: His exciting talks \n",
            "and seminars on Leadership, \n",
            "Selling, Self-Esteem, Goals, Strategy, Creativity \n",
            "and Success Psychology bring about immediate \n",
            "changes and long-term results.\n",
            "--------------------\n",
            "Flashcard 261:\n",
            "  Front: additional information\n",
            "  Back: Research: What additional information, knowledge and skills will you require?\n",
            "--------------------\n",
            "Flashcard 262:\n",
            "  Front: Goal Setting Exercises ..........................................................................\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 263:\n",
            "  Front: the place\n",
            "  Back: 43\n",
            "D A Y\n",
            "13\n",
            " /   /\n",
            "The majority of men meet with failure because of their lack of persistence \n",
            "in creating new plans to take the place of those which fail.\n",
            "--------------------\n",
            "Flashcard 264:\n",
            "  Front: the question\n",
            "  Back: In each case the question you ask yourself is: “What do I really want?\n",
            "--------------------\n",
            "Flashcard 265:\n",
            "  Front: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 266:\n",
            "  Front: a huge ocean\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 267:\n",
            "  Front: Stevens Avenue\n",
            "  Back: 462 Stevens Avenue, Suite 202\n",
            "Solana Beach, CA 92075\n",
            "858-436-7300 • 800-542-4252 • Fax 858-436-7301\n",
            "www.briantracy.com\n",
            "--------------------\n",
            "Flashcard 268:\n",
            "  Front: a new continent\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 269:\n",
            "  Front: an ingrained habit\n",
            "  Back: All you need to do is to practice continuous goal-setting and action planning \n",
            "every day until it becomes an ingrained habit.\n",
            "--------------------\n",
            "Flashcard 270:\n",
            "  Front: the future\n",
            "  Back: 73\n",
            "The empires of the future are the empires of the mind.\n",
            "--------------------\n",
            "Flashcard 271:\n",
            "  Front: the present tense\n",
            "  Back: Write out your major deﬁ nite purpose in the present tense, as if it were already \n",
            "a reality; (#2)\n",
            "4.\n",
            "--------------------\n",
            "Flashcard 272:\n",
            "  Front: any negative thought\n",
            "  Back: You can substitute a positive goal or thought for any negative thought \n",
            "that may be holding you back.\n",
            "--------------------\n",
            "Flashcard 273:\n",
            "  Front: The rule\n",
            "  Back: The rule is: Success depends on the support of other people.\n",
            "--------------------\n",
            "Flashcard 274:\n",
            "  Front: No man\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 275:\n",
            "  Front: no man\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 276:\n",
            "  Front: the training\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY – Author  •  Trainer  •  Consultant\n",
            "B\n",
            "rian Tracy is Chairman and CEO of \n",
            "Brian Tracy International, a company \n",
            "specializing in the training and devel-\n",
            "opment of individuals and organizations.\n",
            "--------------------\n",
            "Flashcard 277:\n",
            "  Front: maximum success\n",
            "  Back: The person determined to achieve maximum success learns the principle that progress \n",
            "is made one step at a time.\n",
            "--------------------\n",
            "Flashcard 278:\n",
            "  Front: This goal planner\n",
            "  Back: This goal planner has been designed after more than 25 years of research and practice.\n",
            "--------------------\n",
            "Flashcard 279:\n",
            "  Front: The successful person\n",
            "  Back: 25\n",
            "The successful person always has a number of projects planned, to which he \n",
            "looks forward.\n",
            "--------------------\n",
            "Flashcard 280:\n",
            "  Front: a state\n",
            "  Back: Success is a state of mind.\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "281d909f"
      },
      "source": [
        "## Format flashcards\n",
        "\n",
        "### Subtask:\n",
        "Create a method to format the extracted content into a flashcard format (e.g., a list of tuples or a dictionary).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62bca981"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the output format of `_extract_flashcard_content` and the `_format_flashcard` method to ensure the output is a list of dictionaries with 'front' and 'back' keys and the format method simply returns the input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96f80bf4"
      },
      "source": [
        "# Reviewing the methods in the existing class definition\n",
        "# The _extract_flashcard_content method returns a list of dictionaries with 'front' and 'back' keys.\n",
        "# The _format_flashcard method currently returns the input dictionary directly, which aligns with the desired output format.\n",
        "# No code modification is needed for this subtask."
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbd91d7c"
      },
      "source": [
        "## Add a user interface for flashcards\n",
        "\n",
        "### Subtask:\n",
        "Integrate the flashcard functionality into the `study_review` method or create a new method for users to access and view the generated flashcards.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592d5826"
      },
      "source": [
        "**Reasoning**:\n",
        "Integrate the flashcard functionality into the `study_review` method by adding new menu options for creating and viewing flashcards and including logic to display the generated flashcards.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ae827a2"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import fitz\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Ensure all necessary NLTK data is downloaded\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
        "except LookupError:\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "try:\n",
        "    nltk.data.find('chunkers/maxent_ne_chunker')\n",
        "except LookupError:\n",
        "    nltk.download('maxent_ne_chunker')\n",
        "try:\n",
        "    nltk.data.find('corpora/words')\n",
        "except LookupError:\n",
        "    nltk.download('words')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "try:\n",
        "    nltk.data.find('taggers/averaged_perceptron_tagger_eng')\n",
        "except LookupError:\n",
        "    nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None # This will be replaced by the embedding model\n",
        "        self.tfidf_matrix = None # This will be replaced by the embeddings\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "        self.embedding_model = None # New attribute for Sentence Transformer model\n",
        "        self.generated_flashcards = [] # To store generated flashcards\n",
        "\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "        # Initialize Sentence Transformer model for embeddings\n",
        "        try:\n",
        "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            print(\"Sentence Transformer model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Sentence Transformer model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.embedding_model = None\n",
        "\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Basic text cleaning.\"\"\"\n",
        "        text = text.lower() # Convert to lowercase\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove non-alphanumeric characters except spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        self.chapter_sections = {} # Clear existing sections\n",
        "\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index using Sentence Transformers.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "        if not self.embedding_model:\n",
        "            print(\"Sentence Transformer model not loaded. Cannot vectorize sections.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "\n",
        "        section_texts = list(self.chapter_sections.values())\n",
        "        print(f\"Creating embeddings for {len(section_texts)} sections...\")\n",
        "\n",
        "        try:\n",
        "            # Create embeddings using the Sentence Transformer model\n",
        "            embeddings = self.embedding_model.encode(section_texts, convert_to_numpy=True)\n",
        "            self.tfidf_matrix = embeddings # Store embeddings (renamed from tfidf_matrix)\n",
        "\n",
        "            # Create FAISS index\n",
        "            dimension = embeddings.shape[1]\n",
        "            if dimension > 0:\n",
        "                self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "                self.index.add(embeddings.astype('float32')) # FAISS requires float32\n",
        "                print(\"FAISS index created.\")\n",
        "                # Store the titles corresponding to the vectorized texts for later lookup\n",
        "                self._vectorized_section_titles = list(self.chapter_sections.keys()) # Store original titles\n",
        "            else:\n",
        "                print(\"Embeddings have no dimensions after vectorization. Cannot create FAISS index.\")\n",
        "                self.index = None\n",
        "                self._vectorized_section_titles = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during embedding creation or FAISS index creation: {e}\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            self._vectorized_section_titles = []\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "        if not self.embedding_model or not self.index or not hasattr(self, '_vectorized_section_titles') or not self._vectorized_section_titles:\n",
        "             return \"Book content not vectorized or index not created. Cannot answer questions.\"\n",
        "\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        try:\n",
        "            # Create embedding for the question\n",
        "            question_vec = self.embedding_model.encode([question], convert_to_numpy=True).astype('float32')\n",
        "            D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating question embedding or searching index: {e}\")\n",
        "            return \"Could not process the question for searching.\"\n",
        "\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        # Use the stored vectorized section titles to get the correct title\n",
        "        relevant_section_title = self._vectorized_section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title] # Use original text for QA\n",
        "\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context) # Use original question for QA pipeline\n",
        "            return f\"Answer: {answer['answer']} (Source: '{relevant_section_title}', Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section from '{relevant_section_title}':\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "    def create_flashcards(self, section_identifier=None):\n",
        "        \"\"\"Generates flashcards from the book content, optionally from a specific section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for flashcard creation.\"\n",
        "\n",
        "        sections_to_process = {}\n",
        "        if section_identifier:\n",
        "            section_titles = list(self.chapter_sections.keys())\n",
        "            section_text = None\n",
        "            section_title = None\n",
        "\n",
        "            try:\n",
        "                # Try to find by number (1-based index)\n",
        "                section_index = int(section_identifier) - 1\n",
        "                if 0 <= section_index < len(section_titles):\n",
        "                    section_title = section_titles[section_index]\n",
        "                    section_text = self.chapter_sections[section_title]\n",
        "            except ValueError:\n",
        "                # If not a number, try to find by partial title match\n",
        "                for title in section_titles:\n",
        "                    if section_identifier.lower() in title.lower():\n",
        "                        section_title = title\n",
        "                        section_text = self.chapter_sections[title]\n",
        "                        break\n",
        "\n",
        "            if section_text is None:\n",
        "                return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "            sections_to_process[section_title] = section_text\n",
        "            print(f\"Generating flashcards for section: '{section_title}'\")\n",
        "        else:\n",
        "            sections_to_process = self.chapter_sections\n",
        "            print(\"Generating flashcards for the entire book.\")\n",
        "\n",
        "        all_flashcards = []\n",
        "        for title, text in sections_to_process.items():\n",
        "            flashcards = self._extract_flashcard_content(text)\n",
        "            formatted_flashcards = [self._format_flashcard(fc) for fc in flashcards]\n",
        "            all_flashcards.extend(formatted_flashcards)\n",
        "\n",
        "        if all_flashcards:\n",
        "            print(f\"Generated {len(all_flashcards)} potential flashcards.\")\n",
        "            self.generated_flashcards = all_flashcards # Store generated flashcards\n",
        "            return all_flashcards\n",
        "        else:\n",
        "            self.generated_flashcards = []\n",
        "            return \"Could not generate any flashcards from the selected content.\"\n",
        "\n",
        "\n",
        "    def _extract_flashcard_content(self, text):\n",
        "        \"\"\"Identifies and extracts potential flashcard material from text using NLP.\"\"\"\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "        flashcard_candidates = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Skip very short sentences\n",
        "            if len(sentence.split()) < 8: # Increased minimum length\n",
        "                continue\n",
        "\n",
        "            # Try to extract Term-Definition pairs using POS tagging and dependency parsing heuristics\n",
        "            tokens = nltk.word_tokenize(sentence)\n",
        "            pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "            # Look for patterns like \"Term is a Definition\" or \"Term refers to Definition\"\n",
        "            # This is still heuristic but more targeted\n",
        "            definition_patterns = [\n",
        "                (r'(.+)\\s+(is a|is the|refers to)\\s+(.+)\\.', 'What is {term}?'),\n",
        "                (r'(.+)\\s+(are|include)\\s+(.+)\\.', 'What are {term}?'),\n",
        "            ]\n",
        "\n",
        "            for pattern, question_template in definition_patterns:\n",
        "                match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "                if match:\n",
        "                    term = match.group(1).strip()\n",
        "                    definition = match.group(3).strip()\n",
        "                    # Basic filtering for reasonable term/definition length\n",
        "                    if 3 <= len(term.split()) <= 10 and len(definition.split()) >= 5:\n",
        "                         flashcard_candidates.append({'front': question_template.format(term=term), 'back': definition})\n",
        "                         # Once a definition is found, move to the next sentence\n",
        "                         break # Break out of pattern loop, continue to next sentence\n",
        "\n",
        "            # As a fallback, consider sentences with question marks\n",
        "            if sentence.strip().endswith('?'):\n",
        "                front = sentence.strip()\n",
        "                # Try to find a concise answer in the following sentence(s)\n",
        "                answer_found = False\n",
        "                for i, next_sentence in enumerate(sentences[sentences.index(sentence)+1:]):\n",
        "                    # Consider sentences that are not too long as potential answers\n",
        "                    if 5 <= len(next_sentence.split()) <= 30:\n",
        "                        back = next_sentence.strip()\n",
        "                        flashcard_candidates.append({'front': front, 'back': back})\n",
        "                        answer_found = True\n",
        "                        break\n",
        "                    if i > 3: # Don't look too far ahead\n",
        "                        break\n",
        "                if not answer_found:\n",
        "                     # If no good answer found, use a placeholder or the original sentence (truncated)\n",
        "                     back = sentence.strip()[:100] + \"...\" if len(sentence) > 100 else sentence.strip()\n",
        "                     flashcard_candidates.append({'front': front, 'back': f\"Answer not found nearby. Relevant context: {back}\"})\n",
        "\n",
        "\n",
        "        # Additional heuristic: Extracting key terms and their surrounding sentence as definition\n",
        "        # Identify potential key terms (e.g., prominent noun phrases)\n",
        "        terms_to_consider = set()\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "        grammar = \"NP: {<DT>?<JJ>*<NNP>+|<DT>?<JJ>*<NN>+<NNS>?}\" # More specific NP pattern\n",
        "        cp = nltk.RegexpParser(grammar)\n",
        "        tree = cp.parse(pos_tags)\n",
        "\n",
        "        for subtree in tree.subtrees():\n",
        "            if subtree.label() == 'NP':\n",
        "                term = \" \".join([word for (word, tag) in subtree.leaves()])\n",
        "                # Filter terms based on length and common words\n",
        "                if 2 <= len(term.split()) <= 5 and term.lower() not in ['the', 'a', 'is', 'are', 'this', 'that', 'it']:\n",
        "                     terms_to_consider.add(term)\n",
        "\n",
        "        # Create flashcards for key terms by finding sentences where they appear\n",
        "        for term in terms_to_consider:\n",
        "             for sentence in sentences:\n",
        "                  if re.search(r'\\b' + re.escape(term) + r'\\b', sentence, re.IGNORECASE):\n",
        "                       # Use the term as the front, and the sentence (or a part of it) as the back\n",
        "                       front = term.strip()\n",
        "                       back = sentence.strip()\n",
        "                       # Avoid creating duplicate flashcards if already captured by other patterns\n",
        "                       if {'front': front, 'back': back} not in flashcard_candidates:\n",
        "                           flashcard_candidates.append({'front': front, 'back': back})\n",
        "                           break # Move to the next term after finding one sentence\n",
        "\n",
        "\n",
        "        return flashcard_candidates\n",
        "\n",
        "\n",
        "    def _format_flashcard(self, flashcard_data):\n",
        "        \"\"\"Formats the extracted content into a flashcard structure.\"\"\"\n",
        "        # In this basic implementation, the data is already in the desired format.\n",
        "        # This method serves as a placeholder for more complex formatting if needed.\n",
        "        return flashcard_data\n",
        "\n",
        "    def view_flashcards(self):\n",
        "        \"\"\"Displays the generated flashcards.\"\"\"\n",
        "        if not self.generated_flashcards:\n",
        "            return \"No flashcards have been generated yet. Please create them first.\"\n",
        "\n",
        "        print(\"\\n--- Generated Flashcards ---\")\n",
        "        for i, fc in enumerate(self.generated_flashcards):\n",
        "            print(f\"Flashcard {i+1}:\")\n",
        "            print(f\"  Front: {fc['front']}\")\n",
        "            print(f\"  Back: {fc['back']}\")\n",
        "            print(\"-\" * 20)\n",
        "        return f\"Displayed {len(self.generated_flashcards)} flashcards.\"\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No book loaded for study/review.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Create Flashcards (Entire Book)\")\n",
        "        print(\"5. Create Flashcards (Specific Section)\")\n",
        "        print(\"6. View Generated Flashcards\") # New option\n",
        "        print(\"7. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                flashcard_result = self.create_flashcards()\n",
        "                if isinstance(flashcard_result, str):\n",
        "                    print(flashcard_result) # Print error message\n",
        "                else:\n",
        "                    print(\"Flashcards generated. Use option 6 to view them.\")\n",
        "            elif choice == '5':\n",
        "                section_input = input(\"Enter the chapter/section number or name to create flashcards from: \")\n",
        "                flashcard_result = self.create_flashcards(section_input)\n",
        "                if isinstance(flashcard_result, str):\n",
        "                    print(flashcard_result) # Print error message\n",
        "                else:\n",
        "                     print(\"Flashcards generated. Use option 6 to view them.\")\n",
        "            elif choice == '6': # New option\n",
        "                view_result = self.view_flashcards()\n",
        "                print(view_result)\n",
        "            elif choice == '7':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# --- How to use the agent in Colab ---\n",
        "\n",
        "# 1. Mount Google Drive to access your files (optional, but common)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# 2. Create an instance of the BookQA agent\n",
        "# agent = BookQA()\n",
        "\n",
        "# 3. Upload a book (replace the path with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "# book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "# print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "# agent.upload_book(book_path)\n",
        "\n",
        "# --- Now you can interact with the agent ---\n",
        "\n",
        "# To enter the study/review mode and test flashcards:\n",
        "# if agent.book_text:\n",
        "#     agent.study_review()\n",
        "# else:\n",
        "#     print(\"\\nBook was not loaded successfully. Please check the file path and format.\")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a388939f"
      },
      "source": [
        "## Test and refine flashcard creation\n",
        "\n",
        "### Subtask:\n",
        "Test the flashcard creation with different sections of a book to ensure relevant and well-formatted flashcards are generated. Refine the extraction logic as needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc8ab4a5"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a new instance of the BookQA agent to load the updated code, upload a book, and then list the sections to prepare for testing flashcard creation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb75091b",
        "outputId": "90ae4851-fba5-49e9-a1c6-e2e4e5c694d4"
      },
      "source": [
        "# 2. Create an instance of the BookQA agent to load the updated code\n",
        "agent = BookQA()\n",
        "\n",
        "# 3. Upload a book (replace the path with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # Using the problematic file again\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)\n",
        "\n",
        "# 4. List sections to see available options\n",
        "if agent.chapter_sections:\n",
        "    print(\"\\nBook processed successfully. Listing sections:\")\n",
        "    agent.list_sections()\n",
        "else:\n",
        "    print(\"\\nBook processing failed.\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization model loaded.\n",
            "Sentence Transformer model loaded.\n",
            "Models initialized.\n",
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Creating embeddings for 1 sections...\n",
            "FAISS index created.\n",
            "\n",
            "Book processed successfully. Listing sections:\n",
            "Chapters/Sections:\n",
            "1. Introduction/Beginning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c26fe269"
      },
      "source": [
        "**Reasoning**:\n",
        "Call the create_flashcards method for the identified section and then call the view_flashcards method to display them and examine their quality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAp_v3-qqsV2",
        "outputId": "19eb2bf5-07c1-4411-e4e9-ec58f7067b22"
      },
      "source": [
        "# 5. Call create_flashcards for the first section\n",
        "if agent.chapter_sections:\n",
        "    first_section_key = list(agent.chapter_sections.keys())[0]\n",
        "    print(f\"\\nAttempting to create flashcards from section: {first_section_key}\")\n",
        "    flashcard_result = agent.create_flashcards(first_section_key)\n",
        "\n",
        "    # 6. View the generated flashcards\n",
        "    view_result = agent.view_flashcards()\n",
        "    print(view_result)\n",
        "\n",
        "    # Note down observations on the quality of flashcards here after viewing the output.\n",
        "    # Observation: The generated flashcards are based on simple pattern matching and key term extraction.\n",
        "    # They might not be perfect Q&A pairs or definitions and may require further refinement of the extraction logic.\n",
        "    # For this specific book (\"Brian Tracy Goal Planner\"), the \"Introduction/Beginning\" section\n",
        "    # seems to contain mostly introductory text and book structure, which might not yield\n",
        "    # many high-quality flashcards with the current heuristic-based extraction.\n",
        "    # More specific sections on \"Goal Setting\" or \"Action Planning\" might yield better results.\n",
        "    # However, given there's only one identified section, the current test is limited.\n",
        "\n",
        "else:\n",
        "    print(\"\\nBook processing failed. Cannot create flashcards.\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to create flashcards from section: Introduction/Beginning\n",
            "Generating flashcards for section: 'Introduction/Beginning'\n",
            "Generated 280 potential flashcards.\n",
            "\n",
            "--- Generated Flashcards ---\n",
            "Flashcard 1:\n",
            "  Front: In each case the question you ask yourself is: “What do I really want?\n",
            "  Back: What are my \n",
            "real goals in life?”\n",
            "You are asked to think about your major goals based on ten goal-achieving criteria.\n",
            "--------------------\n",
            "Flashcard 2:\n",
            "  Front: How would you spend your time, where would you go, what would you do, if \n",
            "you found out today that you only had six months to live?\n",
            "  Back: Answer not found nearby. Relevant context: How would you spend your time, where would you go, what would you do, if \n",
            "you found out today that y...\n",
            "--------------------\n",
            "Flashcard 3:\n",
            "  Front: What would you do differently if you won one million dollars cash, tax free, \n",
            "tomorrow?\n",
            "  Back: What have you always wanted to do but been afraid to attempt?\n",
            "--------------------\n",
            "Flashcard 4:\n",
            "  Front: What have you always wanted to do but been afraid to attempt?\n",
            "  Back: Answer not found nearby. Relevant context: What have you always wanted to do but been afraid to attempt?\n",
            "--------------------\n",
            "Flashcard 5:\n",
            "  Front: What do you enjoy doing most in life?\n",
            "  Back: If you could engage in any full-time \n",
            "activity, without pay, what would it be?\n",
            "--------------------\n",
            "Flashcard 6:\n",
            "  Front: If you could engage in any full-time \n",
            "activity, without pay, what would it be?\n",
            "  Back: How much money would you like to be earning?\n",
            "--------------------\n",
            "Flashcard 7:\n",
            "  Front: How much money would you like to be earning?\n",
            "  Back: ................................................................................$\n",
            " \n",
            "In ﬁ ve years?\n",
            "--------------------\n",
            "Flashcard 8:\n",
            "  Front: How much do you want to be worth when you retire?\n",
            "  Back: ............... $ __________\n",
            "8. \n",
            "Who else is earning the kind of money you want to earn?\n",
            "--------------------\n",
            "Flashcard 9:\n",
            "  Front: ............... $ __________\n",
            "8. \n",
            "Who else is earning the kind of money you want to earn?\n",
            "  Back: What is he/she doing differently from you that enables him/her to earn this \n",
            "kind of money?\n",
            "--------------------\n",
            "Flashcard 10:\n",
            "  Front: What is he/she doing differently from you that enables him/her to earn this \n",
            "kind of money?\n",
            "  Back: Answer not found nearby. Relevant context: What is he/she doing differently from you that enables him/her to earn this \n",
            "kind of money?\n",
            "--------------------\n",
            "Flashcard 11:\n",
            "  Front: Career and professional goals: What do you want to be good at?\n",
            "  Back: Sport and ﬁ tness goals: What do you want to achieve physically?\n",
            "--------------------\n",
            "Flashcard 12:\n",
            "  Front: Sport and ﬁ tness goals: What do you want to achieve physically?\n",
            "  Back: Personal development goals: In what areas do you want to improve?\n",
            "--------------------\n",
            "Flashcard 13:\n",
            "  Front: Personal development goals: In what areas do you want to improve?\n",
            "  Back: Family and relationship goals: What do you want to do for your family?\n",
            "--------------------\n",
            "Flashcard 14:\n",
            "  Front: Family and relationship goals: What do you want to do for your family?\n",
            "  Back: Travel goals — places to visit/vacations: Where do you want to go?\n",
            "--------------------\n",
            "Flashcard 15:\n",
            "  Front: Travel goals — places to visit/vacations: Where do you want to go?\n",
            "  Back: Material and tangible goals (things): What do you want to acquire?\n",
            "--------------------\n",
            "Flashcard 16:\n",
            "  Front: Material and tangible goals (things): What do you want to acquire?\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 17:\n",
            "  Front: Community and service goals: How do you want to contribute?\n",
            "  Back: Creative goals: What do you want to bring into reality?\n",
            "--------------------\n",
            "Flashcard 18:\n",
            "  Front: Creative goals: What do you want to bring into reality?\n",
            "  Back: Spiritual and inner development goals: What kind of a person do you want to \n",
            "become?\n",
            "--------------------\n",
            "Flashcard 19:\n",
            "  Front: Spiritual and inner development goals: What kind of a person do you want to \n",
            "become?\n",
            "  Back: Intellectual and educational goals: What do you want to learn?\n",
            "--------------------\n",
            "Flashcard 20:\n",
            "  Front: Intellectual and educational goals: What do you want to learn?\n",
            "  Back: What one great thing would you dare to dream if you knew you could not \n",
            "fail?\n",
            "--------------------\n",
            "Flashcard 21:\n",
            "  Front: What one great thing would you dare to dream if you knew you could not \n",
            "fail?\n",
            "  Back: If you were guaranteed of success?\n",
            "--------------------\n",
            "Flashcard 22:\n",
            "  Front: If you could have any one goal on this list within 24 hours, which one goal \n",
            "would you choose?\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 23:\n",
            "  Front: Based on these exercises, what do you think should be your most important \n",
            "goal?\n",
            "  Back: Your major deﬁ nite purpose?\n",
            "--------------------\n",
            "Flashcard 24:\n",
            "  Front: Desire: How much do you really want it on a scale of 1 - 10?\n",
            "  Back: Belief: Is it believable and achievable?\n",
            "--------------------\n",
            "Flashcard 25:\n",
            "  Front: Write it down: How will you measure success?\n",
            "  Back: Analyze: Where are you starting from now?\n",
            "--------------------\n",
            "Flashcard 26:\n",
            "  Front: Determine Why : How will you personally beneﬁ t from achieving it?\n",
            "  Back: Timing: Set a deadline on your goal!\n",
            "--------------------\n",
            "Flashcard 27:\n",
            "  Front: Research: What additional information, knowledge and skills will you require?\n",
            "  Back: Key People: Whose assistance or cooperation do you need?\n",
            "--------------------\n",
            "Flashcard 28:\n",
            "  Front: Key People: Whose assistance or cooperation do you need?\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 29:\n",
            "  Front: Write it out clearly; what are you going to do, starting today, \n",
            "and every day?\n",
            "  Back: The more detailed your description, the more likely it is that you \n",
            "will achieve it!\n",
            "--------------------\n",
            "Flashcard 30:\n",
            "  Front: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "  Back: Seek this very minute, whatever you can do, \n",
            "or dream you can; begin it.\n",
            "--------------------\n",
            "Flashcard 31:\n",
            "  Front: 27\n",
            "Would you like me to give you a formula for… success?\n",
            "  Back: Double your rate of \n",
            "failure… You’re thinking of failures as the enemy of success.\n",
            "--------------------\n",
            "Flashcard 32:\n",
            "  Front: What are The empires of the future?\n",
            "  Back: the empires of the mind\n",
            "--------------------\n",
            "Flashcard 33:\n",
            "  Front: a habit\n",
            "  Back: Repeat the process every single day for 30 days until it becomes a habit.\n",
            "--------------------\n",
            "Flashcard 34:\n",
            "  Front: a potential genius\n",
            "  Back: You are a potential genius; there is \n",
            "no problem you cannot solve, and \n",
            "no answer you cannot ﬁ nd some-\n",
            "where.\n",
            "--------------------\n",
            "Flashcard 35:\n",
            "  Front: intense purpose\n",
            "  Back: The suc-\n",
            "cessful men of today are men of one overmastering idea, one unwavering aim, \n",
            "men of single and intense purpose.\n",
            "--------------------\n",
            "Flashcard 36:\n",
            "  Front: the great desire\n",
            "  Back: Concentrate all your thoughts on the great desire in your life.\n",
            "--------------------\n",
            "Flashcard 37:\n",
            "  Front: Goal Planner\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 38:\n",
            "  Front: the box\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 39:\n",
            "  Front: an inevitable part\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 40:\n",
            "  Front: every single day\n",
            "  Back: Repeat the process every single day for 30 days until it becomes a habit.\n",
            "--------------------\n",
            "Flashcard 41:\n",
            "  Front: action steps\n",
            "  Back: Start with number one:\n",
            "GOAL NUMBER ONE:\n",
            " \n",
            "ACTION STEPS \n",
            "ORDER\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 42:\n",
            "  Front: Mental Storehouse\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 43:\n",
            "  Front: the ﬁ\n",
            "  Back: ■   He has studied, researched, written and \n",
            "spoken for 30 years in the ﬁ elds of eco-\n",
            "nomics, history, business, philosophy \n",
            "and psychology.\n",
            "--------------------\n",
            "Flashcard 44:\n",
            "  Front: the form\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 45:\n",
            "  Front: a new Goal Planner\n",
            "  Back: Order a new Goal Planner today so you can keep \n",
            "moving ahead.\n",
            "--------------------\n",
            "Flashcard 46:\n",
            "  Front: ll ﬁ\n",
            "  Back: Because, \n",
            "remember that’s where you’ll ﬁ nd success.\n",
            "--------------------\n",
            "Flashcard 47:\n",
            "  Front: the quality\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 48:\n",
            "  Front: Goal Planning — Day One\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 49:\n",
            "  Front: life overnight\n",
            "  Back: Any one of them could change the course of his life overnight.\n",
            "--------------------\n",
            "Flashcard 50:\n",
            "  Front: The person\n",
            "  Back: Everything you have in your life \n",
            "you have attracted to yourself     \n",
            "because of the person you are.\n",
            "--------------------\n",
            "Flashcard 51:\n",
            "  Front: GOAL SETTING EXERCISES\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 52:\n",
            "  Front: this goal\n",
            "  Back: This goal planner has been designed after more than 25 years of research and practice.\n",
            "--------------------\n",
            "Flashcard 53:\n",
            "  Front: Brian Tracy Univesity .........................................................................\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 54:\n",
            "  Front: a detailed plan\n",
            "  Back: FINALLY — Write out a detailed plan of accomplishment, a list of activities, \n",
            "for your major goal.\n",
            "--------------------\n",
            "Flashcard 55:\n",
            "  Front: no answer\n",
            "  Back: You are a potential genius; there is \n",
            "no problem you cannot solve, and \n",
            "no answer you cannot ﬁ nd some-\n",
            "where.\n",
            "--------------------\n",
            "Flashcard 56:\n",
            "  Front: a success\n",
            "  Back: Then your life will take on a success \n",
            "momentum of its own.\n",
            "--------------------\n",
            "Flashcard 57:\n",
            "  Front: the courage\n",
            "  Back: 69\n",
            "All our dreams come true — if we have the courage\n",
            "to pursue them.\n",
            "--------------------\n",
            "Flashcard 58:\n",
            "  Front: every word\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 59:\n",
            "  Front: The Law\n",
            "  Back: The Law of Control — Your goals allow you to control the direction of change \n",
            "in your life, thereby freeing you from aimlessness, drifting and random occurrences.\n",
            "--------------------\n",
            "Flashcard 60:\n",
            "  Front: this list\n",
            "  Back: If you could have any one goal on this list within 24 hours, which one goal \n",
            "would you choose?\n",
            "--------------------\n",
            "Flashcard 61:\n",
            "  Front: a manner\n",
            "  Back: The Law of Subconscious Activity — You will begin to walk, talk, act and per-\n",
            "ceive in a manner that will make your goals a reality.\n",
            "--------------------\n",
            "Flashcard 62:\n",
            "  Front: every area\n",
            "  Back: 2\n",
            "HOW TO USE YOUR GOAL PLANNER\n",
            "The purpose of this goal planner is to enable you to decide exactly what you want in \n",
            "every area of your life, and then to help you achieve it.\n",
            "--------------------\n",
            "Flashcard 63:\n",
            "  Front: t steal second base\n",
            "  Back: 79\n",
            "Progress always involves risk, you can’t steal second base and\n",
            "keep your foot on ﬁ rst.\n",
            "--------------------\n",
            "Flashcard 64:\n",
            "  Front: management consulting\n",
            "  Back: He has had successful careers in sales \n",
            "and marketing, investments, real estate develop-\n",
            "ment and syndication, importation, distribution \n",
            "and management consulting.\n",
            "--------------------\n",
            "Flashcard 65:\n",
            "  Front: the Ages\n",
            "  Back: The Law of Superconscious Activity — Called the “Secret of the Ages,” this is \n",
            "the most powerful of all laws.\n",
            "--------------------\n",
            "Flashcard 66:\n",
            "  Front: the word\n",
            "  Back: Write your goals in the present, positive tense, starting with the word “I.”\n",
            " \n",
            "(I am, I sell, I achieve, etc.)\n",
            "--------------------\n",
            "Flashcard 67:\n",
            "  Front: no road\n",
            "  Back: There is no road too long to the man who advances deliberately and without \n",
            "undue haste;  there are no honors too distant to the man who prepares himself \n",
            "for them with patience.\n",
            "--------------------\n",
            "Flashcard 68:\n",
            "  Front: the high road\n",
            "  Back: When you complete this planner, you will be on the high road to success and \n",
            "achievement in every area of your life.\n",
            "--------------------\n",
            "Flashcard 69:\n",
            "  Front: The majority\n",
            "  Back: 43\n",
            "D A Y\n",
            "13\n",
            " /   /\n",
            "The majority of men meet with failure because of their lack of persistence \n",
            "in creating new plans to take the place of those which fail.\n",
            "--------------------\n",
            "Flashcard 70:\n",
            "  Front: s date\n",
            "  Back: Begin with today’s date then, write down your three most important goals right \n",
            "now; (#1)\n",
            "3.\n",
            "--------------------\n",
            "Flashcard 71:\n",
            "  Front: the enemy\n",
            "  Back: Double your rate of \n",
            "failure… You’re thinking of failures as the enemy of success.\n",
            "--------------------\n",
            "Flashcard 72:\n",
            "  Front: a matter\n",
            "  Back: All of life is a matter of habit.\n",
            "--------------------\n",
            "Flashcard 73:\n",
            "  Front: a reality\n",
            "  Back: The Law of Subconscious Activity — You will begin to walk, talk, act and per-\n",
            "ceive in a manner that will make your goals a reality.\n",
            "--------------------\n",
            "Flashcard 74:\n",
            "  Front: GOAL NUMBER TWO\n",
            "  Back: 13\n",
            "GOAL NUMBER TWO:\n",
            " \n",
            "ACTION STEPS \n",
            "ORDER\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 75:\n",
            "  Front: major problem\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 76:\n",
            "  Front: BRIAN TRACY\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 77:\n",
            "  Front: every event\n",
            "  Back: The Law of Expectations — Each day, you conﬁ dently expect that every event, \n",
            "positive or negative, has been sent to help move you toward your goals.\n",
            "--------------------\n",
            "Flashcard 78:\n",
            "  Front: a Lifetime\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 79:\n",
            "  Front: the top\n",
            "  Back: He is the top selling \n",
            "author of 48 books that have been trans-\n",
            "lated into dozens of languages.\n",
            "--------------------\n",
            "Flashcard 80:\n",
            "  Front: unstoppable force\n",
            "  Back: It simply says that, “any thought, plan, goal or idea, \n",
            "held continuously in your conscious mind, must be brought into reality by the super-\n",
            "conscious mind.”\n",
            "All these laws in combination will make you an irresistible and unstoppable force of \n",
            "nature.\n",
            "--------------------\n",
            "Flashcard 81:\n",
            "  Front: an action person\n",
            "  Back: You are an action person, so take action today!\n",
            "--------------------\n",
            "Flashcard 82:\n",
            "  Front: every week\n",
            "  Back: This concentration \n",
            "must be continuous, unceasing — every minute; every hour; every day; every week.\n",
            "--------------------\n",
            "Flashcard 83:\n",
            "  Front: A department store grows\n",
            "  Back: A department store grows bigger one customer at a time.\n",
            "--------------------\n",
            "Flashcard 84:\n",
            "  Front: an idea\n",
            "  Back: 67\n",
            "There is one thing stronger than all the armies in the world and that is an idea \n",
            "whose time has come.\n",
            "--------------------\n",
            "Flashcard 85:\n",
            "  Front: Good luck\n",
            "  Back: Good luck!\n",
            "--------------------\n",
            "Flashcard 86:\n",
            "  Front: Travel goals\n",
            "  Back: Travel goals — places to visit/vacations: Where do you want to go?\n",
            "--------------------\n",
            "Flashcard 87:\n",
            "  Front: the President\n",
            "  Back: He is active \n",
            "in community and national af-\n",
            "fairs, and is the President \n",
            "of three companies \n",
            "headquartered in \n",
            "Solana Beach, \n",
            "California.\n",
            "--------------------\n",
            "Flashcard 88:\n",
            "  Front: prosperity consciousness\n",
            "  Back: 29\n",
            "The strongest single factor in prosperity consciousness is self-esteem: \n",
            "believing you can do it, believing you deserve it, believing you will get it.\n",
            "--------------------\n",
            "Flashcard 89:\n",
            "  Front: a question\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 90:\n",
            "  Front: a brick\n",
            "  Back: A house is built a brick at a time.\n",
            "--------------------\n",
            "Flashcard 91:\n",
            "  Front: Nothing splendid\n",
            "  Back: Nothing splendid has ever been achieved except by those who dared believe that \n",
            "something inside of them was superior to circumstance.\n",
            "--------------------\n",
            "Flashcard 92:\n",
            "  Front: own mind\n",
            "  Back: There are no limits on what you can \n",
            "achieve with your life, except the \n",
            "limits you accept in your own mind.\n",
            "--------------------\n",
            "Flashcard 93:\n",
            "  Front: the ignorance\n",
            "  Back: Concerning all acts of initiative \n",
            "(and creation), there is an elementary truth, the ignorance of \n",
            "which kills countless ideas and splendid plans; that the moment \n",
            "one deﬁ nitely commits oneself, then Providence moves, too.\n",
            "--------------------\n",
            "Flashcard 94:\n",
            "  Front: a list\n",
            "  Back: Ten Goal Exercise:\n",
            " \n",
            "Make a list of at least ten goals you would like to accomplish in the next year.\n",
            "--------------------\n",
            "Flashcard 95:\n",
            "  Front: life belongs\n",
            "  Back: No man has come to true greatness who has not felt that his life belongs to his race, \n",
            "that which God gives to him, he gives to mankind.\n",
            "--------------------\n",
            "Flashcard 96:\n",
            "  Front: a number\n",
            "  Back: 25\n",
            "The successful person always has a number of projects planned, to which he \n",
            "looks forward.\n",
            "--------------------\n",
            "Flashcard 97:\n",
            "  Front: take action today\n",
            "  Back: You are an action person, so take action today!\n",
            "--------------------\n",
            "Flashcard 98:\n",
            "  Front: speciﬁ c goals\n",
            "  Back: When you have clear, speciﬁ c goals that you are writing and rewriting every day, you \n",
            "trigger these laws into action on your behalf.\n",
            "--------------------\n",
            "Flashcard 99:\n",
            "  Front: the opportunity\n",
            "  Back: 63\n",
            "Unless you have prepared yourself to proﬁ t by your chance, the opportunity will only \n",
            "make you ridiculous.\n",
            "--------------------\n",
            "Flashcard 100:\n",
            "  Front: Effect — Clear\n",
            "  Back: The Law of Cause and Effect — Clear, repeated goals become the primary \n",
            "cause of the effects in your life.\n",
            "--------------------\n",
            "Flashcard 101:\n",
            "  Front: Attraction — Every\n",
            "  Back: The Law of Attraction — Every time you rewrite or think about your goals, you \n",
            "intensify the speed of vibration that causes you to attract people and circumstances \n",
            "into your life that will help you achieve your goals.\n",
            "--------------------\n",
            "Flashcard 102:\n",
            "  Front: the worldwide\n",
            "  Back: ■   He has written and produced more \n",
            "than 350 audio and video learning \n",
            "programs, including the worldwide, best-\n",
            "selling Psychology of Achieve-\n",
            "ment, which has been trans-\n",
            "lated into more than 20 \n",
            "languages.\n",
            "--------------------\n",
            "Flashcard 103:\n",
            "  Front: The purpose\n",
            "  Back: 2\n",
            "HOW TO USE YOUR GOAL PLANNER\n",
            "The purpose of this goal planner is to enable you to decide exactly what you want in \n",
            "every area of your life, and then to help you achieve it.\n",
            "--------------------\n",
            "Flashcard 104:\n",
            "  Front: single factor\n",
            "  Back: 29\n",
            "The strongest single factor in prosperity consciousness is self-esteem: \n",
            "believing you can do it, believing you deserve it, believing you will get it.\n",
            "--------------------\n",
            "Flashcard 105:\n",
            "  Front: The quality\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 106:\n",
            "  Front: Brian Tracy International\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY – Author  •  Trainer  •  Consultant\n",
            "B\n",
            "rian Tracy is Chairman and CEO of \n",
            "Brian Tracy International, a company \n",
            "specializing in the training and devel-\n",
            "opment of individuals and organizations.\n",
            "--------------------\n",
            "Flashcard 107:\n",
            "  Front: the man\n",
            "  Back: Concentrate… for the greatest achievements are reserved for the man of single aim, \n",
            "in who no rival powers divide the empire of the soul.\n",
            "--------------------\n",
            "Flashcard 108:\n",
            "  Front: Brian Tracy\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 109:\n",
            "  Front: FINALLY — Write\n",
            "  Back: FINALLY — Write out a detailed plan of accomplishment, a list of activities, \n",
            "for your major goal.\n",
            "--------------------\n",
            "Flashcard 110:\n",
            "  Front: a mighty river\n",
            "  Back: You will become more focused, directed and channeled, like a mighty river, \n",
            "moving forward over all obstacles to create the kind of life you desire.\n",
            "--------------------\n",
            "Flashcard 111:\n",
            "  Front: much money\n",
            "  Back: How much money would you like to be earning?\n",
            "--------------------\n",
            "Flashcard 112:\n",
            "  Front: D A Y\n",
            "  Back: — Tom Hopkins\n",
            "D A Y\n",
            "1\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 113:\n",
            "  Front: the moment\n",
            "  Back: Concerning all acts of initiative \n",
            "(and creation), there is an elementary truth, the ignorance of \n",
            "which kills countless ideas and splendid plans; that the moment \n",
            "one deﬁ nitely commits oneself, then Providence moves, too.\n",
            "--------------------\n",
            "Flashcard 114:\n",
            "  Front: the principle\n",
            "  Back: The person determined to achieve maximum success learns the principle that progress \n",
            "is made one step at a time.\n",
            "--------------------\n",
            "Flashcard 115:\n",
            "  Front: continuous goal-setting\n",
            "  Back: You can learn the habits you need to reach Maximum Achievement by practicing \n",
            "continuous goal-setting and daily action planning until these behaviors become auto-\n",
            "matic.\n",
            "--------------------\n",
            "Flashcard 116:\n",
            "  Front: a time\n",
            "  Back: Your success will be largely deter-\n",
            "mined by your ability to concen-\n",
            "trate single-mindedly on one thing \n",
            "at a time.\n",
            "--------------------\n",
            "Flashcard 117:\n",
            "  Front: that point\n",
            "  Back: The ﬁ rst law of success… is concentration — to blend all the energies to one \n",
            "point, and to go directly to that point, looking neither to the right nor to the \n",
            "left.\n",
            "--------------------\n",
            "Flashcard 118:\n",
            "  Front: a Keynote\n",
            "  Back: As a Keynote speaker and \n",
            "seminar leader, he addresses more than 250,000 \n",
            "people each year.\n",
            "--------------------\n",
            "Flashcard 119:\n",
            "  Front: useful bit\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 120:\n",
            "  Front: unwavering aim\n",
            "  Back: The suc-\n",
            "cessful men of today are men of one overmastering idea, one unwavering aim, \n",
            "men of single and intense purpose.\n",
            "--------------------\n",
            "Flashcard 121:\n",
            "  Front: each case\n",
            "  Back: In each case the question you ask yourself is: “What do I really want?\n",
            "--------------------\n",
            "Flashcard 122:\n",
            "  Front: goal-achieving personality\n",
            "  Back: You will take complete charge of your life and turn yourself into an unstop-\n",
            "pable, goal-achieving personality.\n",
            "--------------------\n",
            "Flashcard 123:\n",
            "  Front: important goal\n",
            "  Back: With your goals clearly before you, you are asked to select your most important goal, \n",
            "the one goal that, when you achieve it, will enable you to achieve many of your other \n",
            "goals as well.\n",
            "--------------------\n",
            "Flashcard 124:\n",
            "  Front: the start\n",
            "  Back: At the start of this planner, you are asked to think about your goals in several areas of \n",
            "your life.\n",
            "--------------------\n",
            "Flashcard 125:\n",
            "  Front: single aim\n",
            "  Back: Concentrate… for the greatest achievements are reserved for the man of single aim, \n",
            "in who no rival powers divide the empire of the soul.\n",
            "--------------------\n",
            "Flashcard 126:\n",
            "  Front: any kind\n",
            "  Back: 77\n",
            "I do not think there is any other quality so essential to success of any kind as \n",
            "the quality of perseverance.\n",
            "--------------------\n",
            "Flashcard 127:\n",
            "  Front: rst step\n",
            "  Back: You can \n",
            "break that big plan into small steps and take the ﬁ rst step right away.\n",
            "--------------------\n",
            "Flashcard 128:\n",
            "  Front: the number\n",
            "  Back: 19\n",
            "I am not judged by the number of times I fail, but by the number of times \n",
            "I succeed; and the number of times I succeed is in direct proportion to the \n",
            "number of times I can fail and keep on trying.\n",
            "--------------------\n",
            "Flashcard 129:\n",
            "  Front: a result\n",
            "  Back: If you only care enough for a result, you will almost certainly attain it… Only you \n",
            "must, then, really wish these things, and wish them exclusively, and not wish at the \n",
            "same time a hundred other incompatible things just as strongly.\n",
            "--------------------\n",
            "Flashcard 130:\n",
            "  Front: true greatness\n",
            "  Back: No man has come to true greatness who has not felt that his life belongs to his race, \n",
            "that which God gives to him, he gives to mankind.\n",
            "--------------------\n",
            "Flashcard 131:\n",
            "  Front: the soul\n",
            "  Back: Concentrate… for the greatest achievements are reserved for the man of single aim, \n",
            "in who no rival powers divide the empire of the soul.\n",
            "--------------------\n",
            "Flashcard 132:\n",
            "  Front: the habit\n",
            "  Back: Develop the habit of goal setting by completing two \n",
            "pages each day for 31 days;\n",
            "2.\n",
            "--------------------\n",
            "Flashcard 133:\n",
            "  Front: the time\n",
            "  Back: The Law of Substitution — Whatever your conscious mind is thinking about, most \n",
            "of the time, is being accepted by your subconscious mind and it is being attracted \n",
            "into your life.\n",
            "--------------------\n",
            "Flashcard 134:\n",
            "  Front: high level\n",
            "  Back: He has conducted \n",
            "high level consulting assignments with several \n",
            "billion-dollar plus corporations in strategic \n",
            "planning and organizational develop-\n",
            "ment.\n",
            "--------------------\n",
            "Flashcard 135:\n",
            "  Front: this “\n",
            "  Back: Write out twenty answers to this “mindstorming” question; (#5)\n",
            "7.\n",
            "--------------------\n",
            "Flashcard 136:\n",
            "  Front: action planning\n",
            "  Back: You can learn the habits you need to reach Maximum Achievement by practicing \n",
            "continuous goal-setting and daily action planning until these behaviors become auto-\n",
            "matic.\n",
            "--------------------\n",
            "Flashcard 137:\n",
            "  Front: The potential\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 138:\n",
            "  Front: The great secret\n",
            "  Back: The great secret of success is that \n",
            "there are no secrets of success; \n",
            "there are only timeless principles \n",
            "that have proven effective through-\n",
            "out the centuries.\n",
            "--------------------\n",
            "Flashcard 139:\n",
            "  Front: The pay-off\n",
            "  Back: The pay-off?\n",
            "--------------------\n",
            "Flashcard 140:\n",
            "  Front: Solana Beach\n",
            "  Back: He is active \n",
            "in community and national af-\n",
            "fairs, and is the President \n",
            "of three companies \n",
            "headquartered in \n",
            "Solana Beach, \n",
            "California.\n",
            "--------------------\n",
            "Flashcard 141:\n",
            "  Front: the speed\n",
            "  Back: The Law of Attraction — Every time you rewrite or think about your goals, you \n",
            "intensify the speed of vibration that causes you to attract people and circumstances \n",
            "into your life that will help you achieve your goals.\n",
            "--------------------\n",
            "Flashcard 142:\n",
            "  Front: rst law\n",
            "  Back: The ﬁ rst law of success… is concentration — to blend all the energies to one \n",
            "point, and to go directly to that point, looking neither to the right nor to the \n",
            "left.\n",
            "--------------------\n",
            "Flashcard 143:\n",
            "  Front: Whose assistance\n",
            "  Back: Key People: Whose assistance or cooperation do you need?\n",
            "--------------------\n",
            "Flashcard 144:\n",
            "  Front: GOAL NUMBER THREE\n",
            "  Back: 14\n",
            "GOAL NUMBER THREE:\n",
            " \n",
            "ACTION STEPS \n",
            "ORDER\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 145:\n",
            "  Front: a company\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY – Author  •  Trainer  •  Consultant\n",
            "B\n",
            "rian Tracy is Chairman and CEO of \n",
            "Brian Tracy International, a company \n",
            "specializing in the training and devel-\n",
            "opment of individuals and organizations.\n",
            "--------------------\n",
            "Flashcard 146:\n",
            "  Front: re thinking\n",
            "  Back: Double your rate of \n",
            "failure… You’re thinking of failures as the enemy of success.\n",
            "--------------------\n",
            "Flashcard 147:\n",
            "  Front: great thing\n",
            "  Back: What one great thing would you dare to dream if you knew you could not \n",
            "fail?\n",
            "--------------------\n",
            "Flashcard 148:\n",
            "  Front: the next year\n",
            "  Back: You are about to embark on a journey of adventure and discovery that \n",
            "will enable you to accomplish more in the next year or two than many people accom-\n",
            "plish in ten years, or even twenty.\n",
            "--------------------\n",
            "Flashcard 149:\n",
            "  Front: the above exercise\n",
            "  Back: Select at least one action from the above exercise to begin immediately:\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 150:\n",
            "  Front: the US\n",
            "  Back: ■   Brian Tracy has consulted for more than \n",
            "1,000 companies and addressed more than \n",
            "3,000,000 people in 4,000 talks and seminars \n",
            "throughout the US, Canada and 40 other coun-\n",
            "tries worldwide.\n",
            "--------------------\n",
            "Flashcard 151:\n",
            "  Front: any other quality\n",
            "  Back: 77\n",
            "I do not think there is any other quality so essential to success of any kind as \n",
            "the quality of perseverance.\n",
            "--------------------\n",
            "Flashcard 152:\n",
            "  Front: the eye\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 153:\n",
            "  Front: each year\n",
            "  Back: As a Keynote speaker and \n",
            "seminar leader, he addresses more than 250,000 \n",
            "people each year.\n",
            "--------------------\n",
            "Flashcard 154:\n",
            "  Front: the face\n",
            "  Back: Your ability to persist in the face of adversity will \n",
            "go up.\n",
            "--------------------\n",
            "Flashcard 155:\n",
            "  Front: major goal\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 156:\n",
            "  Front: twenty answers\n",
            "  Back: Write out twenty answers to this “mindstorming” question; (#5)\n",
            "7.\n",
            "--------------------\n",
            "Flashcard 157:\n",
            "  Front: the average person\n",
            "  Back: 82\n",
            "The potential of the average person is like a huge ocean unsailed,\n",
            "a new continent unexplored, a world of possibilities waiting to be released \n",
            "and channeled toward some great good.” — Brian Tracy\n",
            "NOTES\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 158:\n",
            "  Front: the page\n",
            "  Back: Turn the page; write your major problem or goal in the box at the top of the \n",
            "page in the form of a question; (#4)\n",
            "6.\n",
            "--------------------\n",
            "Flashcard 159:\n",
            "  Front: this goal planner\n",
            "  Back: This goal planner has been designed after more than 25 years of research and practice.\n",
            "--------------------\n",
            "Flashcard 160:\n",
            "  Front: every idea\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 161:\n",
            "  Front: positive tense\n",
            "  Back: Write your goals in the present, positive tense, starting with the word “I.”\n",
            " \n",
            "(I am, I sell, I achieve, etc.)\n",
            "--------------------\n",
            "Flashcard 162:\n",
            "  Front: a bias\n",
            "  Back: 23\n",
            "Have a bias toward action — let’s see something happen now.\n",
            "--------------------\n",
            "Flashcard 163:\n",
            "  Front: that big plan\n",
            "  Back: You can \n",
            "break that big plan into small steps and take the ﬁ rst step right away.\n",
            "--------------------\n",
            "Flashcard 164:\n",
            "  Front: the one\n",
            "  Back: With your goals clearly before you, you are asked to select your most important goal, \n",
            "the one goal that, when you achieve it, will enable you to achieve many of your other \n",
            "goals as well.\n",
            "--------------------\n",
            "Flashcard 165:\n",
            "  Front: the world\n",
            "  Back: 65\n",
            "Nothing in the world can take the place of persistence.\n",
            "--------------------\n",
            "Flashcard 166:\n",
            "  Front: wonderful future\n",
            "  Back: After that, your wonderful future of health, wealth and happiness is assured.\n",
            "--------------------\n",
            "Flashcard 167:\n",
            "  Front: the support\n",
            "  Back: The rule is: Success depends on the support of other people.\n",
            "--------------------\n",
            "Flashcard 168:\n",
            "  Front: Continuous action\n",
            "  Back: Continuous action to-\n",
            "ward your goals must take place every day.\n",
            "--------------------\n",
            "Flashcard 169:\n",
            "  Front: conscious mind\n",
            "  Back: The Law of Substitution — Whatever your conscious mind is thinking about, most \n",
            "of the time, is being accepted by your subconscious mind and it is being attracted \n",
            "into your life.\n",
            "--------------------\n",
            "Flashcard 170:\n",
            "  Front: every day\n",
            "  Back: You \n",
            "are asked to rewrite your goals every day, and make plans for their accomplishment.\n",
            "--------------------\n",
            "Flashcard 171:\n",
            "  Front: any thought\n",
            "  Back: It simply says that, “any thought, plan, goal or idea, \n",
            "held continuously in your conscious mind, must be brought into reality by the super-\n",
            "conscious mind.”\n",
            "All these laws in combination will make you an irresistible and unstoppable force of \n",
            "nature.\n",
            "--------------------\n",
            "Flashcard 172:\n",
            "  Front: the day\n",
            "  Back: Work steadily toward the achieve-\n",
            "ment of your goal(s) throughout the day;\n",
            "9.\n",
            "--------------------\n",
            "Flashcard 173:\n",
            "  Front: YOUR MENTAL STOREHOUSE\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 174:\n",
            "  Front: systematic work\n",
            "  Back: Hard, systematic work is necessary.\n",
            "--------------------\n",
            "Flashcard 175:\n",
            "  Front: any form\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 176:\n",
            "  Front: a deadline\n",
            "  Back: Timing: Set a deadline on your goal!\n",
            "--------------------\n",
            "Flashcard 177:\n",
            "  Front: Maximum Achievement\n",
            "  Back: You can learn the habits you need to reach Maximum Achievement by practicing \n",
            "continuous goal-setting and daily action planning until these behaviors become auto-\n",
            "matic.\n",
            "--------------------\n",
            "Flashcard 178:\n",
            "  Front: The only hurdle\n",
            "  Back: The only hurdle \n",
            "between you and what you want to be is the support of others.\n",
            "--------------------\n",
            "Flashcard 179:\n",
            "  Front: A whole stream\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 180:\n",
            "  Front: subconscious mind\n",
            "  Back: Your subconscious mind goes \n",
            "to work to bring your goals into your life — when you are ready.\n",
            "--------------------\n",
            "Flashcard 181:\n",
            "  Front: all manner\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 182:\n",
            "  Front: service goals\n",
            "  Back: Community and service goals: How do you want to contribute?\n",
            "--------------------\n",
            "Flashcard 183:\n",
            "  Front: outer world\n",
            "  Back: The Law of Belief — Your outer world of reality will be like your inner world of \n",
            "belief.\n",
            "--------------------\n",
            "Flashcard 184:\n",
            "  Front: every hour\n",
            "  Back: This concentration \n",
            "must be continuous, unceasing — every minute; every hour; every day; every week.\n",
            "--------------------\n",
            "Flashcard 185:\n",
            "  Front: material assistance\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 186:\n",
            "  Front: direct proportion\n",
            "  Back: 19\n",
            "I am not judged by the number of times I fail, but by the number of times \n",
            "I succeed; and the number of times I succeed is in direct proportion to the \n",
            "number of times I can fail and keep on trying.\n",
            "--------------------\n",
            "Flashcard 187:\n",
            "  Front: real estate\n",
            "  Back: He has had successful careers in sales \n",
            "and marketing, investments, real estate develop-\n",
            "ment and syndication, importation, distribution \n",
            "and management consulting.\n",
            "--------------------\n",
            "Flashcard 188:\n",
            "  Front: Major Goal .............................................................\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 189:\n",
            "  Front: daily action planning\n",
            "  Back: You can learn the habits you need to reach Maximum Achievement by practicing \n",
            "continuous goal-setting and daily action planning until these behaviors become auto-\n",
            "matic.\n",
            "--------------------\n",
            "Flashcard 190:\n",
            "  Front: thoughtful effort\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 191:\n",
            "  Front: The additional knowledge\n",
            "  Back: The additional knowledge and skills I will require are:\n",
            " \n",
            " \n",
            "1.\n",
            "--------------------\n",
            "Flashcard 192:\n",
            "  Front: seminar leader\n",
            "  Back: As a Keynote speaker and \n",
            "seminar leader, he addresses more than 250,000 \n",
            "people each year.\n",
            "--------------------\n",
            "Flashcard 193:\n",
            "  Front: a world\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 194:\n",
            "  Front: a positive goal\n",
            "  Back: You can substitute a positive goal or thought for any negative thought \n",
            "that may be holding you back.\n",
            "--------------------\n",
            "Flashcard 195:\n",
            "  Front: each day\n",
            "  Back: The Law of Expectations — Each day, you conﬁ dently expect that every event, \n",
            "positive or negative, has been sent to help move you toward your goals.\n",
            "--------------------\n",
            "Flashcard 196:\n",
            "  Front: the direction\n",
            "  Back: The Law of Control — Your goals allow you to control the direction of change \n",
            "in your life, thereby freeing you from aimlessness, drifting and random occurrences.\n",
            "--------------------\n",
            "Flashcard 197:\n",
            "  Front: this planner\n",
            "  Back: When you follow this planner, you \n",
            "will be able to accomplish anything you really want.\n",
            "--------------------\n",
            "Flashcard 198:\n",
            "  Front: the mind\n",
            "  Back: Only engage and the mind grows heated; begin \n",
            "and then the task will be completed.”\n",
            "Goethe\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 199:\n",
            "  Front: this Goal Planner\n",
            "  Back: This goal planner has been designed after more than 25 years of research and practice.\n",
            "--------------------\n",
            "Flashcard 200:\n",
            "  Front: The ﬁ\n",
            "  Back: ■   He has studied, researched, written and \n",
            "spoken for 30 years in the ﬁ elds of eco-\n",
            "nomics, history, business, philosophy \n",
            "and psychology.\n",
            "--------------------\n",
            "Flashcard 201:\n",
            "  Front: a complete goal list\n",
            "  Back: This will give you a complete goal list, organized by priority.\n",
            "--------------------\n",
            "Flashcard 202:\n",
            "  Front: a person\n",
            "  Back: Spiritual and inner development goals: What kind of a person do you want to \n",
            "become?\n",
            "--------------------\n",
            "Flashcard 203:\n",
            "  Front: the single-most\n",
            "  Back: If I were asked to give what I consider the single-most useful bit of advice for all \n",
            "humanity, it would be this: Expect trouble as an inevitable part of life and when it \n",
            "comes, hold your head high, look it squarely in the eye and say “I will be bigger \n",
            "than you.\n",
            "--------------------\n",
            "Flashcard 204:\n",
            "  Front: ve years\n",
            "  Back: ................................................................................$\n",
            " \n",
            "In ﬁ ve years?\n",
            "--------------------\n",
            "Flashcard 205:\n",
            "  Front: s life\n",
            "  Back: 71\n",
            "The quality of a person’s life is in direct proportion to their commitment to \n",
            "excellence, regardless of their chosen ﬁ eld of endeavor.\n",
            "--------------------\n",
            "Flashcard 206:\n",
            "  Front: untapped potential\n",
            "  Back: There lies within you a great, untapped potential that no \n",
            "one is yet aware of.\n",
            "--------------------\n",
            "Flashcard 207:\n",
            "  Front: rst rule\n",
            "  Back: The ﬁ rst rule of success, and the one that supersedes all others, is to have energy.\n",
            "--------------------\n",
            "Flashcard 208:\n",
            "  Front: every minute\n",
            "  Back: This concentration \n",
            "must be continuous, unceasing — every minute; every hour; every day; every week.\n",
            "--------------------\n",
            "Flashcard 209:\n",
            "  Front: every bit\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 210:\n",
            "  Front: the empire\n",
            "  Back: Concentrate… for the greatest achievements are reserved for the man of single aim, \n",
            "in who no rival powers divide the empire of the soul.\n",
            "--------------------\n",
            "Flashcard 211:\n",
            "  Front: self-conﬁ dence\n",
            "  Back: Your self-conﬁ dence and self-esteem will increase \n",
            "daily.\n",
            "--------------------\n",
            "Flashcard 212:\n",
            "  Front: the process\n",
            "  Back: Repeat the process every single day for 30 days until it becomes a habit.\n",
            "--------------------\n",
            "Flashcard 213:\n",
            "  Front: nd success\n",
            "  Back: Because, \n",
            "remember that’s where you’ll ﬁ nd success.\n",
            "--------------------\n",
            "Flashcard 214:\n",
            "  Front: No other element\n",
            "  Back: No other element can do so much for a man if he is \n",
            "willing to study them and make capital out of them.\n",
            "--------------------\n",
            "Flashcard 215:\n",
            "  Front: Each day\n",
            "  Back: The Law of Expectations — Each day, you conﬁ dently expect that every event, \n",
            "positive or negative, has been sent to help move you toward your goals.\n",
            "--------------------\n",
            "Flashcard 216:\n",
            "  Front: relationship goals\n",
            "  Back: Family and relationship goals: What do you want to do for your family?\n",
            "--------------------\n",
            "Flashcard 217:\n",
            "  Front: tness goals\n",
            "  Back: Sport and ﬁ tness goals: What do you want to achieve physically?\n",
            "--------------------\n",
            "Flashcard 218:\n",
            "  Front: the race\n",
            "  Back: The giants of the race have been men of concentration, who have struck sledge-\n",
            "hammer blows in one place until they have accomplished their purpose.\n",
            "--------------------\n",
            "Flashcard 219:\n",
            "  Front: all success\n",
            "  Back: 81\n",
            "The establishment of a clear, central purpose or goal in life\n",
            "is the starting point of all success.\n",
            "--------------------\n",
            "Flashcard 220:\n",
            "  Front: a formula for… success\n",
            "  Back: 27\n",
            "Would you like me to give you a formula for… success?\n",
            "--------------------\n",
            "Flashcard 221:\n",
            "  Front: the person\n",
            "  Back: Everything you have in your life \n",
            "you have attracted to yourself     \n",
            "because of the person you are.\n",
            "--------------------\n",
            "Flashcard 222:\n",
            "  Front: a life\n",
            "  Back: By completing this planner over the next 31 days, you will develop in yourself habits \n",
            "that will lead you irresistibly onward to a life of success and achievement.\n",
            "--------------------\n",
            "Flashcard 223:\n",
            "  Front: a basic rule\n",
            "  Back: Here is a basic rule for winning success — Let’s mark it in the mind and remember \n",
            "it.\n",
            "--------------------\n",
            "Flashcard 224:\n",
            "  Front: Napoleon Hill\n",
            "  Back: — Napoleon Hill\n",
            "D A Y\n",
            "2\n",
            " /   /\n",
            "DATE\n",
            "BACKGROUND IDEA FOR TODAY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 225:\n",
            "  Front: major deﬁ\n",
            "  Back: Your major deﬁ nite purpose?\n",
            "--------------------\n",
            "Flashcard 226:\n",
            "  Front: an elementary truth\n",
            "  Back: Concerning all acts of initiative \n",
            "(and creation), there is an elementary truth, the ignorance of \n",
            "which kills countless ideas and splendid plans; that the moment \n",
            "one deﬁ nitely commits oneself, then Providence moves, too.\n",
            "--------------------\n",
            "Flashcard 227:\n",
            "  Front: This concentration\n",
            "  Back: This concentration \n",
            "must be continuous, unceasing — every minute; every hour; every day; every week.\n",
            "--------------------\n",
            "Flashcard 228:\n",
            "  Front: A central theme\n",
            "  Back: A central theme of Maximum Achievement is that you can have anything you want, as \n",
            "long as you know what it is.\n",
            "--------------------\n",
            "Flashcard 229:\n",
            "  Front: ” question\n",
            "  Back: Write out twenty answers to this “mindstorming” question; (#5)\n",
            "7.\n",
            "--------------------\n",
            "Flashcard 230:\n",
            "  Front: a series\n",
            "  Back: Every big \n",
            "accomplishment is a series of little accomplishments.\n",
            "--------------------\n",
            "Flashcard 231:\n",
            "  Front: no problem\n",
            "  Back: You are a potential genius; there is \n",
            "no problem you cannot solve, and \n",
            "no answer you cannot ﬁ nd some-\n",
            "where.\n",
            "--------------------\n",
            "Flashcard 232:\n",
            "  Front: the other fellow\n",
            "  Back: Always try to do something for the other fellow and you will be agreeably \n",
            "surprised how things come your way — how many pleasant things are done \n",
            "for you.\n",
            "--------------------\n",
            "Flashcard 233:\n",
            "  Front: a man\n",
            "  Back: No other element can do so much for a man if he is \n",
            "willing to study them and make capital out of them.\n",
            "--------------------\n",
            "Flashcard 234:\n",
            "  Front: inner world\n",
            "  Back: The Law of Belief — Your outer world of reality will be like your inner world of \n",
            "belief.\n",
            "--------------------\n",
            "Flashcard 235:\n",
            "  Front: A great occasion\n",
            "  Back: A great occasion is valuable to you just in proportion as you \n",
            "have educated yourself to make use of it.\n",
            "--------------------\n",
            "Flashcard 236:\n",
            "  Front: undue haste\n",
            "  Back: There is no road too long to the man who advances deliberately and without \n",
            "undue haste;  there are no honors too distant to the man who prepares himself \n",
            "for them with patience.\n",
            "--------------------\n",
            "Flashcard 237:\n",
            "  Front: the bottom\n",
            "  Back: Select an action commitment for today and write it in the box at the bottom of \n",
            "the page; (#6)\n",
            "8.\n",
            "--------------------\n",
            "Flashcard 238:\n",
            "  Front: A house\n",
            "  Back: A house is built a brick at a time.\n",
            "--------------------\n",
            "Flashcard 239:\n",
            "  Front: the kind\n",
            "  Back: You will become more focused, directed and channeled, like a mighty river, \n",
            "moving forward over all obstacles to create the kind of life you desire.\n",
            "--------------------\n",
            "Flashcard 240:\n",
            "  Front: a scale\n",
            "  Back: Desire: How much do you really want it on a scale of 1 - 10?\n",
            "--------------------\n",
            "Flashcard 241:\n",
            "  Front: a journey\n",
            "  Back: You are about to embark on a journey of adventure and discovery that \n",
            "will enable you to accomplish more in the next year or two than many people accom-\n",
            "plish in ten years, or even twenty.\n",
            "--------------------\n",
            "Flashcard 242:\n",
            "  Front: inner development goals\n",
            "  Back: Spiritual and inner development goals: What kind of a person do you want to \n",
            "become?\n",
            "--------------------\n",
            "Flashcard 243:\n",
            "  Front: complete charge\n",
            "  Back: You will take complete charge of your life and turn yourself into an unstop-\n",
            "pable, goal-achieving personality.\n",
            "--------------------\n",
            "Flashcard 244:\n",
            "  Front: the right-hand column\n",
            "  Back: In the right-hand column, organize your goals from #1 = most important to #7 = \n",
            "least important.\n",
            "--------------------\n",
            "Flashcard 245:\n",
            "  Front: the task\n",
            "  Back: Only engage and the mind grows heated; begin \n",
            "and then the task will be completed.”\n",
            "Goethe\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 246:\n",
            "  Front: skilled thinker\n",
            "  Back: You will become a more skilled thinker with every word you write, with every idea you \n",
            "generate, with every bit of intense, thoughtful effort you put into writing and rewriting \n",
            "your goals.\n",
            "--------------------\n",
            "Flashcard 247:\n",
            "  Front: temporary defeat\n",
            "  Back: 21\n",
            "Opportunity… often it comes disguised in the form of misfortune,\n",
            "or temporary defeat.\n",
            "--------------------\n",
            "Flashcard 248:\n",
            "  Front: goal setting\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 249:\n",
            "  Front: the course\n",
            "  Back: Any one of them could change the course of his life overnight.\n",
            "--------------------\n",
            "Flashcard 250:\n",
            "  Front: a play\n",
            "  Back: Football games are won \n",
            "a play at a time.\n",
            "--------------------\n",
            "Flashcard 251:\n",
            "  Front: an action commitment\n",
            "  Back: Select an action commitment for today and write it in the box at the bottom of \n",
            "the page; (#6)\n",
            "8.\n",
            "--------------------\n",
            "Flashcard 252:\n",
            "  Front: countless ideas\n",
            "  Back: Concerning all acts of initiative \n",
            "(and creation), there is an elementary truth, the ignorance of \n",
            "which kills countless ideas and splendid plans; that the moment \n",
            "one deﬁ nitely commits oneself, then Providence moves, too.\n",
            "--------------------\n",
            "Flashcard 253:\n",
            "  Front: The establishment\n",
            "  Back: 81\n",
            "The establishment of a clear, central purpose or goal in life\n",
            "is the starting point of all success.\n",
            "--------------------\n",
            "Flashcard 254:\n",
            "  Front: the chance\n",
            "  Back: 17\n",
            "COMMITMENT\n",
            "“Until one is committed, there is hesitancy, the chance to draw \n",
            "back, always ineffectiveness.\n",
            "--------------------\n",
            "Flashcard 255:\n",
            "  Front: central purpose\n",
            "  Back: 81\n",
            "The establishment of a clear, central purpose or goal in life\n",
            "is the starting point of all success.\n",
            "--------------------\n",
            "Flashcard 256:\n",
            "  Front: development goals\n",
            "  Back: Personal development goals: In what areas do you want to improve?\n",
            "--------------------\n",
            "Flashcard 257:\n",
            "  Front: ACTION PLAN\n",
            "  Back: ACTION PLAN – What I will do immediately is:\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 258:\n",
            "  Front: rian Tracy\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY – Author  •  Trainer  •  Consultant\n",
            "B\n",
            "rian Tracy is Chairman and CEO of \n",
            "Brian Tracy International, a company \n",
            "specializing in the training and devel-\n",
            "opment of individuals and organizations.\n",
            "--------------------\n",
            "Flashcard 259:\n",
            "  Front: GOAL NUMBER ONE\n",
            "  Back: Start with number one:\n",
            "GOAL NUMBER ONE:\n",
            " \n",
            "ACTION STEPS \n",
            "ORDER\n",
            " 1.\n",
            "--------------------\n",
            "Flashcard 260:\n",
            "  Front: Success Psychology\n",
            "  Back: His exciting talks \n",
            "and seminars on Leadership, \n",
            "Selling, Self-Esteem, Goals, Strategy, Creativity \n",
            "and Success Psychology bring about immediate \n",
            "changes and long-term results.\n",
            "--------------------\n",
            "Flashcard 261:\n",
            "  Front: additional information\n",
            "  Back: Research: What additional information, knowledge and skills will you require?\n",
            "--------------------\n",
            "Flashcard 262:\n",
            "  Front: Goal Setting Exercises ..........................................................................\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "Introduction ...........................................................................................1\n",
            "How to Use Your Goal Planner .............................................................2\n",
            "Activating Your Mental Storehouse ......................................................3\n",
            "Goal Setting Exercises ..........................................................................5\n",
            "How to Test Your Major Goal .............................................................15\n",
            "Commitment .......................................................................................17\n",
            "Getting Started ....................................................................................18\n",
            "Goal Planning — Day One .................................................................19\n",
            "Product Offerings from Brian Tracy ...................................................84\n",
            "Brian Tracy Univesity .........................................................................85\n",
            "TABLE OF CONTENTS\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "© Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 263:\n",
            "  Front: the place\n",
            "  Back: 43\n",
            "D A Y\n",
            "13\n",
            " /   /\n",
            "The majority of men meet with failure because of their lack of persistence \n",
            "in creating new plans to take the place of those which fail.\n",
            "--------------------\n",
            "Flashcard 264:\n",
            "  Front: the question\n",
            "  Back: In each case the question you ask yourself is: “What do I really want?\n",
            "--------------------\n",
            "Flashcard 265:\n",
            "  Front: any purpose\n",
            "  Back: The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "--------------------\n",
            "Flashcard 266:\n",
            "  Front: a huge ocean\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 267:\n",
            "  Front: Stevens Avenue\n",
            "  Back: 462 Stevens Avenue, Suite 202\n",
            "Solana Beach, CA 92075\n",
            "858-436-7300 • 800-542-4252 • Fax 858-436-7301\n",
            "www.briantracy.com\n",
            "--------------------\n",
            "Flashcard 268:\n",
            "  Front: a new continent\n",
            "  Back: Your Blueprint\n",
            "to a Lifetime of \n",
            "Success, Prosperity\n",
            "and Achievement\n",
            "BRIAN \n",
            "TRACY\n",
            "GOAL\n",
            "PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "“The potential of the average\n",
            "person is like a huge ocean unsailed,\n",
            "a new continent unexplored,\n",
            "a world of possibilities waiting to be released \n",
            "and channeled toward some great good.”\n",
            "BRIAN TRACY\n",
            "By Brian Tracy\n",
            "GOAL PLANNER\n",
            "M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY IDEAS TO LIVE BY\n",
            "1.\n",
            "--------------------\n",
            "Flashcard 269:\n",
            "  Front: an ingrained habit\n",
            "  Back: All you need to do is to practice continuous goal-setting and action planning \n",
            "every day until it becomes an ingrained habit.\n",
            "--------------------\n",
            "Flashcard 270:\n",
            "  Front: the future\n",
            "  Back: 73\n",
            "The empires of the future are the empires of the mind.\n",
            "--------------------\n",
            "Flashcard 271:\n",
            "  Front: the present tense\n",
            "  Back: Write out your major deﬁ nite purpose in the present tense, as if it were already \n",
            "a reality; (#2)\n",
            "4.\n",
            "--------------------\n",
            "Flashcard 272:\n",
            "  Front: any negative thought\n",
            "  Back: You can substitute a positive goal or thought for any negative thought \n",
            "that may be holding you back.\n",
            "--------------------\n",
            "Flashcard 273:\n",
            "  Front: The rule\n",
            "  Back: The rule is: Success depends on the support of other people.\n",
            "--------------------\n",
            "Flashcard 274:\n",
            "  Front: No man\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 275:\n",
            "  Front: no man\n",
            "  Back: A whole stream of events issues from the deci-\n",
            "sion, raising in one’s favor all manner of unforeseen incidents \n",
            "and meetings and material assistance, which no man could have \n",
            "dreamed would have come his way.”\n",
            "Charles Murray\n",
            "“Are you earnest?\n",
            "--------------------\n",
            "Flashcard 276:\n",
            "  Front: the training\n",
            "  Back: M\n",
            "A\n",
            "X\n",
            "I\n",
            "M\n",
            "U\n",
            "M\n",
            " A\n",
            "C\n",
            "H\n",
            "I\n",
            "E\n",
            "V\n",
            "E\n",
            "M\n",
            "E\n",
            "N\n",
            "T\n",
            " \n",
            "G\n",
            "O\n",
            "A\n",
            "L  \n",
            "P\n",
            "L\n",
            "A\n",
            "N\n",
            "N\n",
            "E\n",
            "R\n",
            "BRIAN TRACY – Author  •  Trainer  •  Consultant\n",
            "B\n",
            "rian Tracy is Chairman and CEO of \n",
            "Brian Tracy International, a company \n",
            "specializing in the training and devel-\n",
            "opment of individuals and organizations.\n",
            "--------------------\n",
            "Flashcard 277:\n",
            "  Front: maximum success\n",
            "  Back: The person determined to achieve maximum success learns the principle that progress \n",
            "is made one step at a time.\n",
            "--------------------\n",
            "Flashcard 278:\n",
            "  Front: This goal planner\n",
            "  Back: This goal planner has been designed after more than 25 years of research and practice.\n",
            "--------------------\n",
            "Flashcard 279:\n",
            "  Front: The successful person\n",
            "  Back: 25\n",
            "The successful person always has a number of projects planned, to which he \n",
            "looks forward.\n",
            "--------------------\n",
            "Flashcard 280:\n",
            "  Front: a state\n",
            "  Back: Success is a state of mind.\n",
            "--------------------\n",
            "Displayed 280 flashcards.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff20bad2"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The original task involved fixing a \"setting an array element with a sequence\" error during TF-IDF vectorization. However, this specific error was not encountered or addressed in the provided solving steps, as the focus shifted entirely to adding flashcard functionality.\n",
        "*   Flashcard creation functionality was successfully added to the `BookQA` class, including methods for creating, extracting content, and formatting flashcards.\n",
        "*   The flashcard extraction logic uses NLTK for sentence tokenization, POS tagging, and basic noun phrase chunking, along with heuristic pattern matching for term-definition pairs and question-answer structures.\n",
        "*   Initial testing of the flashcard creation revealed issues with NLTK resource availability (`punkt_tab`, `averaged_perceptron_tagger_eng`), which were resolved by downloading the necessary resources.\n",
        "*   The heuristic-based flashcard extraction method, even after refinement with more specific patterns and key term extraction, produced flashcards of inconsistent quality. Many were not ideal Q\\&A pairs or definitions, highlighting the limitations of this approach for complex text.\n",
        "*   Testing the flashcard creation with different sections was a required step, but the specific book used in the final testing phase (\"Brian Tracy Goal Planner\") was processed into only a single section, preventing comprehensive testing across varied content.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current heuristic-based flashcard extraction is insufficient for consistently generating high-quality flashcards from arbitrary book text. More advanced NLP techniques, such as dedicated Question Generation (QG) models, Information Extraction (IE), or more sophisticated semantic analysis, would be required to significantly improve flashcard quality.\n",
        "*   To fully evaluate and refine the flashcard creation logic, it is necessary to test with books that are parsed into multiple distinct sections by the `process_book_text` method. Alternatively, the sectioning logic could be improved to create smaller, more manageable chunks of text for processing.\n"
      ]
    }
  ]
}