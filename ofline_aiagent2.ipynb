{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBdM1RFRh/aI+a2bapMcLR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57f363e20b9b4e4f9cda343a15972250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_902754345b5b4aa58594b82a423f56b4",
              "IPY_MODEL_367064c39b08435181bbf678b676abf1",
              "IPY_MODEL_1933b6fca35242229b9063192cd63fcb"
            ],
            "layout": "IPY_MODEL_f32dc1281a294609bf3878594e7b076f"
          }
        },
        "902754345b5b4aa58594b82a423f56b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d3feaa490fa4f54bd771f9f9eab6211",
            "placeholder": "​",
            "style": "IPY_MODEL_87525172f0ea479799dc8d2190efe744",
            "value": "modules.json: 100%"
          }
        },
        "367064c39b08435181bbf678b676abf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a182a9d5dc4443178f70345607f7d1e0",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81310f93c70d4946af7a53ae349fc37e",
            "value": 349
          }
        },
        "1933b6fca35242229b9063192cd63fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d937be38b2d4177a7196cb9fff04961",
            "placeholder": "​",
            "style": "IPY_MODEL_43210386bd2242cbab337bd7c4ea2cbb",
            "value": " 349/349 [00:00&lt;00:00, 4.84kB/s]"
          }
        },
        "f32dc1281a294609bf3878594e7b076f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3feaa490fa4f54bd771f9f9eab6211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87525172f0ea479799dc8d2190efe744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a182a9d5dc4443178f70345607f7d1e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81310f93c70d4946af7a53ae349fc37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d937be38b2d4177a7196cb9fff04961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43210386bd2242cbab337bd7c4ea2cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c28ea7f95f254ff9b885e7855502618e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6830c8057c74eaf8dd4da5f4e7f057f",
              "IPY_MODEL_99830715524940c6a6fb69f50394c098",
              "IPY_MODEL_e9cda53938fe4ababb27b4be9c772801"
            ],
            "layout": "IPY_MODEL_e268cff4af7b4ba0b182f754f722cc68"
          }
        },
        "a6830c8057c74eaf8dd4da5f4e7f057f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34caa10969be4254941f3a601c50625b",
            "placeholder": "​",
            "style": "IPY_MODEL_b5175011803445fbbab16fde06266b51",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "99830715524940c6a6fb69f50394c098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e3b8abfccd46e1828f8c105f97c09c",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_642e507bcb2e45849abb20d9a31d44bb",
            "value": 116
          }
        },
        "e9cda53938fe4ababb27b4be9c772801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ebb4f10ac7742449ddc590b10adf465",
            "placeholder": "​",
            "style": "IPY_MODEL_fd1aecbcda87485f9c17d3376c4c9a68",
            "value": " 116/116 [00:00&lt;00:00, 2.10kB/s]"
          }
        },
        "e268cff4af7b4ba0b182f754f722cc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34caa10969be4254941f3a601c50625b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5175011803445fbbab16fde06266b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e3b8abfccd46e1828f8c105f97c09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642e507bcb2e45849abb20d9a31d44bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ebb4f10ac7742449ddc590b10adf465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd1aecbcda87485f9c17d3376c4c9a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8de9e35cc9a4c62b50d3a45a9108762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2560832d9ee4584997d45def4a5f735",
              "IPY_MODEL_40c88f8f5d83439f817caba3c967b65f",
              "IPY_MODEL_02c03773c7b04c16a3d94d108505d715"
            ],
            "layout": "IPY_MODEL_5b24dfaae93549f89497aadc9618e204"
          }
        },
        "e2560832d9ee4584997d45def4a5f735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abe32017803248ec8a8e177630f9c522",
            "placeholder": "​",
            "style": "IPY_MODEL_2315baa66f514de9bc2f8e14e1dbb5dd",
            "value": "README.md: "
          }
        },
        "40c88f8f5d83439f817caba3c967b65f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13f5d43205a4f02ab22b3903a73dfad",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2eedbe8d66d416081804612f517b226",
            "value": 1
          }
        },
        "02c03773c7b04c16a3d94d108505d715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e086fcafba444e12a2068ad0daa397ce",
            "placeholder": "​",
            "style": "IPY_MODEL_dc81e945177147b9ab1b3fc15cc139a5",
            "value": " 10.5k/? [00:00&lt;00:00, 110kB/s]"
          }
        },
        "5b24dfaae93549f89497aadc9618e204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abe32017803248ec8a8e177630f9c522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2315baa66f514de9bc2f8e14e1dbb5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e13f5d43205a4f02ab22b3903a73dfad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e2eedbe8d66d416081804612f517b226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e086fcafba444e12a2068ad0daa397ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc81e945177147b9ab1b3fc15cc139a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6423198a9cc3439399597ab744d9204e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44fdf0a52ccf41359506a6c14a8f14d8",
              "IPY_MODEL_bc0dece8f1b34c7db3f44c66fa50f06a",
              "IPY_MODEL_be3d6a9af05e4742ab2f3424f865f3b1"
            ],
            "layout": "IPY_MODEL_e3fc20d6fb1943e88ac9f335fcc3145b"
          }
        },
        "44fdf0a52ccf41359506a6c14a8f14d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c83a26ceca984d9ea86a2d9b601ce747",
            "placeholder": "​",
            "style": "IPY_MODEL_6d842613a3964303bbd40ce892fbfada",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "bc0dece8f1b34c7db3f44c66fa50f06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91ca24ea8a7f4945a68f0e836d5a9c21",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c151a509f694c10a00b63250f0e6d33",
            "value": 53
          }
        },
        "be3d6a9af05e4742ab2f3424f865f3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8cb203201fa4649bfb4a9d744808a65",
            "placeholder": "​",
            "style": "IPY_MODEL_0ecc584ec91047c9a790e6718d48940c",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.08kB/s]"
          }
        },
        "e3fc20d6fb1943e88ac9f335fcc3145b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c83a26ceca984d9ea86a2d9b601ce747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d842613a3964303bbd40ce892fbfada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91ca24ea8a7f4945a68f0e836d5a9c21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c151a509f694c10a00b63250f0e6d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8cb203201fa4649bfb4a9d744808a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ecc584ec91047c9a790e6718d48940c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "975b3d8eb02b4c78b23179edadbaf9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8fb30335dfc48a4a96cd1474cc27c77",
              "IPY_MODEL_6d394109fb4e4057a6f00dc71cacb1e2",
              "IPY_MODEL_8aadce0a2378441982f625c879f1c819"
            ],
            "layout": "IPY_MODEL_b7275c16e30c456eaa4b44e4023f4aa6"
          }
        },
        "f8fb30335dfc48a4a96cd1474cc27c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e88ee826c504a47b9fa8ecb6ce10a5a",
            "placeholder": "​",
            "style": "IPY_MODEL_d08ab0b710274b9ebcfbe635cf7eb6a7",
            "value": "config.json: 100%"
          }
        },
        "6d394109fb4e4057a6f00dc71cacb1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f73b475c6644bdf9b9087c636b303d4",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f49049fd77b646bd8a2cf389012b65df",
            "value": 612
          }
        },
        "8aadce0a2378441982f625c879f1c819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b79e8a7a695439d897adf56f4ea97ee",
            "placeholder": "​",
            "style": "IPY_MODEL_dbc7d136a66e47daa649dc039ea9ea1c",
            "value": " 612/612 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "b7275c16e30c456eaa4b44e4023f4aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e88ee826c504a47b9fa8ecb6ce10a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d08ab0b710274b9ebcfbe635cf7eb6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f73b475c6644bdf9b9087c636b303d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49049fd77b646bd8a2cf389012b65df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b79e8a7a695439d897adf56f4ea97ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc7d136a66e47daa649dc039ea9ea1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37bad82439b24484b31d68fe44a9dfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8513a14baf6b40ad94250683681f9fa9",
              "IPY_MODEL_ebf9f90960f84b50bf7a6c005534b2de",
              "IPY_MODEL_d6e8b850e59a42bfb0dd44419b39644a"
            ],
            "layout": "IPY_MODEL_615bfec5977c41fcb8a319405b7fad40"
          }
        },
        "8513a14baf6b40ad94250683681f9fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20e0c55e71a4218bb6d144bf8ac128e",
            "placeholder": "​",
            "style": "IPY_MODEL_bee79f8202244796b2523f968721ad5f",
            "value": "model.safetensors: 100%"
          }
        },
        "ebf9f90960f84b50bf7a6c005534b2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87de8c993e554690bfba4e7fe8c6a858",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1aebf1e655954f5cb8419772ce2bf5df",
            "value": 90868376
          }
        },
        "d6e8b850e59a42bfb0dd44419b39644a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_090c2834faa84988ad0c5e370e065989",
            "placeholder": "​",
            "style": "IPY_MODEL_4f7e560839c84df9a17408aa445d27eb",
            "value": " 90.9M/90.9M [00:03&lt;00:00, 37.1MB/s]"
          }
        },
        "615bfec5977c41fcb8a319405b7fad40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20e0c55e71a4218bb6d144bf8ac128e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bee79f8202244796b2523f968721ad5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87de8c993e554690bfba4e7fe8c6a858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aebf1e655954f5cb8419772ce2bf5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "090c2834faa84988ad0c5e370e065989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7e560839c84df9a17408aa445d27eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9df24d1407f24d41ba48aa731f97cc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_995ad44805af4be39c8221d95deaf15b",
              "IPY_MODEL_d8f4b7d49a19408f98e5dfee53cd99fa",
              "IPY_MODEL_b69add0700ca42e48c3897b8c1bec08d"
            ],
            "layout": "IPY_MODEL_9a889208730641f39dcbeb485d664044"
          }
        },
        "995ad44805af4be39c8221d95deaf15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91af01a361484ed2982e63a24e6d4b1e",
            "placeholder": "​",
            "style": "IPY_MODEL_cd76f88eae8543aaa25ce817ac7b96ab",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d8f4b7d49a19408f98e5dfee53cd99fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13cf1871967b47ceb9f7cd4fc8e93875",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb618f87c31f481ab5962d591c46b585",
            "value": 350
          }
        },
        "b69add0700ca42e48c3897b8c1bec08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c56756439994412a7bbeae7d51bae86",
            "placeholder": "​",
            "style": "IPY_MODEL_d2b56234f6db4714841b821a67ee02e1",
            "value": " 350/350 [00:00&lt;00:00, 4.77kB/s]"
          }
        },
        "9a889208730641f39dcbeb485d664044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91af01a361484ed2982e63a24e6d4b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd76f88eae8543aaa25ce817ac7b96ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13cf1871967b47ceb9f7cd4fc8e93875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb618f87c31f481ab5962d591c46b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c56756439994412a7bbeae7d51bae86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b56234f6db4714841b821a67ee02e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3842c759c7934185b3289ef5487ed196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59511b35ce0647f78b309e5f58f9a5ff",
              "IPY_MODEL_58eed49664ca4b0c8a586c8f798c1f38",
              "IPY_MODEL_a0deafa352864de68deea4aa6646e7e4"
            ],
            "layout": "IPY_MODEL_6b7f17a4729747718490e4e79edae415"
          }
        },
        "59511b35ce0647f78b309e5f58f9a5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2adb888db464c6cbbce752af8669536",
            "placeholder": "​",
            "style": "IPY_MODEL_ef6582d276194f6b98f9a3602d39b754",
            "value": "vocab.txt: "
          }
        },
        "58eed49664ca4b0c8a586c8f798c1f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26f7396e6cf341f3a2e5384cee99f61c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de78887f25554895a8b6da2fe0d57854",
            "value": 1
          }
        },
        "a0deafa352864de68deea4aa6646e7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ebb35bc683e4254b153d523cdec8838",
            "placeholder": "​",
            "style": "IPY_MODEL_bec834f1923d46b39101312cd7530500",
            "value": " 232k/? [00:00&lt;00:00, 4.09MB/s]"
          }
        },
        "6b7f17a4729747718490e4e79edae415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2adb888db464c6cbbce752af8669536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef6582d276194f6b98f9a3602d39b754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26f7396e6cf341f3a2e5384cee99f61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "de78887f25554895a8b6da2fe0d57854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ebb35bc683e4254b153d523cdec8838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec834f1923d46b39101312cd7530500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e7feed5c1724d42b86a2f4905b51d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4513c74f528a4465b4793616ab5e6ee0",
              "IPY_MODEL_ae22f966715240bfa810fdf40bca654f",
              "IPY_MODEL_67eefa2a3c3a4b318d11887887f2bffc"
            ],
            "layout": "IPY_MODEL_41c3464c4b7946b7aba8baad2c4b2194"
          }
        },
        "4513c74f528a4465b4793616ab5e6ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c9d5645ba6847e8a364769ff3e8d53a",
            "placeholder": "​",
            "style": "IPY_MODEL_1bb602b169fe47ccb2baca2fa2e284eb",
            "value": "tokenizer.json: "
          }
        },
        "ae22f966715240bfa810fdf40bca654f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3943955c20c4622adb33855a6b2b2e5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fa196780c1f478bb752cfec1c865427",
            "value": 1
          }
        },
        "67eefa2a3c3a4b318d11887887f2bffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_428467850e9d4e7fa8142c4689e4f370",
            "placeholder": "​",
            "style": "IPY_MODEL_fc00590c52dd488b8f667d51e3039891",
            "value": " 466k/? [00:00&lt;00:00, 6.86MB/s]"
          }
        },
        "41c3464c4b7946b7aba8baad2c4b2194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9d5645ba6847e8a364769ff3e8d53a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb602b169fe47ccb2baca2fa2e284eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3943955c20c4622adb33855a6b2b2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4fa196780c1f478bb752cfec1c865427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "428467850e9d4e7fa8142c4689e4f370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc00590c52dd488b8f667d51e3039891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "122e4d4c64914457a8ada87c234fe40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_448429f569af404bbf162ae3ccec32d4",
              "IPY_MODEL_5770e86c094d4d4f8e3473241495ad3f",
              "IPY_MODEL_7aaba2873c6140b4abefe864c34f0120"
            ],
            "layout": "IPY_MODEL_324dd3386d7d43e9bb63afcc048d42b0"
          }
        },
        "448429f569af404bbf162ae3ccec32d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919e56bd82874eb0963285dd7d520a1d",
            "placeholder": "​",
            "style": "IPY_MODEL_bc2e184e5cc943a6aa173c9579acfc4b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5770e86c094d4d4f8e3473241495ad3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3488471a0ae548d394dc40c93cf51a3a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6626a52314c8439a8a82c5994a4f4eac",
            "value": 112
          }
        },
        "7aaba2873c6140b4abefe864c34f0120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11565bb74a4d4902965b2cb386157f78",
            "placeholder": "​",
            "style": "IPY_MODEL_2e8df7f17f87442e90066644dc855a6d",
            "value": " 112/112 [00:00&lt;00:00, 4.23kB/s]"
          }
        },
        "324dd3386d7d43e9bb63afcc048d42b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "919e56bd82874eb0963285dd7d520a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc2e184e5cc943a6aa173c9579acfc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3488471a0ae548d394dc40c93cf51a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6626a52314c8439a8a82c5994a4f4eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11565bb74a4d4902965b2cb386157f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e8df7f17f87442e90066644dc855a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1757ed981e834159bde05a810c8b1d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51d487adffa142e5b4b412c13216c4e3",
              "IPY_MODEL_cc13e815e637486d986f92dbf00ec74b",
              "IPY_MODEL_961cba277876429ca6392916a98a0c6e"
            ],
            "layout": "IPY_MODEL_195ad42c0e1941ccb35a2baf7ac6697e"
          }
        },
        "51d487adffa142e5b4b412c13216c4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25685bc5a39d40bfaccd38243c539841",
            "placeholder": "​",
            "style": "IPY_MODEL_e76ae1d6fcff4ea5a0ddfbc8af4b5a42",
            "value": "config.json: 100%"
          }
        },
        "cc13e815e637486d986f92dbf00ec74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9945d3f1be5a4ba78867888b5d8f5957",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b395229599354ce6bdc8eef3bd70f80d",
            "value": 190
          }
        },
        "961cba277876429ca6392916a98a0c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f30518c50454c9385dfa9867905cc61",
            "placeholder": "​",
            "style": "IPY_MODEL_f0345518a8c84c11993f9adc93a73c67",
            "value": " 190/190 [00:00&lt;00:00, 6.35kB/s]"
          }
        },
        "195ad42c0e1941ccb35a2baf7ac6697e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25685bc5a39d40bfaccd38243c539841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76ae1d6fcff4ea5a0ddfbc8af4b5a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9945d3f1be5a4ba78867888b5d8f5957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b395229599354ce6bdc8eef3bd70f80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f30518c50454c9385dfa9867905cc61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0345518a8c84c11993f9adc93a73c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekerintaiwoa/MediaApp/blob/master/ofline_aiagent2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A9L75fjXXEs"
      },
      "outputs": [],
      "source": [
        "# prompt: create an ai agents that allows users to upload a book, ask question about the book,Summarize Chapters or Sections,Study and Review\n",
        "\n",
        "# This code requires several libraries that might not be installed by default\n",
        "# on a standard Colab instance. We'll install them first.\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install PyMuPDF  # For handling PDF files\n",
        "!pip install nltk  # For natural language processing tasks like tokenization\n",
        "!pip install scikit-learn  # For text vectorization (TF-IDF)\n",
        "!pip install faiss-cpu  # For efficient similarity search (vector database)\n",
        "!pip install transformers  # For using powerful language models\n",
        "!pip install torch  # PyTorch is a dependency for transformers\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import nltk\n",
        "import re\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Download necessary NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None\n",
        "        self.tfidf_matrix = None\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            return\n",
        "\n",
        "        section_texts = list(self.chapter_sections.values())\n",
        "        print(f\"Vectorizing {len(section_texts)} sections...\")\n",
        "\n",
        "        # Using TF-IDF for simplicity; consider Sentence Transformers for better semantic search\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(section_texts)\n",
        "\n",
        "        # Create FAISS index\n",
        "        dimension = self.tfidf_matrix.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "        self.index.add(self.tfidf_matrix.astype('float32')) # FAISS requires float32\n",
        "        print(\"FAISS index created.\")\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        question_vec = self.vectorizer.transform([question]).toarray().astype('float32')\n",
        "        D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        relevant_section_title = section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title]\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context)\n",
        "            return f\"Answer: {answer['answer']} (Source: {relevant_section_title}, Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section:\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for study/review.\"\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# --- How to use the agent in Colab ---\n",
        "\n",
        "# 1. Mount Google Drive to access your files (optional, but common)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Create an instance of the BookQA agent\n",
        "agent = BookQA()\n",
        "\n",
        "# 3. Upload a book (replace '/content/drive/My Drive/your_book.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/My Drive/your_book.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)\n",
        "\n",
        "# --- Now you can interact with the agent ---\n",
        "\n",
        "# Example 1: Ask a question\n",
        "if agent.book_text:\n",
        "    question1 = \"What is the main topic of the introduction?\"\n",
        "    answer1 = agent.ask_question(question1)\n",
        "    print(f\"\\nQuestion: {question1}\")\n",
        "    print(answer1)\n",
        "\n",
        "    question2 = \"What is the author's perspective on [some topic mentioned in your book]?\"\n",
        "    answer2 = agent.ask_question(question2)\n",
        "    print(f\"\\nQuestion: {question2}\")\n",
        "    print(answer2)\n",
        "\n",
        "    # Example 2: List sections\n",
        "    print(\"\\nListing sections:\")\n",
        "    agent.list_sections()\n",
        "\n",
        "    # Example 3: Summarize a section (replace '1' with the actual section number or part of the title)\n",
        "    section_to_summarize = \"1\" # <--- **CHANGE THIS TO A SECTION NUMBER OR TITLE FROM `list_sections()`**\n",
        "    print(f\"\\nAttempting to summarize section: {section_to_summarize}\")\n",
        "    summary = agent.summarize_section(section_to_summarize)\n",
        "    print(summary)\n",
        "\n",
        "    # Example 4: Enter Study/Review mode\n",
        "    print(\"\\nEntering Study/Review mode:\")\n",
        "    # agent.study_review() # Uncomment this line to start the interactive study mode\n",
        "\n",
        "else:\n",
        "    print(\"\\nBook was not loaded successfully. Please check the file path and format.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install necessary libraries\n",
        "!pip install PyMuPDF  # For handling PDF files\n",
        "!pip install nltk  # For natural language processing tasks like tokenization\n",
        "!pip install scikit-learn  # For text vectorization (TF-IDF)\n",
        "!pip install faiss-cpu  # For efficient similarity search (vector database)\n",
        "!pip install transformers  # For using powerful language models\n",
        "!pip install torch  # PyTorch is a dependency for transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkxes4xOZFDi",
        "outputId": "9462bf35-8230-495d-d8d6-6acac34606eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.3\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xv2VTA73ZpZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import nltk\n",
        "import re\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "gFBM6QUBZsOv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import nltk\n",
        "import re\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None\n",
        "        self.tfidf_matrix = None\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Basic text cleaning.\"\"\"\n",
        "        text = text.lower() # Convert to lowercase\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove non-alphanumeric characters except spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        self.chapter_sections = {} # Clear existing sections\n",
        "\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            self.vectorizer = None\n",
        "            self.tfidf_matrix = None\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "        # Ensure all values in chapter_sections are strings, clean them, and filter empty ones\n",
        "        valid_section_texts = []\n",
        "        valid_section_titles = []\n",
        "        print(\"Cleaning and filtering sections for vectorization:\")\n",
        "        for title, text in self.chapter_sections.items():\n",
        "            if isinstance(text, str) and text.strip():\n",
        "                cleaned_text = self.clean_text(text) # Clean the text\n",
        "                if cleaned_text: # Only add if cleaned text is not empty\n",
        "                    valid_section_texts.append(cleaned_text)\n",
        "                    valid_section_titles.append(title) # Keep track of titles for valid sections\n",
        "                else:\n",
        "                    print(f\"Warning: Section '{title}' became empty after cleaning. Skipping for vectorization.\")\n",
        "            else:\n",
        "                print(f\"Warning: Section '{title}' is not a valid string or is empty. Skipping for vectorization.\")\n",
        "\n",
        "        print(f\"Found {len(valid_section_texts)} valid sections after cleaning and filtering.\")\n",
        "\n",
        "        if not valid_section_texts:\n",
        "            print(\"No valid sections to vectorize after filtering.\")\n",
        "            self.vectorizer = None\n",
        "            self.tfidf_matrix = None\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "        print(f\"Vectorizing {len(valid_section_texts)} valid sections...\")\n",
        "\n",
        "        # Using TF-IDF for simplicity; consider Sentence Transformers for better semantic search\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "        try:\n",
        "            self.tfidf_matrix = self.vectorizer.fit_transform(valid_section_texts)\n",
        "\n",
        "            # Create FAISS index\n",
        "            dimension = self.tfidf_matrix.shape[1]\n",
        "            if dimension > 0:\n",
        "                self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "                self.index.add(self.tfidf_matrix.astype('float32')) # FAISS requires float32\n",
        "                print(\"FAISS index created.\")\n",
        "                # Store the titles corresponding to the vectorized texts for later lookup\n",
        "                self._vectorized_section_titles = valid_section_titles\n",
        "            else:\n",
        "                print(\"TF-IDF matrix has no features after vectorization. Cannot create FAISS index.\")\n",
        "                self.index = None\n",
        "                self._vectorized_section_titles = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during TF-IDF vectorization: {e}\")\n",
        "            self.vectorizer = None\n",
        "            self.tfidf_matrix = None\n",
        "            self.index = None\n",
        "            self._vectorized_section_titles = []\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "        if not self.vectorizer or not self.index or not hasattr(self, '_vectorized_section_titles') or not self._vectorized_section_titles:\n",
        "             return \"Book content not vectorized or index not created. Cannot answer questions.\"\n",
        "\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        try:\n",
        "            # Clean the question before vectorizing for search\n",
        "            cleaned_question = self.clean_text(question)\n",
        "            if not cleaned_question:\n",
        "                 return \"Please provide a valid question after cleaning.\"\n",
        "\n",
        "            question_vec = self.vectorizer.transform([cleaned_question]).toarray().astype('float32')\n",
        "            D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "        except Exception as e:\n",
        "            print(f\"Error transforming question for search: {e}\")\n",
        "            return \"Could not process the question for searching.\"\n",
        "\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        # Use the stored vectorized section titles to get the correct title\n",
        "        relevant_section_title = self._vectorized_section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title] # Use original text for QA\n",
        "\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context) # Use original question for QA pipeline\n",
        "            return f\"Answer: {answer['answer']} (Source: '{relevant_section_title}', Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section from '{relevant_section_title}':\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for study/review.\"\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")"
      ],
      "metadata": {
        "id": "j6P1UkopZsX3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- How to use the agent in Colab ---\n",
        "\n",
        "# 1. Mount Google Drive to access your files (optional, but common)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4Vvz_0LZsfj",
        "outputId": "83e81f5a-192a-4561-eab4-c74564e6bdef"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VR7Q_usbZskc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create an instance of the BookQA agent\n",
        "agent = BookQA()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJSYhoGzZspi",
        "outputId": "028aeeca-d243-4ab4-beae-2d790ba9ef18"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization model loaded.\n",
            "Models initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXLRUpBGZsuj",
        "outputId": "9b68421f-4b1e-42f1-bcc4-9aaeee424d5d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Vectorizing 1 valid sections...\n",
            "Error during TF-IDF vectorization: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Now you can interact with the agent ---\n",
        "\n",
        "# Example 1: Ask a question\n",
        "if agent.book_text:\n",
        "    question1 = \"BRIAN TRACY IDEAS TO LIVE BY\"\n",
        "    answer1 = agent.ask_question(question1)\n",
        "    print(f\"\\nQuestion: {question1}\")\n",
        "    print(answer1)\n"
      ],
      "metadata": {
        "id": "R3S1fjB9ZtIh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c92528f",
        "outputId": "e9e12ba8-b085-4ae6-996c-2069364a63d8"
      },
      "source": [
        "# 2. Create an instance of the BookQA agent\n",
        "agent = BookQA()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization model loaded.\n",
            "Models initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ff7bf5",
        "outputId": "cadf6e6e-2c84-4566-ff4f-50e176232247"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Vectorizing 1 sections...\n",
            "Error reading file: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6825f1ca",
        "outputId": "7f693522-3d92-4ed9-f108-a0b3c67e4ca6"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/627260606-chatbotdoc (1).pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/627260606-chatbotdoc (1).pdf\n",
            "Reading 97 pages from /content/drive/MyDrive/627260606-chatbotdoc (1).pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 2 chapters/sections or chunks.\n",
            "Vectorizing 2 sections...\n",
            "Error reading file: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f0655f4",
        "outputId": "a933dda3-7b14-40d4-d85e-18604573785b"
      },
      "source": [
        "# --- Now you can interact with the agent ---\n",
        "\n",
        "# Example 1: Ask a question\n",
        "if agent.book_text:\n",
        "    question1 = \"What is the main topic of the introduction?\"\n",
        "    answer1 = agent.ask_question(question1)\n",
        "    print(f\"\\nQuestion: {question1}\")\n",
        "    print(answer1)\n",
        "\n",
        "    question2 = \"What are the key steps for setting goals?\" # Example question related to the book title\n",
        "    answer2 = agent.ask_question(question2)\n",
        "    print(f\"\\nQuestion: {question2}\")\n",
        "    print(answer2)\n",
        "\n",
        "    # Example 2: List sections\n",
        "    print(\"\\nListing sections:\")\n",
        "    agent.list_sections()\n",
        "\n",
        "    # Example 3: Summarize a section (replace '1' with the actual section number or part of the title)\n",
        "    # Check the output of list_sections() to find a section to summarize.\n",
        "    # For now, let's try summarizing the first identified section (assuming there's at least one)\n",
        "    if agent.chapter_sections:\n",
        "        first_section_key = list(agent.chapter_sections.keys())[0]\n",
        "        print(f\"\\nAttempting to summarize section: {first_section_key}\")\n",
        "        summary = agent.summarize_section(first_section_key)\n",
        "        print(summary)\n",
        "    else:\n",
        "        print(\"\\nNo sections available to summarize.\")\n",
        "\n",
        "\n",
        "    # Example 4: Enter Study/Review mode\n",
        "    print(\"\\nEntering Study/Review mode:\")\n",
        "    # agent.study_review() # Uncomment this line to start the interactive study mode\n",
        "\n",
        "else:\n",
        "    print(\"\\nBook was not loaded successfully. Please check the file path and format.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Book was not loaded successfully. Please check the file path and format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89c63f5c",
        "outputId": "a5c67147-23ee-4d6c-bbd9-dcc6dafc1236"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/627260606-chatbotdoc (1).pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/627260606-chatbotdoc (1).pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/627260606-chatbotdoc (1).pdf\n",
            "Reading 97 pages from /content/drive/MyDrive/627260606-chatbotdoc (1).pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 2 chapters/sections or chunks.\n",
            "Vectorizing 2 sections...\n",
            "Error reading file: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3710e6",
        "outputId": "d9b0ace2-6ac7-4655-a480-d2f34cbcce9c"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Vectorizing 1 valid sections...\n",
            "Error during TF-IDF vectorization: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09398f4e",
        "outputId": "54c09539-1ea6-48b9-9407-51843c5c9930"
      },
      "source": [
        "# 3. Upload a book (replace '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' with your file path)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # <--- **CHANGE THIS TO YOUR BOOK PATH**\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Vectorizing 1 valid sections...\n",
            "Error during TF-IDF vectorization: setting an array element with a sequence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fd2f2e0"
      },
      "source": [
        "# Task\n",
        "Explain the error \"setting an array element with a sequence\" encountered during TF-IDF vectorization when processing PDF files \"/content/drive/MyDrive/627260606-chatbotdoc (1).pdf\" and \"/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\". If possible, fix the error in the provided code and incorporate the changes. Otherwise, diagnose the error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b59d8c9"
      },
      "source": [
        "## Install sentence transformers\n",
        "\n",
        "### Subtask:\n",
        "Add the necessary library for Sentence Transformers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeb69d2a"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to add the necessary library for Sentence Transformers. This requires installing the `sentence-transformers` package using pip. This needs to be in a separate code cell as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e96c3a96",
        "outputId": "cc5d35a4-7342-42c9-f527-517fa2bd725a"
      },
      "source": [
        "!pip install sentence-transformers"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae6cfad4"
      },
      "source": [
        "## Update `initialize models`\n",
        "\n",
        "### Subtask:\n",
        "Load a Sentence Transformer model instead of relying solely on TF-IDF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfd16b2"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary class for Sentence Transformers and initialize the Sentence Transformer model in the `initialize_models` method, replacing the TF-IDF vectorizer initialization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b28a24c"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class BookQA:\n",
        "    def __init__(self):\n",
        "        self.book_text = \"\"\n",
        "        self.chapter_sections = {} # To store chapter/section titles and their text\n",
        "        self.vectorizer = None # This will be replaced by the embedding model\n",
        "        self.tfidf_matrix = None # This will be replaced by the embeddings\n",
        "        self.index = None # FAISS index for vector search\n",
        "        self.qa_pipeline = None\n",
        "        self.summarizer_pipeline = None\n",
        "        self.tokenizer = None\n",
        "        self.summarizer_model = None\n",
        "        self.embedding_model = None # New attribute for Sentence Transformer model\n",
        "\n",
        "\n",
        "        # Initialize NLP pipelines and models\n",
        "        print(\"Initializing NLP models...\")\n",
        "        self.initialize_models()\n",
        "        print(\"Models initialized.\")\n",
        "\n",
        "    def initialize_models(self):\n",
        "        # Initialize Question Answering pipeline\n",
        "        # Using a smaller model for demonstration; consider a larger one for better results\n",
        "        try:\n",
        "            self.qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "            print(\"Question Answering model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading QA model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.qa_pipeline = None\n",
        "\n",
        "        # Initialize Summarization model and tokenizer\n",
        "        # Using a smaller T5 model; consider t5-large or bart-large-cnn for better summaries\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "            self.summarizer_pipeline = pipeline(\"summarization\", model=self.summarizer_model, tokenizer=self.tokenizer)\n",
        "            print(\"Summarization model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Summarization model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.tokenizer = None\n",
        "            self.summarizer_model = None\n",
        "            self.summarizer_pipeline = None\n",
        "\n",
        "        # Initialize Sentence Transformer model for embeddings\n",
        "        try:\n",
        "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            print(\"Sentence Transformer model loaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Sentence Transformer model: {e}\")\n",
        "            print(\"Please ensure you have sufficient resources and internet connection.\")\n",
        "            self.embedding_model = None\n",
        "\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Basic text cleaning.\"\"\"\n",
        "        text = text.lower() # Convert to lowercase\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove non-alphanumeric characters except spaces\n",
        "        text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def upload_book(self, file_path):\n",
        "        \"\"\"Reads content from a PDF file.\"\"\"\n",
        "        try:\n",
        "            doc = fitz.open(file_path)\n",
        "            self.book_text = \"\"\n",
        "            print(f\"Reading {doc.page_count} pages from {file_path}...\")\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc.load_page(page_num)\n",
        "                self.book_text += page.get_text()\n",
        "            print(\"Finished reading book.\")\n",
        "            self.process_book_text()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            self.book_text = \"\"\n",
        "            self.chapter_sections = {}\n",
        "\n",
        "    def process_book_text(self):\n",
        "        \"\"\"Splits book text into chapters/sections and prepares for search.\"\"\"\n",
        "        if not self.book_text:\n",
        "            print(\"No book text loaded to process.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing book text...\")\n",
        "        # Simple approach to split into sections based on common patterns (e.g., \"Chapter X\", \"Section Y\")\n",
        "        # This is a basic implementation; a more robust parser might be needed for complex books.\n",
        "        sections = re.split(r'(Chapter \\d+|Section \\d+)', self.book_text, flags=re.IGNORECASE)\n",
        "\n",
        "        current_title = \"Introduction/Beginning\"\n",
        "        current_text = \"\"\n",
        "        self.chapter_sections = {} # Clear existing sections\n",
        "\n",
        "        for i, part in enumerate(sections):\n",
        "            if i % 2 == 1: # This part is likely a title\n",
        "                if current_text.strip():\n",
        "                    self.chapter_sections[current_title] = current_text.strip()\n",
        "                current_title = part.strip()\n",
        "                current_text = \"\"\n",
        "            else: # This part is the content\n",
        "                current_text += part\n",
        "\n",
        "        if current_text.strip(): # Add the last section\n",
        "             self.chapter_sections[current_title] = current_text.strip()\n",
        "\n",
        "        # Handle cases where no clear chapters/sections are found (e.g., a simple document)\n",
        "        if not self.chapter_sections and self.book_text:\n",
        "             # Split into chunks for search\n",
        "             chunk_size = 2000 # characters\n",
        "             chunks = [self.book_text[i:i + chunk_size] for i in range(0, len(self.book_text), chunk_size)]\n",
        "             self.chapter_sections = {f\"Chunk {i+1}\": chunk for i, chunk in enumerate(chunks)}\n",
        "             print(f\"Book text split into {len(chunks)} chunks.\")\n",
        "\n",
        "        print(f\"Identified {len(self.chapter_sections)} chapters/sections or chunks.\")\n",
        "\n",
        "        # Prepare for vector search\n",
        "        self.prepare_for_search()\n",
        "\n",
        "    def prepare_for_search(self):\n",
        "        \"\"\"Vectorizes the text and creates a FAISS index using Sentence Transformers.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            print(\"No sections to vectorize.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "        if not self.embedding_model:\n",
        "            print(\"Sentence Transformer model not loaded. Cannot vectorize sections.\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            return\n",
        "\n",
        "\n",
        "        section_texts = list(self.chapter_sections.values())\n",
        "        print(f\"Creating embeddings for {len(section_texts)} sections...\")\n",
        "\n",
        "        try:\n",
        "            # Create embeddings using the Sentence Transformer model\n",
        "            embeddings = self.embedding_model.encode(section_texts, convert_to_numpy=True)\n",
        "            self.tfidf_matrix = embeddings # Store embeddings (renamed from tfidf_matrix)\n",
        "\n",
        "            # Create FAISS index\n",
        "            dimension = embeddings.shape[1]\n",
        "            if dimension > 0:\n",
        "                self.index = faiss.IndexFlatL2(dimension) # Using L2 distance (Euclidean)\n",
        "                self.index.add(embeddings.astype('float32')) # FAISS requires float32\n",
        "                print(\"FAISS index created.\")\n",
        "                # Store the titles corresponding to the vectorized texts for later lookup\n",
        "                self._vectorized_section_titles = list(self.chapter_sections.keys()) # Store original titles\n",
        "            else:\n",
        "                print(\"Embeddings have no dimensions after vectorization. Cannot create FAISS index.\")\n",
        "                self.index = None\n",
        "                self._vectorized_section_titles = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during embedding creation or FAISS index creation: {e}\")\n",
        "            self.tfidf_matrix = None # Renamed to embeddings\n",
        "            self.index = None\n",
        "            self._vectorized_section_titles = []\n",
        "\n",
        "\n",
        "    def ask_question(self, question):\n",
        "        \"\"\"Answers a question based on the book content.\"\"\"\n",
        "        if not self.book_text:\n",
        "            return \"Please upload a book first.\"\n",
        "        if not self.qa_pipeline:\n",
        "             return \"Question Answering model is not loaded. Please check initialization.\"\n",
        "        if not self.embedding_model or not self.index or not hasattr(self, '_vectorized_section_titles') or not self._vectorized_section_titles:\n",
        "             return \"Book content not vectorized or index not created. Cannot answer questions.\"\n",
        "\n",
        "\n",
        "        print(f\"Searching for answer to: '{question}'\")\n",
        "\n",
        "        # Find the most relevant section using the FAISS index\n",
        "        try:\n",
        "            # Create embedding for the question\n",
        "            question_vec = self.embedding_model.encode([question], convert_to_numpy=True).astype('float32')\n",
        "            D, I = self.index.search(question_vec, 1) # Search for the top 1 most similar section\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating question embedding or searching index: {e}\")\n",
        "            return \"Could not process the question for searching.\"\n",
        "\n",
        "\n",
        "        if I.size == 0 or I[0][0] == -1:\n",
        "            return \"Could not find a relevant section in the book.\"\n",
        "\n",
        "        relevant_section_index = I[0][0]\n",
        "        # Use the stored vectorized section titles to get the correct title\n",
        "        relevant_section_title = self._vectorized_section_titles[relevant_section_index]\n",
        "        relevant_section_text = self.chapter_sections[relevant_section_title] # Use original text for QA\n",
        "\n",
        "\n",
        "        print(f\"Most relevant section: '{relevant_section_title}'\")\n",
        "\n",
        "        # Use the QA pipeline on the relevant section\n",
        "        try:\n",
        "            # The QA pipeline has context length limitations. We might need to\n",
        "            # further refine the relevant text chunk for the QA model.\n",
        "            # For simplicity, using the whole section here, which might fail for very long sections.\n",
        "            # A better approach would be to split the section into smaller paragraphs.\n",
        "            # For this example, let's limit the context length for the pipeline\n",
        "            max_context_length = self.qa_pipeline.model.config.max_position_embeddings if hasattr(self.qa_pipeline.model.config, 'max_position_embeddings') else 512\n",
        "            # Let's roughly estimate tokens by characters for now (approx 4 chars per token)\n",
        "            max_chars = max_context_length * 4\n",
        "            context = relevant_section_text[:max_chars]\n",
        "\n",
        "\n",
        "            answer = self.qa_pipeline(question=question, context=context) # Use original question for QA pipeline\n",
        "            return f\"Answer: {answer['answer']} (Source: '{relevant_section_title}', Score: {answer['score']:.2f})\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during QA pipeline: {e}\")\n",
        "            # Fallback: Return the relevant section\n",
        "            return f\"Could not generate a specific answer. Relevant section from '{relevant_section_title}':\\n{relevant_section_text[:500]}...\" # Show beginning of section\n",
        "\n",
        "\n",
        "    def list_sections(self):\n",
        "        \"\"\"Lists the identified chapters/sections.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections identified yet. Please upload a book.\"\n",
        "        print(\"Chapters/Sections:\")\n",
        "        for i, title in enumerate(self.chapter_sections.keys()):\n",
        "            print(f\"{i+1}. {title}\")\n",
        "\n",
        "    def summarize_section(self, section_identifier):\n",
        "        \"\"\"Summarizes a specified chapter or section.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No chapters or sections available to summarize. Please upload a book.\"\n",
        "        if not self.summarizer_pipeline:\n",
        "            return \"Summarization model is not loaded. Please check initialization.\"\n",
        "\n",
        "        section_titles = list(self.chapter_sections.keys())\n",
        "        section_text = None\n",
        "        section_title = None\n",
        "\n",
        "        try:\n",
        "            # Try to find by number (1-based index)\n",
        "            section_index = int(section_identifier) - 1\n",
        "            if 0 <= section_index < len(section_titles):\n",
        "                section_title = section_titles[section_index]\n",
        "                section_text = self.chapter_sections[section_title]\n",
        "        except ValueError:\n",
        "            # If not a number, try to find by partial title match\n",
        "            for title in section_titles:\n",
        "                if section_identifier.lower() in title.lower():\n",
        "                    section_title = title\n",
        "                    section_text = self.chapter_sections[title]\n",
        "                    break\n",
        "\n",
        "        if section_text is None:\n",
        "            return f\"Could not find a section matching '{section_identifier}'. Use `list_sections()` to see available sections.\"\n",
        "\n",
        "        print(f\"Summarizing section: '{section_title}'\")\n",
        "\n",
        "        # Summarization models have input length limits. We need to handle long sections.\n",
        "        # A common approach is to split the text into smaller chunks, summarize each chunk,\n",
        "        # and then optionally summarize the summaries.\n",
        "        # For simplicity here, we'll just truncate or split the text for the summarizer input.\n",
        "\n",
        "        # Let's split the text into smaller chunks and summarize each chunk\n",
        "        chunk_size = 1000 # characters per chunk for summarization input\n",
        "        chunks = [section_text[i:i + chunk_size] for i in range(0, len(section_text), chunk_size)]\n",
        "\n",
        "        all_summaries = []\n",
        "        print(f\"Splitting section into {len(chunks)} chunks for summarization...\")\n",
        "        for i, chunk in enumerate(chunks):\n",
        "             # Need to handle potential tokenizer limits more robustly\n",
        "             # A simple approach: if a chunk is too long after tokenization, summarize a smaller part\n",
        "             input_tokens = self.tokenizer(chunk, return_tensors=\"pt\", max_length=self.tokenizer.model_max_length, truncation=True).input_ids\n",
        "             if input_tokens.shape[1] > self.tokenizer.model_max_length:\n",
        "                 print(f\"Warning: Chunk {i+1} is too long, truncating for summarization.\")\n",
        "                 # Further split or refine truncation if necessary\n",
        "                 # For this example, just use the truncated version by the tokenizer\n",
        "\n",
        "             try:\n",
        "                summary = self.summarizer_pipeline(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "                all_summaries.append(summary[0]['summary_text'])\n",
        "                print(f\"Summarized chunk {i+1}/{len(chunks)}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "                 all_summaries.append(f\"[Error summarizing this part: {str(e)[:100]}...]\") # Add error indicator\n",
        "\n",
        "        # Combine the summaries\n",
        "        if all_summaries:\n",
        "            combined_summary = \"\\n\".join(all_summaries)\n",
        "            return f\"Summary of '{section_title}':\\n{combined_summary}\"\n",
        "        else:\n",
        "            return f\"Could not generate a summary for '{section_title}'. No valid chunks were processed.\"\n",
        "\n",
        "\n",
        "    def study_review(self):\n",
        "        \"\"\"Provides options for studying and reviewing.\"\"\"\n",
        "        if not self.chapter_sections:\n",
        "            return \"No book loaded for study/review.\"\n",
        "\n",
        "        print(\"\\n--- Study & Review Options ---\")\n",
        "        print(\"1. List Chapters/Sections\")\n",
        "        print(\"2. Summarize a specific Chapter/Section\")\n",
        "        print(\"3. Ask a question about the book\")\n",
        "        print(\"4. Exit Study/Review\")\n",
        "\n",
        "        while True:\n",
        "            choice = input(\"Enter your choice: \")\n",
        "            if choice == '1':\n",
        "                self.list_sections()\n",
        "            elif choice == '2':\n",
        "                section_input = input(\"Enter the chapter/section number or name to summarize: \")\n",
        "                summary = self.summarize_section(section_input)\n",
        "                print(summary)\n",
        "            elif choice == '3':\n",
        "                question = input(\"What is your question about the book? \")\n",
        "                answer = self.ask_question(question)\n",
        "                print(answer)\n",
        "            elif choice == '4':\n",
        "                print(\"Exiting Study/Review.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57d9c5f1"
      },
      "source": [
        "## Review and refine\n",
        "\n",
        "### Subtask:\n",
        "Test the updated agent with the problematic PDF and potentially other documents. Adjust text splitting, model choice, or search parameters as needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86b2ecc"
      },
      "source": [
        "**Reasoning**:\n",
        "Re-instantiate the BookQA agent to load the updated code and then attempt to upload one of the problematic PDF files to test if the error is resolved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720,
          "referenced_widgets": [
            "57f363e20b9b4e4f9cda343a15972250",
            "902754345b5b4aa58594b82a423f56b4",
            "367064c39b08435181bbf678b676abf1",
            "1933b6fca35242229b9063192cd63fcb",
            "f32dc1281a294609bf3878594e7b076f",
            "2d3feaa490fa4f54bd771f9f9eab6211",
            "87525172f0ea479799dc8d2190efe744",
            "a182a9d5dc4443178f70345607f7d1e0",
            "81310f93c70d4946af7a53ae349fc37e",
            "1d937be38b2d4177a7196cb9fff04961",
            "43210386bd2242cbab337bd7c4ea2cbb",
            "c28ea7f95f254ff9b885e7855502618e",
            "a6830c8057c74eaf8dd4da5f4e7f057f",
            "99830715524940c6a6fb69f50394c098",
            "e9cda53938fe4ababb27b4be9c772801",
            "e268cff4af7b4ba0b182f754f722cc68",
            "34caa10969be4254941f3a601c50625b",
            "b5175011803445fbbab16fde06266b51",
            "18e3b8abfccd46e1828f8c105f97c09c",
            "642e507bcb2e45849abb20d9a31d44bb",
            "7ebb4f10ac7742449ddc590b10adf465",
            "fd1aecbcda87485f9c17d3376c4c9a68",
            "c8de9e35cc9a4c62b50d3a45a9108762",
            "e2560832d9ee4584997d45def4a5f735",
            "40c88f8f5d83439f817caba3c967b65f",
            "02c03773c7b04c16a3d94d108505d715",
            "5b24dfaae93549f89497aadc9618e204",
            "abe32017803248ec8a8e177630f9c522",
            "2315baa66f514de9bc2f8e14e1dbb5dd",
            "e13f5d43205a4f02ab22b3903a73dfad",
            "e2eedbe8d66d416081804612f517b226",
            "e086fcafba444e12a2068ad0daa397ce",
            "dc81e945177147b9ab1b3fc15cc139a5",
            "6423198a9cc3439399597ab744d9204e",
            "44fdf0a52ccf41359506a6c14a8f14d8",
            "bc0dece8f1b34c7db3f44c66fa50f06a",
            "be3d6a9af05e4742ab2f3424f865f3b1",
            "e3fc20d6fb1943e88ac9f335fcc3145b",
            "c83a26ceca984d9ea86a2d9b601ce747",
            "6d842613a3964303bbd40ce892fbfada",
            "91ca24ea8a7f4945a68f0e836d5a9c21",
            "4c151a509f694c10a00b63250f0e6d33",
            "e8cb203201fa4649bfb4a9d744808a65",
            "0ecc584ec91047c9a790e6718d48940c",
            "975b3d8eb02b4c78b23179edadbaf9c7",
            "f8fb30335dfc48a4a96cd1474cc27c77",
            "6d394109fb4e4057a6f00dc71cacb1e2",
            "8aadce0a2378441982f625c879f1c819",
            "b7275c16e30c456eaa4b44e4023f4aa6",
            "6e88ee826c504a47b9fa8ecb6ce10a5a",
            "d08ab0b710274b9ebcfbe635cf7eb6a7",
            "6f73b475c6644bdf9b9087c636b303d4",
            "f49049fd77b646bd8a2cf389012b65df",
            "5b79e8a7a695439d897adf56f4ea97ee",
            "dbc7d136a66e47daa649dc039ea9ea1c",
            "37bad82439b24484b31d68fe44a9dfff",
            "8513a14baf6b40ad94250683681f9fa9",
            "ebf9f90960f84b50bf7a6c005534b2de",
            "d6e8b850e59a42bfb0dd44419b39644a",
            "615bfec5977c41fcb8a319405b7fad40",
            "d20e0c55e71a4218bb6d144bf8ac128e",
            "bee79f8202244796b2523f968721ad5f",
            "87de8c993e554690bfba4e7fe8c6a858",
            "1aebf1e655954f5cb8419772ce2bf5df",
            "090c2834faa84988ad0c5e370e065989",
            "4f7e560839c84df9a17408aa445d27eb",
            "9df24d1407f24d41ba48aa731f97cc03",
            "995ad44805af4be39c8221d95deaf15b",
            "d8f4b7d49a19408f98e5dfee53cd99fa",
            "b69add0700ca42e48c3897b8c1bec08d",
            "9a889208730641f39dcbeb485d664044",
            "91af01a361484ed2982e63a24e6d4b1e",
            "cd76f88eae8543aaa25ce817ac7b96ab",
            "13cf1871967b47ceb9f7cd4fc8e93875",
            "fb618f87c31f481ab5962d591c46b585",
            "0c56756439994412a7bbeae7d51bae86",
            "d2b56234f6db4714841b821a67ee02e1",
            "3842c759c7934185b3289ef5487ed196",
            "59511b35ce0647f78b309e5f58f9a5ff",
            "58eed49664ca4b0c8a586c8f798c1f38",
            "a0deafa352864de68deea4aa6646e7e4",
            "6b7f17a4729747718490e4e79edae415",
            "c2adb888db464c6cbbce752af8669536",
            "ef6582d276194f6b98f9a3602d39b754",
            "26f7396e6cf341f3a2e5384cee99f61c",
            "de78887f25554895a8b6da2fe0d57854",
            "7ebb35bc683e4254b153d523cdec8838",
            "bec834f1923d46b39101312cd7530500",
            "6e7feed5c1724d42b86a2f4905b51d79",
            "4513c74f528a4465b4793616ab5e6ee0",
            "ae22f966715240bfa810fdf40bca654f",
            "67eefa2a3c3a4b318d11887887f2bffc",
            "41c3464c4b7946b7aba8baad2c4b2194",
            "2c9d5645ba6847e8a364769ff3e8d53a",
            "1bb602b169fe47ccb2baca2fa2e284eb",
            "f3943955c20c4622adb33855a6b2b2e5",
            "4fa196780c1f478bb752cfec1c865427",
            "428467850e9d4e7fa8142c4689e4f370",
            "fc00590c52dd488b8f667d51e3039891",
            "122e4d4c64914457a8ada87c234fe40c",
            "448429f569af404bbf162ae3ccec32d4",
            "5770e86c094d4d4f8e3473241495ad3f",
            "7aaba2873c6140b4abefe864c34f0120",
            "324dd3386d7d43e9bb63afcc048d42b0",
            "919e56bd82874eb0963285dd7d520a1d",
            "bc2e184e5cc943a6aa173c9579acfc4b",
            "3488471a0ae548d394dc40c93cf51a3a",
            "6626a52314c8439a8a82c5994a4f4eac",
            "11565bb74a4d4902965b2cb386157f78",
            "2e8df7f17f87442e90066644dc855a6d",
            "1757ed981e834159bde05a810c8b1d00",
            "51d487adffa142e5b4b412c13216c4e3",
            "cc13e815e637486d986f92dbf00ec74b",
            "961cba277876429ca6392916a98a0c6e",
            "195ad42c0e1941ccb35a2baf7ac6697e",
            "25685bc5a39d40bfaccd38243c539841",
            "e76ae1d6fcff4ea5a0ddfbc8af4b5a42",
            "9945d3f1be5a4ba78867888b5d8f5957",
            "b395229599354ce6bdc8eef3bd70f80d",
            "6f30518c50454c9385dfa9867905cc61",
            "f0345518a8c84c11993f9adc93a73c67"
          ]
        },
        "id": "924e90c1",
        "outputId": "341d4c21-34e5-4b91-c1e1-9d1ee1a8c18d"
      },
      "source": [
        "# 2. Create an instance of the BookQA agent to load the updated code\n",
        "agent = BookQA()\n",
        "\n",
        "# 3. Upload a book (replace the path with one of the problematic PDF files)\n",
        "# Make sure the PDF is in your Google Drive or uploaded directly to the Colab runtime.\n",
        "book_path = '/content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf' # Using one of the problematic files\n",
        "print(f\"\\nAttempting to upload book from: {book_path}\")\n",
        "agent.upload_book(book_path)\n",
        "\n",
        "# If upload is successful, list sections to confirm processing\n",
        "if agent.chapter_sections:\n",
        "    print(\"\\nBook processed successfully. Listing sections:\")\n",
        "    agent.list_sections()\n",
        "else:\n",
        "    print(\"\\nBook processing failed.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NLP models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization model loaded.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57f363e20b9b4e4f9cda343a15972250"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c28ea7f95f254ff9b885e7855502618e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8de9e35cc9a4c62b50d3a45a9108762"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6423198a9cc3439399597ab744d9204e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "975b3d8eb02b4c78b23179edadbaf9c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37bad82439b24484b31d68fe44a9dfff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9df24d1407f24d41ba48aa731f97cc03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3842c759c7934185b3289ef5487ed196"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e7feed5c1724d42b86a2f4905b51d79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "122e4d4c64914457a8ada87c234fe40c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1757ed981e834159bde05a810c8b1d00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Transformer model loaded.\n",
            "Models initialized.\n",
            "\n",
            "Attempting to upload book from: /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf\n",
            "Reading 89 pages from /content/drive/MyDrive/229250892-Brian-Tracy-Goal-Planner.pdf...\n",
            "Finished reading book.\n",
            "Processing book text...\n",
            "Identified 1 chapters/sections or chunks.\n",
            "Creating embeddings for 1 sections...\n",
            "FAISS index created.\n",
            "\n",
            "Book processed successfully. Listing sections:\n",
            "Chapters/Sections:\n",
            "1. Introduction/Beginning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99b18539"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully loaded the book and created embeddings. Now, test the `ask_question`, `list_sections`, and `summarize_section` methods to ensure the agent is functional with the loaded book.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeTb4Q58gMU9",
        "outputId": "625e55db-82b9-4267-e751-bfddfb68f33e"
      },
      "source": [
        "# Test the ask_question method\n",
        "question1 = \"What are the main ideas presented in the book?\"\n",
        "answer1 = agent.ask_question(question1)\n",
        "print(f\"\\nQuestion: {question1}\")\n",
        "print(answer1)\n",
        "\n",
        "question2 = \"How to set goals?\"\n",
        "answer2 = agent.ask_question(question2)\n",
        "print(f\"\\nQuestion: {question2}\")\n",
        "print(answer2)\n",
        "\n",
        "# Test the list_sections method (already done in the previous step, but can be repeated)\n",
        "print(\"\\nListing sections again:\")\n",
        "agent.list_sections()\n",
        "\n",
        "# Test the summarize_section method\n",
        "# Assuming there's at least one section, summarize the first one.\n",
        "if agent.chapter_sections:\n",
        "    first_section_key = list(agent.chapter_sections.keys())[0]\n",
        "    print(f\"\\nAttempting to summarize section: {first_section_key}\")\n",
        "    summary = agent.summarize_section(first_section_key)\n",
        "    print(summary)\n",
        "else:\n",
        "    print(\"\\nNo sections available to summarize.\")\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for answer to: 'What are the main ideas presented in the book?'\n",
            "Most relevant section: 'Introduction/Beginning'\n",
            "\n",
            "Question: What are the main ideas presented in the book?\n",
            "Answer: The more reasons you have for \n",
            "achieving your goal (Source: 'Introduction/Beginning', Score: 0.03)\n",
            "Searching for answer to: 'How to set goals?'\n",
            "Most relevant section: 'Introduction/Beginning'\n",
            "\n",
            "Question: How to set goals?\n",
            "Answer: act as if it were impossible to fail (Source: 'Introduction/Beginning', Score: 0.01)\n",
            "\n",
            "Listing sections again:\n",
            "Chapters/Sections:\n",
            "1. Introduction/Beginning\n",
            "\n",
            "Attempting to summarize section: Introduction/Beginning\n",
            "Summarizing section: 'Introduction/Beginning'\n",
            "Splitting section into 68 chunks for summarization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 1/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 2/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 3/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 4/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 5/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 6/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 7/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 8/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 9/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 10/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 11/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 12/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 13/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 14/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 15/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 16/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 17/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 18/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 19/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 20/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 21/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 22/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 23/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 24/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 25/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 26/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 27/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 28/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 29/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 30/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 31/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 32/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 33/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 34/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 35/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 36/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 37/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 38/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 39/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 40/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 41/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 42/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 43/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 44/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 45/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 46/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 47/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 48/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 49/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 50/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 51/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 52/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 53/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 54/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 55/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 56/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 57/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 58/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 59/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 60/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 61/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 62/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 63/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 64/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 65/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 66/68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 150, but your input_length is only 131. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=65)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized chunk 67/68\n",
            "Summarized chunk 68/68\n",
            "Summary of 'Introduction/Beginning':\n",
            "BRIAN TRACY GOAL PLANNER M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R . the great secret of success is that there are no secrets of success .\n",
            "there are no limits on what you can achieve with your life, except the limits you accept in your own mind . you are a potential genius; there is no problem you cannot solve, and no answer you cannot fi nd some- where .\n",
            "Brian Tracy has consulted for more than 1,000 companies and addressed more than 3,000,000 people in 4,000 talks and seminars . he has studied, researched, written and spoken for 30 years in the fi elds of eco- nomics, history, business, philosophy and psychology .\n",
            "nguages speaks to corporate and public audiences on the subjects of Person- al and Professional Development . talks and seminars on Leadership, Selling, Self-Esteem, Goals, Strategy, Creativity and Success Psychology bring about immediate changes .\n",
            "Brian is the president of three companies headquartered in solana beach, California . he is also the President of a private on-line college for business and entre-preneurship .\n",
            "the contents, or parts thereof, may not be reproduced for any purpose without the written permission of Brian Tracy . this goal planner has been designed after more than 25 years of research and practice .\n",
            "you can learn the habits you need to reach Maximum Achievement by practicing continuous goal-setting and daily action planning . bycompleting this planner over the next 31 days, you will develop in yourself habits that will lead you irresistibly onward to a life of success and achievement .\n",
            "NER The purpose of this goal planner is to enable you to decide exactly what you want in every area of your life . you are asked to set priorities on your goals and organize them in order of importance to you .\n",
            "you are asked to think about your major goals based on ten goal-achieving criteria . you will become a more skilled thinker with every word you write, with every idea you generate . self-discipline is required. Continuous action to-ward your goals must take place every day .\n",
            "you learn how to harness the awesome pow- ers of your subconscious and superconscious minds to bring you anything you really want in life . when you have clear, specifi c goals that you are writing and rewriting every day, you trigger these laws into action on your behalf .\n",
            "your outer world of reality will be like your inner world of belief . as you set challenging goals and move toward them, your belief in yourself becomes unshakable . every day, you confi dently expect that every event, positive or negative, has been sent to help move you toward your goals .\n",
            "you can substitute a positive goal for any negative thought that may be holding you back . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "nation will make you an irresistible force of nature . you can be and do and have all kinds of wonderful things . there lies within you a great, untapped potential .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . write out your three most important goals in life right now: 1. 2. 3. 2. How would you spend your time, where would you go, what would you do, if you found out today that you only had six months to live? 2. 3. 4. 5. 5. 3. 3. What have you always wanted to do but been afraid to attempt?\n",
            "ney would you like to be earning? in one year?.................................................$ In two years? ..........................................$ In three years? $ __________ 8. Who else is earning the kind of money you want to earn?\n",
            "written permission of Brian Tracy . 7 10. Career and professional goals: What do you want to be good at? A. B. C. 11. Sport and fi tness goals .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . M A X I M U M A C H I E V E M E N T G O A L P L A N N E R  Brian Tracy.\n",
            "ts, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . what do you think should be your most important goal? Write it out in detail .\n",
            "the people whose help and cooperation I will require are: 1. ________________________________ ______________ . __________ ___________________ ____________ 3. _ _____________.______________ 4. _ _______ ______ . 5. _.________,______________, ____________ _ (______________)______________. .\n",
            "in the right-hand column, organize your goals from #1 = most important to #7 = least important . this will give you a completion of your goals .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . GOAL NUMBER ONE: ACTION STEPS ORDER 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. Organize your action steps in order of importance to achieve your goal, from #1 to #10 .\n",
            "rganize your action steps in the right-hand column in order of importance to achieving your goal, from #1 to #10 . ACTION PLAN – What I will do immediately is: 1. 2. 3. 4. 5. 6. M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy .\n",
            "______________________ 1. Belief: Is it believable and achievable? 3. Write it down: How will you measure success? 4. Analyze: Where are you starting from now? 7. Ask: What major obstacles must you overcome? 9. Key People: Whose assistance or cooperation do you need? 16 10. FINALLY — Write out a detailed plan of accomplishment .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 17 COMMITMENT \"all sorts of things occur to help that would never otherwise have occurred,\" he said .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . GETTING STARTED 1. You are responsible. Develop the habit of goal setting by finishing two pages each day for 31 days .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the number of times I succeed is in direct proportion to the number I can fail and keep on trying.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . M A X I M U M A C H I E V E M E N T G O A L P L A N N E R  Brian Tracy. All rights reserved.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .   2. Daily Goal Setting Exercise — my major defi nite purpose is: 3. Daily Goal Planning Exercise .\n",
            "M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved. the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the successful person always has a number of projects planned, to which he looks forward .\n",
            "ns in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "es as the enemy of success, but it isn’t at all... You can be discouraged by failure — or you can learn from it . so go ahead and make mistakes. make all you can . remember that’s where you’ll fi nd success. on the far side of failure .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the contedence is a powerful factor in prosperity consciousness: self-esteem: believing you can do it, believing you deserve it .\n",
            "nts, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "Joyce Brothers M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved. The contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "daily goal setting exercise — my major defi nite purpose is: 3. Daily Goal Setting Exercise — write out plans in longhand using the present tense . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . a questio is a challenge for a man if he is willing to study them and make capital from them .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . it is important to know how to concentrate it, how to husband it and how to focus it on important things .\n",
            "Michael Korda M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved. The contents, or parts thereof, may not be reproduce in any form for any purpose without the written permission of Brian Tracy .\n",
            "ercise — my major defi nite purpose is: 3. Daily Goal Planning Exercise — write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. The fi rst law of success... is concentration — to blend all the energies to one point, and to go directly to that point, looking neither to the right nor to the left .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the giants of the race have been men of concentration, who have struck sledge-hammer blows in one place until they have accomplished their purpose .\n",
            "the contents, or parts thereof, may not be reproduced in any form without the written permission of Brian Tracy . the majority of men meet with failure because of their lack of persistence in creating new plans to take the place of those which fail .\n",
            "M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "rpose is: 3. Daily Goal Planning Exercise . write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. Only you must, then, really wish these things, and wish them exclusively, and not wish a hundred other incompatible things just as strongly .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . the contents of the daily goal planning exercise Quick List — my major defi nite purpose is: 3. Daily Goal Setting Exercise — write out plans in longhand using the present tense .\n",
            "48 4. Write your major problem or goal in the form of a question . 5. Write out 20 answers to question number four: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20 .\n",
            "Tom Hopkins M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy. All rights reserved. The contents, or parts thereof, may not be reproduce in any form for any purpose without the written permission of Brian Tracy .\n",
            "IDEA FOR TODAY 1. Daily Goal Planning Exercise Quick List . write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. Always try to do something for the other fellow and you will be agreeably surprised how things come your way .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . a y 18 / / DATE BACKGROUND IDEA FOR TODAY 1. Daily Goal Planning Exercise Quick List — your three most important goals:   2. Daily Goal Setting Exercise — write out plans in longhand using the present tense .\n",
            "your major problem or goal in the form of a question is 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 6. Select at least one action from the above exercise to begin immediately: M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R .\n",
            "Bruce Barton M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy. 57 D A Y 20 / / DATE BACKGROUND IDEA FOR TODAY 1.\n",
            "ily Goal Planning Exercise — write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. Expect trouble as an inevitable part of life . when it comes, hold your head high, look it squarely in the eye and say \"I will be bigger than you. You cannot defeat me\"\n",
            "E M E N T G O A L P L A N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 61 D A Y 22 / / DATE BACKGROUND IDEA FOR TODAY 1. Daily Goal Planning Exercise Quick List — your three most important goals .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 62 4. Write your major problem or goal in the form of a question: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20.\n",
            "lf to profi t by your chance, the opportunity will only make you ridiculous . a great occasion is valuable to you just in proportion as you have educated yourself to make use of it .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy. 65 Nothing in the world can take the place of persistence alone is omnipotent .\n",
            "67 There is one thing stronger than all the armies in the world and that is an idea whose time has come . the contents, or parts thereof, may not be reproduced in any form without the written permission of Brian Tracy .\n",
            "A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "al Setting exercise — my major defi nite purpose is: 3. Daily Goal Planning Exercise — write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. M A X I M U M A C H I E V E M E N T G O A L P L A N N E R  Brian Tracy . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy. 72 4. Write your major problem or goal in the form of a question: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20.\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 73 The empires of the future are the empire of the mind .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy . 75 In order to succeed, we must fi rst believe we can .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy. 77 I do not think there is any other quality so essential to success of any kind as the quality of perseverance. it overcome almost everything, even nature.\n",
            "al Planning Exercise — write out plans in longhand using the present tense: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. M A X I M U M A C H I E V E M E N T G O A L P L A N N N E R  Brian Tracy . 79 Progress always involves risk, you can’t steal second base and keep your foot on fi rst .\n",
            "the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .   2. Daily Goal Setting Exercise — my major defi nite purpose is: 3. Daily Goal Planning Exercise .\n",
            "81 The establishment of a clear, central purpose or goal in life is the starting point of all success . the contents, or parts thereof, may not be reproduced in any form for any purpose without the written permission of Brian Tracy .\n",
            "you are an action person, so take action today! it is not what you say, or wish, or hope, or intend... It is only what you do that counts .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the ask_question method\n",
        "question1 = \"What are the main ideas presented in the book?\"\n",
        "answer1 = agent.ask_question(question1)\n",
        "print(f\"\\nQuestion: {question1}\")\n",
        "print(answer1)\n",
        "\n",
        "question2 = \"How to set goals?\"\n",
        "answer2 = agent.ask_question(question2)\n",
        "print(f\"\\nQuestion: {question2}\")\n",
        "print(answer2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7rUHDt9g-ln",
        "outputId": "2f370c5f-1b92-4180-d412-650f75a12bfd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for answer to: 'What are the main ideas presented in the book?'\n",
            "Most relevant section: 'Introduction/Beginning'\n",
            "\n",
            "Question: What are the main ideas presented in the book?\n",
            "Answer: The more reasons you have for \n",
            "achieving your goal (Source: 'Introduction/Beginning', Score: 0.03)\n",
            "Searching for answer to: 'How to set goals?'\n",
            "Most relevant section: 'Introduction/Beginning'\n",
            "\n",
            "Question: How to set goals?\n",
            "Answer: act as if it were impossible to fail (Source: 'Introduction/Beginning', Score: 0.01)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88ccc655"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial error \"setting an array element with a sequence\" occurred during TF-IDF vectorization when processing the provided PDF files.\n",
        "*   This error was resolved by replacing the TF-IDF vectorization approach with Sentence Transformer embeddings for creating text representations.\n",
        "*   The updated `BookQA` class successfully initialized a Sentence Transformer model (`all-MiniLM-L6-v2`) and used it to generate embeddings for the book sections.\n",
        "*   A FAISS index was created using the generated embeddings, enabling efficient semantic search.\n",
        "*   The agent successfully processed the previously problematic PDF file using the new embedding approach.\n",
        "*   Core functionalities, including listing sections, asking questions, and summarizing sections, worked after the update.\n",
        "*   The summarization pipeline produced warnings regarding `max_new_tokens` and `max_length` parameters but completed the task.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The switch from TF-IDF to Sentence Transformer embeddings effectively addressed the array dimension error, suggesting that the issue was related to how TF-IDF handled sequences within the text data extracted from the PDFs.\n",
        "*   Future work could involve addressing the summarization warnings for potentially better control over summary length and exploring more sophisticated text splitting techniques or larger language models for improved QA and summarization quality.\n"
      ]
    }
  ]
}